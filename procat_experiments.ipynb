{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCAT Experiments\n",
    "\n",
    "In this notebook, we run experiments on the 10K set of real catalogues from the PROCAT dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn import Parameter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# sacred\n",
    "from sacred import Experiment\n",
    "from sacred.observers import MongoObserver\n",
    "\n",
    "# text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from itertools import chain\n",
    "import nltk  # had to also run nltk.download('punkt')\n",
    "\n",
    "# visuals\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show full width tables\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom utils\n",
    "from utils import count_params, train_epochs\n",
    "from data import test_model_custom, compare_solved_sort_unique, \\\n",
    "    get_single_kendall_tau, get_single_spearman_rho, get_batch_rank_correlation, get_batch_rank_correlation_and_perc_valid\n",
    "from procat_utils import get_catalogs_with_full_info, show_predicted_catalog, show_correct_catalog, get_prediction_as_offers, print_predicted_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload if saved changes in modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacred experiment\n",
    "config['ptr_mask'] = True\n",
    "config['dataset_folder'] = 'PROCAT'\n",
    "config['dataset_name'] = config['dataset_folder']\n",
    "config['task'] = 'real_catalogs'\n",
    "config['experiment_name'] = config['task'] + '_' + config['dataset_folder'] + '_mask_' + str(config['ptr_mask'])\n",
    "config['db_name'] = 'sacred'\n",
    "config['db_url'] = 'localhost:27017'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture\n",
    "config['ptr_word_emb_dim'] = 32\n",
    "config['ptr_offer_emb_dim'] = 64\n",
    "config['ptr_hid_dim'] = 64\n",
    "config['ptr_offer_rnn_layers'] = 2\n",
    "config['ptr_catalog_rnn_layers'] = 2\n",
    "config['ptr_dropout_catalogs'] = 0.05\n",
    "config['ptr_dropout_offers'] = 0.05\n",
    "config['ptr_bidir_catalogs'] = True\n",
    "config['ptr_bidir_offers'] = False\n",
    "\n",
    "# training\n",
    "config['batch_size'] = 64\n",
    "config['learning_rate'] =  0.0001\n",
    "config['num_epochs'] = 5  # set this to 150 or 200 for actual results\n",
    "\n",
    "# persisting\n",
    "config['model_path'] = './model/model.pkb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv size\n",
    "config['test_small_size'] = 300\n",
    "\n",
    "# text preprocessing\n",
    "config['vocab_max'] =  300000 # vocabulary cap (for tokens)\n",
    "config['unknown_token'] = '?UNK?'\n",
    "config['eos_token'] = '?EOS?'\n",
    "config['pad_token'] = '?PAD?'\n",
    "config['max_tokens'] = 30\n",
    "\n",
    "# catalog preprocessing\n",
    "config['page_break_token'] = '?PAGE_BREAK?'\n",
    "config['page_break_priority'] = 0\n",
    "config['max_offer_tokens_per_catalog'] = 200  # choose based on distributions, includes page-breaks\n",
    "config['pad_not_real_offer'] = '?NOT_REAL_OFFER?'\n",
    "config['pad_not_real_offer_priority'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Config paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "config['path_in_df_offers_csv'] = './{}/offer_features.csv'.format(config['dataset_folder'])\n",
    "config['path_in_df_sections_csv'] = './{}/section_features.csv'.format(config['dataset_folder'])\n",
    "config['path_in_df_catalog_csv'] = './{}/catalog_features.csv'.format(config['dataset_folder'])\n",
    "\n",
    "config['path_in_df_catalog_train_csv'] = './{}/catalog_train_set_features.csv'.format(config['dataset_folder'])\n",
    "config['path_in_df_catalog_test_csv'] = './{}/catalog_test_set_features.csv'.format(config['dataset_folder'])\n",
    "\n",
    "config['path_in_dictionary'] = './{}/dictionary.pickle'.format(config['dataset_folder'])\n",
    "config['path_in_catalog_id_to_section_ids'] = './{}/catalog_to_sections.pickle'.format(config['dataset_folder'])\n",
    "\n",
    "config['path_in_section_id_to_offer_ids'] = './{}/section_to_offers.pickle'.format(config['dataset_folder'])\n",
    "config['path_in_section_id_to_offer_vectors'] = './{}/section_id_to_offer_vectors.pickle'.format(config['dataset_folder'])\n",
    "config['path_in_section_id_to_section_num'] = './{}/section_to_number.pickle'.format(config['dataset_folder'])\n",
    "config['path_in_section_id_to_offer_priorities'] = './{}/section_id_to_offer_priorities.pickle'.format(config['dataset_folder'])\n",
    "\n",
    "config['path_in_offer_id_to_priority'] = './{}/offer_to_priority.pickle'.format(config['dataset_folder'])\n",
    "config['path_in_offer_id_to_vector'] = './{}/offer_to_vector.pickle'.format(config['dataset_folder'])\n",
    "\n",
    "config['path_in_np_X_train'] = './{}/X_train.npy'.format(config['dataset_folder'])\n",
    "config['path_in_np_Y_train'] = './{}/Y_train.npy'.format(config['dataset_folder'])\n",
    "config['path_in_np_X_test'] = './{}/X_test.npy'.format(config['dataset_folder'])\n",
    "config['path_in_np_Y_test'] = './{}/Y_test.npy'.format(config['dataset_folder'])\n",
    "\n",
    "config['path_in_torch_X_train'] = './{}/X_train.pb'.format(config['dataset_folder'])\n",
    "config['path_in_torch_Y_train'] = './{}/Y_train.pb'.format(config['dataset_folder'])\n",
    "config['path_in_torch_X_test'] = './{}/X_test.pb'.format(config['dataset_folder'])\n",
    "config['path_in_torch_Y_test'] = './{}/Y_test.pb'.format(config['dataset_folder'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ptr_mask': True,\n",
       " 'dataset_folder': 'PROCAT',\n",
       " 'dataset_name': 'PROCAT',\n",
       " 'task': 'real_catalogs',\n",
       " 'experiment_name': 'real_catalogs_PROCAT_mask_True',\n",
       " 'db_name': 'sacred',\n",
       " 'db_url': 'localhost:27017',\n",
       " 'ptr_word_emb_dim': 32,\n",
       " 'ptr_offer_emb_dim': 64,\n",
       " 'ptr_hid_dim': 64,\n",
       " 'ptr_offer_rnn_layers': 2,\n",
       " 'ptr_catalog_rnn_layers': 2,\n",
       " 'ptr_dropout_catalogs': 0.05,\n",
       " 'ptr_dropout_offers': 0.05,\n",
       " 'ptr_bidir_catalogs': True,\n",
       " 'ptr_bidir_offers': False,\n",
       " 'batch_size': 64,\n",
       " 'learning_rate': 0.0001,\n",
       " 'num_epochs': 5,\n",
       " 'model_path': './model/model.pkb',\n",
       " 'test_small_size': 300,\n",
       " 'vocab_max': 300000,\n",
       " 'unknown_token': '?UNK?',\n",
       " 'eos_token': '?EOS?',\n",
       " 'pad_token': '?PAD?',\n",
       " 'max_tokens': 30,\n",
       " 'page_break_token': '?PAGE_BREAK?',\n",
       " 'page_break_priority': 0,\n",
       " 'max_offer_tokens_per_catalog': 200,\n",
       " 'pad_not_real_offer': '?NOT_REAL_OFFER?',\n",
       " 'pad_not_real_offer_priority': -1,\n",
       " 'path_in_df_offers_csv': './PROCAT/offer_features.csv',\n",
       " 'path_in_df_sections_csv': './PROCAT/section_features.csv',\n",
       " 'path_in_df_catalog_csv': './PROCAT/catalog_features.csv',\n",
       " 'path_in_df_catalog_train_csv': './PROCAT/catalog_train_set_features.csv',\n",
       " 'path_in_df_catalog_test_csv': './PROCAT/catalog_test_set_features.csv',\n",
       " 'path_in_dictionary': './PROCAT/dictionary.pickle',\n",
       " 'path_in_catalog_id_to_section_ids': './PROCAT/catalog_to_sections.pickle',\n",
       " 'path_in_section_id_to_offer_ids': './PROCAT/section_to_offers.pickle',\n",
       " 'path_in_section_id_to_offer_vectors': './PROCAT/section_id_to_offer_vectors.pickle',\n",
       " 'path_in_section_id_to_section_num': './PROCAT/section_to_number.pickle',\n",
       " 'path_in_section_id_to_offer_priorities': './PROCAT/section_id_to_offer_priorities.pickle',\n",
       " 'path_in_offer_id_to_priority': './PROCAT/offer_to_priority.pickle',\n",
       " 'path_in_offer_id_to_vector': './PROCAT/offer_to_vector.pickle',\n",
       " 'path_in_np_X_train': './PROCAT/X_train.npy',\n",
       " 'path_in_np_Y_train': './PROCAT/Y_train.npy',\n",
       " 'path_in_np_X_test': './PROCAT/X_test.npy',\n",
       " 'path_in_np_Y_test': './PROCAT/Y_test.npy',\n",
       " 'path_in_torch_X_train': './PROCAT/X_train.pb',\n",
       " 'path_in_torch_Y_train': './PROCAT/Y_train.pb',\n",
       " 'path_in_torch_X_test': './PROCAT/X_test.pb',\n",
       " 'path_in_torch_Y_test': './PROCAT/Y_test.pb'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Tracking via Sacred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the experiment\n",
    "ex = Experiment(name=config['experiment_name'], interactive=True)\n",
    "\n",
    "# add an observer, storing experiment info\n",
    "ex.observers.append(MongoObserver(url=config['db_url'], db_name=config['db_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment config\n",
    "@ex.config\n",
    "def ex_config():\n",
    "    \n",
    "    # general\n",
    "    learning_rate = config['learning_rate']\n",
    "    dataset = config['dataset_name'] \n",
    "    epochs = config['num_epochs']\n",
    "    cfg = config\n",
    "    \n",
    "    # model\n",
    "    model = None\n",
    "    final_training_loss = None\n",
    "    optimizer = None\n",
    "    \n",
    "    # db \n",
    "    db_name = config['db_name']\n",
    "    db_url = config['db_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment run function\n",
    "@ex.main\n",
    "def run_model_tests():\n",
    "\n",
    "    # run all tests, get all results\n",
    "    result_general, result_tau, result_spearman, rank_valid_perc = run_tests(current_tested_model, test_dataloader, config)\n",
    "    \n",
    "    # log params and results\n",
    "    log_experiment_results(result_general, result_tau, result_spearman, rank_valid_perc)\n",
    "    \n",
    "    return round(result_general, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests(a_model, a_dataloader, a_config):\n",
    "    \n",
    "    print('Model: ', a_model.__class__)\n",
    "\n",
    "    a_model.eval() \n",
    "    \n",
    "    # general accuracy\n",
    "    result_general, _ = test_model_custom(a_model, a_dataloader, compare_solved_sort_unique, print_every=999999, x_name=0, y_name=1)\n",
    "    print('Result: {:.4f}'.format(result_general))\n",
    "    \n",
    "    result_tau, rank_valid_perc = get_batch_rank_correlation_and_perc_valid(a_dataloader, a_model, get_single_kendall_tau, print_every=999999)\n",
    "    print('K-Tau: {:.4f}, perc_valid: {}'.format(result_tau, rank_valid_perc))\n",
    "\n",
    "    result_spearman, rank_valid_perc = get_batch_rank_correlation_and_perc_valid(a_dataloader, a_model, get_single_spearman_rho, print_every=999999)\n",
    "    print('S-Rho: {:.4f}, perc_valid: {}'.format(result_spearman, rank_valid_perc))\n",
    "\n",
    "    a_model.train()\n",
    "    \n",
    "    return result_general, result_tau, result_spearman, rank_valid_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_experiment_results(r_general, r_tau, r_spearman, rank_valid_perc):\n",
    "    \n",
    "    # round if not none\n",
    "    if r_tau:\n",
    "        r_tau = round(r_tau, 5)\n",
    "    if r_spearman:\n",
    "        r_spearman = round(r_spearman, 5)\n",
    "    \n",
    "    # log the results\n",
    "    ex.log_scalar('test.general', r_general)\n",
    "    ex.log_scalar('test.rank_correlation_valid_perc', rank_valid_perc)\n",
    "    ex.log_scalar('test.tau', r_tau, 5)\n",
    "    ex.log_scalar('test.rho', r_spearman, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_unshuffled_x(x, y):\n",
    "    r = [x[i] for i in y]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(220788)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example(a_dataloader, x_name=0, y_name=1):\n",
    "    \"\"\"\n",
    "    Take a torch dataloader and get a single example.\n",
    "    \"\"\"\n",
    "    a_batch = next(iter(a_dataloader))\n",
    "    example_points = a_batch[x_name][0]\n",
    "    example_solution = a_batch[y_name][0]\n",
    "\n",
    "    return example_points, example_solution\n",
    "\n",
    "\n",
    "def get_batch(a_dataloader, x_name=0, y_name=1):\n",
    "    \"\"\"\n",
    "    Get a batch of points and solutions from a torch dataloader.\n",
    "    \"\"\"\n",
    "    a_batch = next(iter(a_dataloader))\n",
    "    batch_points = a_batch[x_name]\n",
    "    batch_solutions = a_batch[y_name]\n",
    "\n",
    "    return batch_points, batch_solutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "Load all needed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload Data\n",
    "Including:\n",
    "- **SIGIR csv's**\n",
    "    - df_offers\n",
    "    - df_sections\n",
    "    - df_catalogs\n",
    "- **any meta-resources**:\n",
    "    - (word2idx)\n",
    "    - section to offer ids etc?\n",
    "- **numpy X and Y**\n",
    "    - train and test separately\n",
    "- **torch dataloaders**\n",
    "    - the actual torch dataloaders (for myself?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog_id</th>\n",
       "      <th>section</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>priority</th>\n",
       "      <th>heading</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>token_length</th>\n",
       "      <th>offer_as_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0003leq</td>\n",
       "      <td>1</td>\n",
       "      <td>fed3AqfY</td>\n",
       "      <td>2</td>\n",
       "      <td>Påskebryg</td>\n",
       "      <td>33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælges fra fredag d. 17/3. Ved køb af mere end 60 stk., er prisen herefter 4,98 kr</td>\n",
       "      <td>Påskebryg 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælges fra fredag d. 17/3. Ved køb af mere end 60 stk., er prisen herefter 4,98 kr</td>\n",
       "      <td>['påskebryg', '33', 'cl', '.', 'kylle', '-', 'kylle', '.', '3', '33', '.', '+', 'pant', '.', 'sælges', 'fra', 'fredag', 'd.', '17/3', '.', 'ved', 'køb', 'af', 'mere', 'end', '60', 'stk.', ',', 'er', '?EOS?']</td>\n",
       "      <td>33</td>\n",
       "      <td>[10912, 250, 50, 5, 16874, 18, 16874, 5, 35, 250, 5, 82, 128, 5, 267, 46, 2199, 147, 41453, 5, 93, 210, 22, 182, 227, 106, 3845, 6, 31, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  catalog_id  section  offer_id  priority    heading                                                                                                             description                                                                                                                              text                                                                                                                                                                                                   text_tokenized  token_length                                                                                                                             offer_as_vector\n",
       "0  0003leq    1        fed3AqfY  2         Påskebryg  33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælges fra fredag d. 17/3. Ved køb af mere end 60 stk., er prisen herefter 4,98 kr  Påskebryg 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælges fra fredag d. 17/3. Ved køb af mere end 60 stk., er prisen herefter 4,98 kr  ['påskebryg', '33', 'cl', '.', 'kylle', '-', 'kylle', '.', '3', '33', '.', '+', 'pant', '.', 'sælges', 'fra', 'fredag', 'd.', '17/3', '.', 'ved', 'køb', 'af', 'mere', 'end', '60', 'stk.', ',', 'er', '?EOS?']  33            [10912, 250, 50, 5, 16874, 18, 16874, 5, 35, 250, 5, 82, 128, 5, 267, 46, 2199, 147, 41453, 5, 93, 210, 22, 182, 227, 106, 3845, 6, 31, 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(config['path_in_df_offers_csv'], sep=';')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1613686"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog_id</th>\n",
       "      <th>section_id</th>\n",
       "      <th>section_num</th>\n",
       "      <th>offer_ids</th>\n",
       "      <th>offer_vectors</th>\n",
       "      <th>offer_priorities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0003leq</td>\n",
       "      <td>0003leq_1</td>\n",
       "      <td>1</td>\n",
       "      <td>['fed3AqfY', '799dzqfY', 'b8a3DqfY', 'a4c88qfY', '3cf8qqfY', '88a5UqfY', '6d6e0qfY', 'ef59YqfY', 'ab38CqfY', '0cbffqfY', '0a4eEqfY']</td>\n",
       "      <td>[[10912, 250, 50, 5, 16874, 18, 16874, 5, 35, 250, 5, 82, 128, 5, 267, 46, 2199, 147, 41453, 5, 93, 210, 22, 182, 227, 106, 3845, 6, 31, 0], [408, 99, 1024, 15, 5, 29, 5, 37, 5, 136, 141, 46, 5612, 13, 1763, 7, 3228, 7, 4673, 7, 6008, 7, 6644, 0, 1, 1, 1, 1, 1, 1], [50781, 17910, 5, 967, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1163, 712, 1063, 3313, 2145, 3686, 27, 5, 7, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1362, 16, 3494, 4462, 34761, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1585, 26725, 5, 19, 20, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [932, 11768, 21, 5, 7, 140, 7, 420, 5, 1787, 5, 168, 104, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3772, 3048, 65, 27, 5, 7, 6182, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [882, 248, 7, 578, 5, 79, 21, 5, 93, 210, 22, 182, 227, 57, 425, 6, 31, 200, 202, 7012, 102, 5, 75, 31, 336, 160, 0, 1, 1, 1], [1587, 3925, 21, 5, 18, 152, 18, 465, 5, 688, 336, 5, 7, 727, 7, 800, 7, 1761, 2026, 7, 189, 9, 518, 7, 2168, 7, 272, 1004, 7, 0], [2359, 93, 210, 22, 182, 227, 65, 425, 6, 31, 200, 202, 11439, 102, 5, 112, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]</td>\n",
       "      <td>[2, 2, 1, 1, 2, 1, 1, 1, 3, 3, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  catalog_id section_id  section_num                                                                                                                             offer_ids                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      offer_vectors                   offer_priorities\n",
       "0  0003leq    0003leq_1  1            ['fed3AqfY', '799dzqfY', 'b8a3DqfY', 'a4c88qfY', '3cf8qqfY', '88a5UqfY', '6d6e0qfY', 'ef59YqfY', 'ab38CqfY', '0cbffqfY', '0a4eEqfY']  [[10912, 250, 50, 5, 16874, 18, 16874, 5, 35, 250, 5, 82, 128, 5, 267, 46, 2199, 147, 41453, 5, 93, 210, 22, 182, 227, 106, 3845, 6, 31, 0], [408, 99, 1024, 15, 5, 29, 5, 37, 5, 136, 141, 46, 5612, 13, 1763, 7, 3228, 7, 4673, 7, 6008, 7, 6644, 0, 1, 1, 1, 1, 1, 1], [50781, 17910, 5, 967, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1163, 712, 1063, 3313, 2145, 3686, 27, 5, 7, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1362, 16, 3494, 4462, 34761, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1585, 26725, 5, 19, 20, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [932, 11768, 21, 5, 7, 140, 7, 420, 5, 1787, 5, 168, 104, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3772, 3048, 65, 27, 5, 7, 6182, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [882, 248, 7, 578, 5, 79, 21, 5, 93, 210, 22, 182, 227, 57, 425, 6, 31, 200, 202, 7012, 102, 5, 75, 31, 336, 160, 0, 1, 1, 1], [1587, 3925, 21, 5, 18, 152, 18, 465, 5, 688, 336, 5, 7, 727, 7, 800, 7, 1761, 2026, 7, 189, 9, 518, 7, 2168, 7, 272, 1004, 7, 0], [2359, 93, 210, 22, 182, 227, 65, 425, 6, 31, 200, 202, 11439, 102, 5, 112, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]  [2, 2, 1, 1, 2, 1, 1, 1, 3, 3, 2]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sections = pd.read_csv(config['path_in_df_sections_csv'], sep=';')\n",
    "df_sections.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238256"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog_id</th>\n",
       "      <th>section_ids</th>\n",
       "      <th>offer_ids_with_pb</th>\n",
       "      <th>offer_vectors_with_pb</th>\n",
       "      <th>offer_priorities_with_pb</th>\n",
       "      <th>num_offers</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0003leq</td>\n",
       "      <td>{'0003leq_1', '0003leq_2', '0003leq_4', '0003leq_6', '0003leq_3', '0003leq_5', '0003leq_7'}</td>\n",
       "      <td>['fed3AqfY', '799dzqfY', 'b8a3DqfY', 'a4c88qfY', '3cf8qqfY', '88a5UqfY', '6d6e0qfY', 'ef59YqfY', 'ab38CqfY', '0cbffqfY', '0a4eEqfY', '?PAGE_BREAK?', '0ef3QqfY', 'a3abpqfY', 'ce94wqfY', 'e545VqfY', '11aaxqfY', 'e4e12qfY', '431baqfY', '3030ZqfY', 'db3fNqfY', 'd638dqfY', '539csqfY', 'b25flqfY', '18cdFqfY', '50b5vqfY', '?PAGE_BREAK?', 'db9dGqfY', '4daaRqfY', 'bd0fXqfY', '9937SqfY', 'a3ddnqfY', '59cchqfY', 'd8f9oqfY', '0be3HqfY', 'b3acOqfY', 'aeberqfY', '44a2IqfY', '708e7qfY', 'f4f4MqfY', '?PAGE_BREAK?', '2502x0fY', '070eU0fY', 'a6a7Z0fY', '183cY0fY', '257as0fY', '0da4f0fY', '4809E0fY', '4815F0fY', 'f1a9z0fY', '3672p0fY', '283c80fY', '?PAGE_BREAK?', '29c0BqfY', '9381iqfY', '907ajqfY', '28d5kqfY', '280auqfY', '00b64qfY', '1864JqfY', 'e2835qfY', '7c1eeqfY', '067bTqfY', '46df6qfY', 'b84a9qfY', '614ebqfY', '11bbPqfY', '?PAGE_BREAK?', 'b553q0fY', '36f3y0fY', '222fcqfY', '5cb900fY', '7d7a10fY', '97f9K0fY', 'fc78C0fY', 'c90d30fY', '5b2ag0fY', 'c941A0fY', 'a259L0fY', '6429tqfY', 'a5caD0fY', '08cfm0fY', '22edWqfY', '?PAGE_BREAK?', 'b7fcb0fY', 'd4f0v0fY', 'fb3cQ0fY', '0ba1i0fY', 'a367w0fY', 'ac74V0fY', '3531u0fY', 'fbff20fY', 'e4b8a0fY', '3956N0fY', '0d81d0fY', '029aT0fY', '5dbdl0fY', '?PAGE_BREAK?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?']</td>\n",
       "      <td>[[10912, 250, 50, 5, 16874, 18, 16874, 5, 35, 250, 5, 82, 128, 5, 267, 46, 2199, 147, 41453, 5, 93, 210, 22, 182, 227, 106, 3845, 6, 31, 0], [408, 99, 1024, 15, 5, 29, 5, 37, 5, 136, 141, 46, 5612, 13, 1763, 7, 3228, 7, 4673, 7, 6008, 7, 6644, 0, 1, 1, 1, 1, 1, 1], [50781, 17910, 5, 967, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1163, 712, 1063, 3313, 2145, 3686, 27, 5, 7, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1362, 16, 3494, 4462, 34761, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1585, 26725, 5, 19, 20, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [932, 11768, 21, 5, 7, 140, 7, 420, 5, 1787, 5, 168, 104, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3772, 3048, 65, 27, 5, 7, 6182, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [882, 248, 7, 578, 5, 79, 21, 5, 93, 210, 22, 182, 227, 57, 425, 6, 31, 200, 202, 7012, 102, 5, 75, 31, 336, 160, 0, 1, 1, 1], [1587, 3925, 21, 5, 18, 152, 18, 465, 5, 688, 336, 5, 7, 727, 7, 800, 7, 1761, 2026, 7, 189, 9, 518, 7, 2168, 7, 272, 1004, 7, 0], [2359, 93, 210, 22, 182, 227, 65, 425, 6, 31, 200, 202, 11439, 102, 5, 112, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [1791, 120, 44401, 102, 5, 15, 5, 17, 75, 31, 336, 5, 151, 5, 7, 9, 3376, 45, 38, 99, 5, 825, 21, 0, 1, 1, 1, 1, 1, 1], [629, 641, 7, 6597, 3664, 7, 3262, 4189, 7, 678, 11, 662, 7, 99, 1522, 232, 942, 7, 5156, 7, 10564, 5, 289, 21, 5, 1932, 42, 0, 1, 1], [1959, 6453, 574, 216, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [7987, 401, 964, 32, 5, 1932, 42, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [12124, 11, 228, 112, 21, 5, 22, 1692, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1172, 7, 12675, 7, 1878, 29642, 7, 1878, 14856, 5, 278, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2621, 13403, 21, 5, 7, 3828, 2621, 7, 11914, 2621, 5, 629, 641, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1038, 491, 1541, 112, 21, 5, 137, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5157, 3302, 5, 5331, 21, 5, 4025, 42, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1172, 1932, 42, 5, 7, 1516, 7, 665, 1265, 7, 229, 665, 2795, 2779, 7, 6325, 7, 6587, 7, 2510, 5635, 7, 5515, 7, 2999, 2614, 7, 491, 5419, 0], [1038, 2819, 964, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2634, 9977, 21, 5, 3302, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [46762, 11, 676, 79, 21, 5, 8696, 8, 220, 13, 123, 11, 110, 5, 5156, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [9487, 15, 5, 4286, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [129, 1269, 416, 13535, 692, 5, 29, 5, 2689, 62, 33, 1480, 160, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [879, 7, 1131, 7, 272, 965, 7, 3179, 7, 4130, 11, 230, 7, 1131, 165, 38, 7, 4900, 165, 38, 7, 122, 27046, 7, 122, 4900, 5, 19397, 21, 0], [1296, 66, 21, 5, 11, 230, 5, 7, 393, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [821, 3687, 21, 5, 579, 5, 137, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1084, 7, 5102, 18, 155, 18, 126, 1194, 5, 18, 9, 836, 5, 8069, 21, 5, 7, 724, 5121, 7, 15791, 9343, 7, 7504, 7, 14954, 4204, 7, 5855, 0], [18785, 118, 21, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3734, 7, 5, 68, 21, 5, 19094, 5, 2904, 33, 151, 4416, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3005, 879, 5, 10794, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [735, 851, 258, 89, 5, 972, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1879, 531, 112, 21, 5, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [463, 7, 5, 3329, 21, 5, 7, 3292, 7, 25769, 7, 25770, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5259, 1180, 68, 32, 5, 7, 862, 7, 328, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [463, 125, 5, 66, 21, 5, 11121, 1190, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [14167, 168, 104, 7, 3537, 628, 7, 457, 7, 4515, 148, 17238, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3445, 7, 155, 7, 565, 5, 2135, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1016, 1044, 35, 29, 5, 7, 290, 7, 457, 7, 2327, 5, 863, 5, 15, 5, 305, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [759, 3054, 5985, 21, 5, 7, 712, 1792, 7, 759, 155, 7, 759, 1362, 7, 2730, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4564, 514, 6, 3161, 16, 3498, 2192, 999, 74, 2103, 18, 449, 18, 984, 18, 7, 18, 155, 18, 6725, 2233, 5, 7, 4163, 21, 5, 18, 18, 18, 0], [720, 1282, 3235, 7, 7534, 6646, 5, 380, 720, 108, 1946, 851, 11, 7256, 65, 1721, 33, 1877, 6, 62, 108, 262, 22, 582, 444, 6, 248, 6, 300, 0], [1111, 285, 5, 75, 31, 336, 5, 10467, 21, 5, 7, 1149, 504, 21, 7, 1719, 6, 646, 7, 5122, 6, 1486, 0, 1, 1, 1, 1, 1, 1, 1], [547, 117, 50, 5, 19, 20, 5, 82, 128, 5, 35, 5, 7, 1041, 7, 677, 724, 7, 3872, 3868, 2576, 7, 648, 7, 648, 37, 7, 1940, 5, 0], [882, 248, 68, 21, 5, 7, 152, 404, 7, 649, 18, 151, 675, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [21862, 990, 19, 20, 16992, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1900, 404, 252, 207, 5, 7, 971, 248, 18, 155, 18, 4707, 5, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [576, 620, 410, 6, 46763, 410, 16, 34762, 36013, 524, 32, 5, 45, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1243, 514, 552, 1078, 5, 1253, 21, 5, 7, 7988, 7, 2233, 7, 620, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [856, 30, 17, 5, 840, 2608, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [37395, 79, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2766, 54, 1050, 5, 384, 216, 21, 5, 6020, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [6463, 6, 2100, 6, 3911, 16, 5446, 232, 331, 3665, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [552, 1078, 3076, 105, 21, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1704, 705, 5, 105, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5353, 20580, 38, 5, 79, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [544, 7, 5380, 18045, 7, 12625, 18045, 7, 1728, 5258, 7, 37396, 2019, 7, 17613, 7, 506, 10565, 7, 50782, 7, 699, 2019, 7, 699, 4398, 5, 528, 108, 0], [3579, 16, 22539, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [31470, 16, 39749, 9397, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3283, 148, 819, 7, 11, 207, 7, 11, 1982, 5, 7569, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1882, 642, 68, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [345, 2168, 89, 5, 211, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1030, 7, 1190, 7, 965, 5, 79, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [449, 1154, 278, 21, 5, 2046, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [16001, 1534, 21, 5, 7, 5380, 7, 6645, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1963, 99, 5, 175, 17, 5, 3006, 13, 2519, 6, 3430, 358, 16, 9428, 13, 1288, 1335, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [189, 11, 1363, 14233, 471, 21, 5, 358, 99, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [247, 9238, 74, 2243, 5, 682, 38, 89, 5, 68, 21, 5, 910, 1674, 31, 151, 649, 269, 148, 910, 160, 3354, 8, 2771, 11, 3735, 11, 3457, 5, 0], [3293, 89, 5, 112, 21, 5, 22, 566, 5, 434, 665, 31471, 3293, 927, 22, 99, 566, 5, 75, 31, 336, 160, 120, 496, 102, 5, 15, 5, 2677, 0], [1557, 4407, 15, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5984, 2268, 6357, 307, 2268, 22, 77, 2268, 13, 13, 385, 570, 912, 4880, 5, 912, 5, 7, 5, 7293, 12, 2901, 483, 62048, 5, 7, 5, 7725, 12, 0], [1042, 11, 1310, 62049, 21, 5, 7, 1009, 151, 4750, 7, 1009, 11, 2470, 7, 32474, 11, 2470, 7, 144, 844, 11, 2470, 0, 1, 1, 1, 1, 1, 1], [9588, 68, 5, 7, 1445, 7, 515, 18330, 7, 378, 417, 7, 1095, 1510, 417, 5, 7406, 21, 5, 31473, 11122, 160, 1002, 9879, 16, 3531, 1808, 5, 1377, 0], [25462, 89, 5, 79, 21, 5, 1009, 1713, 9, 2756, 6, 279, 5, 4045, 5210, 5, 2968, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1030, 247, 189, 278, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1562, 11858, 9, 2968, 68, 21, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [5067, 40622, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1675, 24, 25, 5, 7, 733, 7, 1087, 7, 1850, 68, 32, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2138, 1013, 7, 772, 7, 1021, 74, 796, 5, 11440, 27, 5, 7, 7, 5, 79, 5, 19, 20, 5, 75, 31, 336, 0, 1, 1, 1, 1, 1, 1], [2482, 963, 19, 20, 112, 32, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1532, 19, 20, 5, 7, 1255, 7, 940, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5867, 4372, 5, 7, 578, 164, 7, 6193, 2894, 5, 79, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2763, 7, 284, 314, 5, 18, 626, 18, 363, 18, 415, 5, 168, 104, 5008, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2253, 80, 20, 5, 524, 32, 5, 7, 306, 7, 362, 7, 2723, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3043, 1816, 1117, 392, 19, 20, 5, 67, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5067, 3007, 19, 20, 235, 32, 5, 520, 184, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2874, 799, 19, 20, 5, 1307, 32, 5, 7, 473, 7, 876, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5885, 3314, 15, 5, 6793, 5, 35, 14, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3621, 799, 19, 20, 5, 117, 32, 5, 7, 473, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]]</td>\n",
       "      <td>[2, 2, 1, 1, 2, 1, 1, 1, 3, 3, 2, 0, 3, 3, 1, 2, 1, 1, 2, 1, 3, 3, 1, 1, 1, 1, 0, 1, 2, 1, 2, 3, 2, 2, 1, 2, 2, 2, 1, 1, 0, 1, 1, 1, 2, 2, 3, 3, 2, 1, 1, 1, 0, 1, 2, 3, 1, 1, 3, 2, 1, 1, 3, 2, 1, 1, 1, 0, 2, 2, 1, 1, 2, 1, 3, 2, 2, 2, 2, 3, 1, 1, 1, 0, 2, 2, 3, 1, 1, 1, 3, 1, 1, 3, 2, 1, 2, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "      <td>91</td>\n",
       "      <td>[[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1038, 491, 1541, 112, 21, 5, 137, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3734, 7, 5, 68, 21, 5, 19094, 5, 2904, 33, 151, 4416, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [9487, 15, 5, 4286, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1791, 120, 44401, 102, 5, 15, 5, 17, 75, 31, 336, 5, 151, 5, 7, 9, 3376, 45, 38, 99, 5, 825, 21, 0, 1, 1, 1, 1, 1, 1], [10912, 250, 50, 5, 16874, 18, 16874, 5, 35, 250, 5, 82, 128, 5, 267, 46, 2199, 147, 41453, 5, 93, 210, 22, 182, 227, 106, 3845, 6, 31, 0], [14167, 168, 104, 7, 3537, 628, 7, 457, 7, 4515, 148, 17238, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1585, 26725, 5, 19, 20, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1038, 2819, 964, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [576, 620, 410, 6, 46763, 410, 16, 34762, 36013, 524, 32, 5, 45, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1042, 11, 1310, 62049, 21, 5, 7, 1009, 151, 4750, 7, 1009, 11, 2470, 7, 32474, 11, 2470, 7, 144, 844, 11, 2470, 0, 1, 1, 1, 1, 1, 1], [2138, 1013, 7, 772, 7, 1021, 74, 796, 5, 11440, 27, 5, 7, 7, 5, 79, 5, 19, 20, 5, 75, 31, 336, 0, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [735, 851, 258, 89, 5, 972, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5067, 40622, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [5867, 4372, 5, 7, 578, 164, 7, 6193, 2894, 5, 79, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2253, 80, 20, 5, 524, 32, 5, 7, 306, 7, 362, 7, 2723, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [46762, 11, 676, 79, 21, 5, 8696, 8, 220, 13, 123, 11, 110, 5, 5156, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [547, 117, 50, 5, 19, 20, 5, 82, 128, 5, 35, 5, 7, 1041, 7, 677, 724, 7, 3872, 3868, 2576, 7, 648, 7, 648, 37, 7, 1940, 5, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3293, 89, 5, 112, 21, 5, 22, 566, 5, 434, 665, 31471, 3293, 927, 22, 99, 566, 5, 75, 31, 336, 160, 120, 496, 102, 5, 15, 5, 2677, 0], [552, 1078, 3076, 105, 21, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3621, 799, 19, 20, 5, 117, 32, 5, 7, 473, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [879, 7, 1131, 7, 272, 965, 7, 3179, 7, 4130, 11, 230, 7, 1131, 165, 38, 7, 4900, 165, 38, 7, 122, 27046, 7, 122, 4900, 5, 19397, 21, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3445, 7, 155, 7, 565, 5, 2135, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2359, 93, 210, 22, 182, 227, 65, 425, 6, 31, 200, 202, 11439, 102, 5, 112, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [629, 641, 7, 6597, 3664, 7, 3262, 4189, 7, 678, 11, 662, 7, 99, 1522, 232, 942, 7, 5156, 7, 10564, 5, 289, 21, 5, 1932, 42, 0, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [5885, 3314, 15, 5, 6793, 5, 35, 14, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1959, 6453, 574, 216, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1084, 7, 5102, 18, 155, 18, 126, 1194, 5, 18, 9, 836, 5, 8069, 21, 5, 7, 724, 5121, 7, 15791, 9343, 7, 7504, 7, 14954, 4204, 7, 5855, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [12124, 11, 228, 112, 21, 5, 22, 1692, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1532, 19, 20, 5, 7, 1255, 7, 940, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [408, 99, 1024, 15, 5, 29, 5, 37, 5, 136, 141, 46, 5612, 13, 1763, 7, 3228, 7, 4673, 7, 6008, 7, 6644, 0, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [1111, 285, 5, 75, 31, 336, 5, 10467, 21, 5, 7, 1149, 504, 21, 7, 1719, 6, 646, 7, 5122, 6, 1486, 0, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1163, 712, 1063, 3313, 2145, 3686, 27, 5, 7, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1562, 11858, 9, 2968, 68, 21, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [50781, 17910, 5, 967, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [932, 11768, 21, 5, 7, 140, 7, 420, 5, 1787, 5, 168, 104, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [37395, 79, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1879, 531, 112, 21, 5, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2766, 54, 1050, 5, 384, 216, 21, 5, 6020, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5067, 3007, 19, 20, 235, 32, 5, 520, 184, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5157, 3302, 5, 5331, 21, 5, 4025, 42, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1243, 514, 552, 1078, 5, 1253, 21, 5, 7, 7988, 7, 2233, 7, 620, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3043, 1816, 1117, 392, 19, 20, 5, 67, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [720, 1282, 3235, 7, 7534, 6646, 5, 380, 720, 108, 1946, 851, 11, 7256, 65, 1721, 33, 1877, 6, 62, 108, 262, 22, 582, 444, 6, 248, 6, 300, 0], [3005, 879, 5, 10794, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4564, 514, 6, 3161, 16, 3498, 2192, 999, 74, 2103, 18, 449, 18, 984, 18, 7, 18, 155, 18, 6725, 2233, 5, 7, 4163, 21, 5, 18, 18, 18, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1587, 3925, 21, 5, 18, 152, 18, 465, 5, 688, 336, 5, 7, 727, 7, 800, 7, 1761, 2026, 7, 189, 9, 518, 7, 2168, 7, 272, 1004, 7, 0], [6463, 6, 2100, 6, 3911, 16, 5446, 232, 331, 3665, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [31470, 16, 39749, 9397, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2482, 963, 19, 20, 112, 32, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1172, 1932, 42, 5, 7, 1516, 7, 665, 1265, 7, 229, 665, 2795, 2779, 7, 6325, 7, 6587, 7, 2510, 5635, 7, 5515, 7, 2999, 2614, 7, 491, 5419, 0], [25462, 89, 5, 79, 21, 5, 1009, 1713, 9, 2756, 6, 279, 5, 4045, 5210, 5, 2968, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1362, 16, 3494, 4462, 34761, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [882, 248, 68, 21, 5, 7, 152, 404, 7, 649, 18, 151, 675, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2634, 9977, 21, 5, 3302, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3772, 3048, 65, 27, 5, 7, 6182, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [544, 7, 5380, 18045, 7, 12625, 18045, 7, 1728, 5258, 7, 37396, 2019, 7, 17613, 7, 506, 10565, 7, 50782, 7, 699, 2019, 7, 699, 4398, 5, 528, 108, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [21862, 990, 19, 20, 16992, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1675, 24, 25, 5, 7, 733, 7, 1087, 7, 1850, 68, 32, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [759, 3054, 5985, 21, 5, 7, 712, 1792, 7, 759, 155, 7, 759, 1362, 7, 2730, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [16001, 1534, 21, 5, 7, 5380, 7, 6645, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1900, 404, 252, 207, 5, 7, 971, 248, 18, 155, 18, 4707, 5, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1557, 4407, 15, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [9588, 68, 5, 7, 1445, 7, 515, 18330, 7, 378, 417, 7, 1095, 1510, 417, 5, 7406, 21, 5, 31473, 11122, 160, 1002, 9879, 16, 3531, 1808, 5, 1377, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [189, 11, 1363, 14233, 471, 21, 5, 358, 99, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1963, 99, 5, 175, 17, 5, 3006, 13, 2519, 6, 3430, 358, 16, 9428, 13, 1288, 1335, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [882, 248, 7, 578, 5, 79, 21, 5, 93, 210, 22, 182, 227, 57, 425, 6, 31, 200, 202, 7012, 102, 5, 75, 31, 336, 160, 0, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [129, 1269, 416, 13535, 692, 5, 29, 5, 2689, 62, 33, 1480, 160, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [463, 7, 5, 3329, 21, 5, 7, 3292, 7, 25769, 7, 25770, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2763, 7, 284, 314, 5, 18, 626, 18, 363, 18, 415, 5, 168, 104, 5008, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [7987, 401, 964, 32, 5, 1932, 42, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1882, 642, 68, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1172, 7, 12675, 7, 1878, 29642, 7, 1878, 14856, 5, 278, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [463, 125, 5, 66, 21, 5, 11121, 1190, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [856, 30, 17, 5, 840, 2608, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1296, 66, 21, 5, 11, 230, 5, 7, 393, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [2621, 13403, 21, 5, 7, 3828, 2621, 7, 11914, 2621, 5, 629, 641, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1704, 705, 5, 105, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2874, 799, 19, 20, 5, 1307, 32, 5, 7, 473, 7, 876, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [1030, 247, 189, 278, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [5984, 2268, 6357, 307, 2268, 22, 77, 2268, 13, 13, 385, 570, 912, 4880, 5, 912, 5, 7, 5, 7293, 12, 2901, 483, 62048, 5, 7, 5, 7725, 12, 0], [449, 1154, 278, 21, 5, 2046, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [247, 9238, 74, 2243, 5, 682, 38, 89, 5, 68, 21, 5, 910, 1674, 31, 151, 649, 269, 148, 910, 160, 3354, 8, 2771, 11, 3735, 11, 3457, 5, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [821, 3687, 21, 5, 579, 5, 137, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1030, 7, 1190, 7, 965, 5, 79, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3283, 148, 819, 7, 11, 207, 7, 11, 1982, 5, 7569, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3579, 16, 22539, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1016, 1044, 35, 29, 5, 7, 290, 7, 457, 7, 2327, 5, 863, 5, 15, 5, 305, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [5259, 1180, 68, 32, 5, 7, 862, 7, 328, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [345, 2168, 89, 5, 211, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18785, 118, 21, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5353, 20580, 38, 5, 79, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]</td>\n",
       "      <td>[14, 71, 78, 75, 116, 16, 79, 121, 148, 101, 49, 174, 13, 53, 62, 155, 65, 159, 167, 6, 94, 114, 18, 120, 32, 12, 166, 150, 44, 165, 183, 63, 198, 8, 98, 23, 84, 151, 192, 163, 72, 15, 47, 189, 129, 99, 97, 73, 34, 117, 125, 135, 38, 19, 95, 164, 83, 92, 102, 37, 170, 199, 122, 188, 112, 186, 157, 138, 195, 184, 179, 132, 145, 144, 181, 36, 141, 178, 20, 142, 115, 175, 77, 130, 24, 128, 21, 113, 70, 27, 152, 29, 96, 93, 173, 60, 42, 86, 194, 30, 39, 68, 57, 131, 5, 127, 22, 76, 59, 197, 149, 11, 52, 74, 111, 168, 26, 182, 3, 106, 46, 104, 140, 169, 119, 162, 35, 118, 45, 51, 193, 9, 156, 103, 90, 160, 58, 81, 67, 196, 143, 133, 134, 85, 82, 69, 43, 1, 107, 137, 66, 177, 91, 124, 108, 180, 61, 54, 7, 41, 50, 87, 33, 28, 89, 64, 154, 158, 17, 0, 187, 40, 126, 190, 185, 191, 147, 172, 80, 139, 171, 100, 31, 56, 153, 2, 109, 4, 176, 161, 136, 123, 48, 55, 10, 88, 146, 105, 25, 110]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  catalog_id                                                                                  section_ids                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             offer_ids_with_pb                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  offer_vectors_with_pb                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        offer_priorities_with_pb  num_offers                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      x                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           y\n",
       "0  0003leq    {'0003leq_1', '0003leq_2', '0003leq_4', '0003leq_6', '0003leq_3', '0003leq_5', '0003leq_7'}  ['fed3AqfY', '799dzqfY', 'b8a3DqfY', 'a4c88qfY', '3cf8qqfY', '88a5UqfY', '6d6e0qfY', 'ef59YqfY', 'ab38CqfY', '0cbffqfY', '0a4eEqfY', '?PAGE_BREAK?', '0ef3QqfY', 'a3abpqfY', 'ce94wqfY', 'e545VqfY', '11aaxqfY', 'e4e12qfY', '431baqfY', '3030ZqfY', 'db3fNqfY', 'd638dqfY', '539csqfY', 'b25flqfY', '18cdFqfY', '50b5vqfY', '?PAGE_BREAK?', 'db9dGqfY', '4daaRqfY', 'bd0fXqfY', '9937SqfY', 'a3ddnqfY', '59cchqfY', 'd8f9oqfY', '0be3HqfY', 'b3acOqfY', 'aeberqfY', '44a2IqfY', '708e7qfY', 'f4f4MqfY', '?PAGE_BREAK?', '2502x0fY', '070eU0fY', 'a6a7Z0fY', '183cY0fY', '257as0fY', '0da4f0fY', '4809E0fY', '4815F0fY', 'f1a9z0fY', '3672p0fY', '283c80fY', '?PAGE_BREAK?', '29c0BqfY', '9381iqfY', '907ajqfY', '28d5kqfY', '280auqfY', '00b64qfY', '1864JqfY', 'e2835qfY', '7c1eeqfY', '067bTqfY', '46df6qfY', 'b84a9qfY', '614ebqfY', '11bbPqfY', '?PAGE_BREAK?', 'b553q0fY', '36f3y0fY', '222fcqfY', '5cb900fY', '7d7a10fY', '97f9K0fY', 'fc78C0fY', 'c90d30fY', '5b2ag0fY', 'c941A0fY', 'a259L0fY', '6429tqfY', 'a5caD0fY', '08cfm0fY', '22edWqfY', '?PAGE_BREAK?', 'b7fcb0fY', 'd4f0v0fY', 'fb3cQ0fY', '0ba1i0fY', 'a367w0fY', 'ac74V0fY', '3531u0fY', 'fbff20fY', 'e4b8a0fY', '3956N0fY', '0d81d0fY', '029aT0fY', '5dbdl0fY', '?PAGE_BREAK?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?']  [[10912, 250, 50, 5, 16874, 18, 16874, 5, 35, 250, 5, 82, 128, 5, 267, 46, 2199, 147, 41453, 5, 93, 210, 22, 182, 227, 106, 3845, 6, 31, 0], [408, 99, 1024, 15, 5, 29, 5, 37, 5, 136, 141, 46, 5612, 13, 1763, 7, 3228, 7, 4673, 7, 6008, 7, 6644, 0, 1, 1, 1, 1, 1, 1], [50781, 17910, 5, 967, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1163, 712, 1063, 3313, 2145, 3686, 27, 5, 7, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1362, 16, 3494, 4462, 34761, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1585, 26725, 5, 19, 20, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [932, 11768, 21, 5, 7, 140, 7, 420, 5, 1787, 5, 168, 104, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3772, 3048, 65, 27, 5, 7, 6182, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [882, 248, 7, 578, 5, 79, 21, 5, 93, 210, 22, 182, 227, 57, 425, 6, 31, 200, 202, 7012, 102, 5, 75, 31, 336, 160, 0, 1, 1, 1], [1587, 3925, 21, 5, 18, 152, 18, 465, 5, 688, 336, 5, 7, 727, 7, 800, 7, 1761, 2026, 7, 189, 9, 518, 7, 2168, 7, 272, 1004, 7, 0], [2359, 93, 210, 22, 182, 227, 65, 425, 6, 31, 200, 202, 11439, 102, 5, 112, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [1791, 120, 44401, 102, 5, 15, 5, 17, 75, 31, 336, 5, 151, 5, 7, 9, 3376, 45, 38, 99, 5, 825, 21, 0, 1, 1, 1, 1, 1, 1], [629, 641, 7, 6597, 3664, 7, 3262, 4189, 7, 678, 11, 662, 7, 99, 1522, 232, 942, 7, 5156, 7, 10564, 5, 289, 21, 5, 1932, 42, 0, 1, 1], [1959, 6453, 574, 216, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [7987, 401, 964, 32, 5, 1932, 42, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [12124, 11, 228, 112, 21, 5, 22, 1692, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1172, 7, 12675, 7, 1878, 29642, 7, 1878, 14856, 5, 278, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2621, 13403, 21, 5, 7, 3828, 2621, 7, 11914, 2621, 5, 629, 641, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1038, 491, 1541, 112, 21, 5, 137, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5157, 3302, 5, 5331, 21, 5, 4025, 42, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1172, 1932, 42, 5, 7, 1516, 7, 665, 1265, 7, 229, 665, 2795, 2779, 7, 6325, 7, 6587, 7, 2510, 5635, 7, 5515, 7, 2999, 2614, 7, 491, 5419, 0], [1038, 2819, 964, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2634, 9977, 21, 5, 3302, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [46762, 11, 676, 79, 21, 5, 8696, 8, 220, 13, 123, 11, 110, 5, 5156, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [9487, 15, 5, 4286, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [129, 1269, 416, 13535, 692, 5, 29, 5, 2689, 62, 33, 1480, 160, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [879, 7, 1131, 7, 272, 965, 7, 3179, 7, 4130, 11, 230, 7, 1131, 165, 38, 7, 4900, 165, 38, 7, 122, 27046, 7, 122, 4900, 5, 19397, 21, 0], [1296, 66, 21, 5, 11, 230, 5, 7, 393, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [821, 3687, 21, 5, 579, 5, 137, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1084, 7, 5102, 18, 155, 18, 126, 1194, 5, 18, 9, 836, 5, 8069, 21, 5, 7, 724, 5121, 7, 15791, 9343, 7, 7504, 7, 14954, 4204, 7, 5855, 0], [18785, 118, 21, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3734, 7, 5, 68, 21, 5, 19094, 5, 2904, 33, 151, 4416, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3005, 879, 5, 10794, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [735, 851, 258, 89, 5, 972, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1879, 531, 112, 21, 5, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [463, 7, 5, 3329, 21, 5, 7, 3292, 7, 25769, 7, 25770, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5259, 1180, 68, 32, 5, 7, 862, 7, 328, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [463, 125, 5, 66, 21, 5, 11121, 1190, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [14167, 168, 104, 7, 3537, 628, 7, 457, 7, 4515, 148, 17238, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3445, 7, 155, 7, 565, 5, 2135, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1016, 1044, 35, 29, 5, 7, 290, 7, 457, 7, 2327, 5, 863, 5, 15, 5, 305, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [759, 3054, 5985, 21, 5, 7, 712, 1792, 7, 759, 155, 7, 759, 1362, 7, 2730, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4564, 514, 6, 3161, 16, 3498, 2192, 999, 74, 2103, 18, 449, 18, 984, 18, 7, 18, 155, 18, 6725, 2233, 5, 7, 4163, 21, 5, 18, 18, 18, 0], [720, 1282, 3235, 7, 7534, 6646, 5, 380, 720, 108, 1946, 851, 11, 7256, 65, 1721, 33, 1877, 6, 62, 108, 262, 22, 582, 444, 6, 248, 6, 300, 0], [1111, 285, 5, 75, 31, 336, 5, 10467, 21, 5, 7, 1149, 504, 21, 7, 1719, 6, 646, 7, 5122, 6, 1486, 0, 1, 1, 1, 1, 1, 1, 1], [547, 117, 50, 5, 19, 20, 5, 82, 128, 5, 35, 5, 7, 1041, 7, 677, 724, 7, 3872, 3868, 2576, 7, 648, 7, 648, 37, 7, 1940, 5, 0], [882, 248, 68, 21, 5, 7, 152, 404, 7, 649, 18, 151, 675, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [21862, 990, 19, 20, 16992, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1900, 404, 252, 207, 5, 7, 971, 248, 18, 155, 18, 4707, 5, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [576, 620, 410, 6, 46763, 410, 16, 34762, 36013, 524, 32, 5, 45, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1243, 514, 552, 1078, 5, 1253, 21, 5, 7, 7988, 7, 2233, 7, 620, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [856, 30, 17, 5, 840, 2608, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [37395, 79, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2766, 54, 1050, 5, 384, 216, 21, 5, 6020, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [6463, 6, 2100, 6, 3911, 16, 5446, 232, 331, 3665, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [552, 1078, 3076, 105, 21, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1704, 705, 5, 105, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5353, 20580, 38, 5, 79, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [544, 7, 5380, 18045, 7, 12625, 18045, 7, 1728, 5258, 7, 37396, 2019, 7, 17613, 7, 506, 10565, 7, 50782, 7, 699, 2019, 7, 699, 4398, 5, 528, 108, 0], [3579, 16, 22539, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [31470, 16, 39749, 9397, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3283, 148, 819, 7, 11, 207, 7, 11, 1982, 5, 7569, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1882, 642, 68, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [345, 2168, 89, 5, 211, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1030, 7, 1190, 7, 965, 5, 79, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [449, 1154, 278, 21, 5, 2046, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [16001, 1534, 21, 5, 7, 5380, 7, 6645, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1963, 99, 5, 175, 17, 5, 3006, 13, 2519, 6, 3430, 358, 16, 9428, 13, 1288, 1335, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [189, 11, 1363, 14233, 471, 21, 5, 358, 99, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [247, 9238, 74, 2243, 5, 682, 38, 89, 5, 68, 21, 5, 910, 1674, 31, 151, 649, 269, 148, 910, 160, 3354, 8, 2771, 11, 3735, 11, 3457, 5, 0], [3293, 89, 5, 112, 21, 5, 22, 566, 5, 434, 665, 31471, 3293, 927, 22, 99, 566, 5, 75, 31, 336, 160, 120, 496, 102, 5, 15, 5, 2677, 0], [1557, 4407, 15, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5984, 2268, 6357, 307, 2268, 22, 77, 2268, 13, 13, 385, 570, 912, 4880, 5, 912, 5, 7, 5, 7293, 12, 2901, 483, 62048, 5, 7, 5, 7725, 12, 0], [1042, 11, 1310, 62049, 21, 5, 7, 1009, 151, 4750, 7, 1009, 11, 2470, 7, 32474, 11, 2470, 7, 144, 844, 11, 2470, 0, 1, 1, 1, 1, 1, 1], [9588, 68, 5, 7, 1445, 7, 515, 18330, 7, 378, 417, 7, 1095, 1510, 417, 5, 7406, 21, 5, 31473, 11122, 160, 1002, 9879, 16, 3531, 1808, 5, 1377, 0], [25462, 89, 5, 79, 21, 5, 1009, 1713, 9, 2756, 6, 279, 5, 4045, 5210, 5, 2968, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1030, 247, 189, 278, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1562, 11858, 9, 2968, 68, 21, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [5067, 40622, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1675, 24, 25, 5, 7, 733, 7, 1087, 7, 1850, 68, 32, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2138, 1013, 7, 772, 7, 1021, 74, 796, 5, 11440, 27, 5, 7, 7, 5, 79, 5, 19, 20, 5, 75, 31, 336, 0, 1, 1, 1, 1, 1, 1], [2482, 963, 19, 20, 112, 32, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1532, 19, 20, 5, 7, 1255, 7, 940, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5867, 4372, 5, 7, 578, 164, 7, 6193, 2894, 5, 79, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2763, 7, 284, 314, 5, 18, 626, 18, 363, 18, 415, 5, 168, 104, 5008, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2253, 80, 20, 5, 524, 32, 5, 7, 306, 7, 362, 7, 2723, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3043, 1816, 1117, 392, 19, 20, 5, 67, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5067, 3007, 19, 20, 235, 32, 5, 520, 184, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2874, 799, 19, 20, 5, 1307, 32, 5, 7, 473, 7, 876, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5885, 3314, 15, 5, 6793, 5, 35, 14, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3621, 799, 19, 20, 5, 117, 32, 5, 7, 473, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]]  [2, 2, 1, 1, 2, 1, 1, 1, 3, 3, 2, 0, 3, 3, 1, 2, 1, 1, 2, 1, 3, 3, 1, 1, 1, 1, 0, 1, 2, 1, 2, 3, 2, 2, 1, 2, 2, 2, 1, 1, 0, 1, 1, 1, 2, 2, 3, 3, 2, 1, 1, 1, 0, 1, 2, 3, 1, 1, 3, 2, 1, 1, 3, 2, 1, 1, 1, 0, 2, 2, 1, 1, 2, 1, 3, 2, 2, 2, 2, 3, 1, 1, 1, 0, 2, 2, 3, 1, 1, 1, 3, 1, 1, 3, 2, 1, 2, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  91          [[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1038, 491, 1541, 112, 21, 5, 137, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3734, 7, 5, 68, 21, 5, 19094, 5, 2904, 33, 151, 4416, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [9487, 15, 5, 4286, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1791, 120, 44401, 102, 5, 15, 5, 17, 75, 31, 336, 5, 151, 5, 7, 9, 3376, 45, 38, 99, 5, 825, 21, 0, 1, 1, 1, 1, 1, 1], [10912, 250, 50, 5, 16874, 18, 16874, 5, 35, 250, 5, 82, 128, 5, 267, 46, 2199, 147, 41453, 5, 93, 210, 22, 182, 227, 106, 3845, 6, 31, 0], [14167, 168, 104, 7, 3537, 628, 7, 457, 7, 4515, 148, 17238, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1585, 26725, 5, 19, 20, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1038, 2819, 964, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [576, 620, 410, 6, 46763, 410, 16, 34762, 36013, 524, 32, 5, 45, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1042, 11, 1310, 62049, 21, 5, 7, 1009, 151, 4750, 7, 1009, 11, 2470, 7, 32474, 11, 2470, 7, 144, 844, 11, 2470, 0, 1, 1, 1, 1, 1, 1], [2138, 1013, 7, 772, 7, 1021, 74, 796, 5, 11440, 27, 5, 7, 7, 5, 79, 5, 19, 20, 5, 75, 31, 336, 0, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [735, 851, 258, 89, 5, 972, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5067, 40622, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [5867, 4372, 5, 7, 578, 164, 7, 6193, 2894, 5, 79, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2253, 80, 20, 5, 524, 32, 5, 7, 306, 7, 362, 7, 2723, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [46762, 11, 676, 79, 21, 5, 8696, 8, 220, 13, 123, 11, 110, 5, 5156, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [547, 117, 50, 5, 19, 20, 5, 82, 128, 5, 35, 5, 7, 1041, 7, 677, 724, 7, 3872, 3868, 2576, 7, 648, 7, 648, 37, 7, 1940, 5, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3293, 89, 5, 112, 21, 5, 22, 566, 5, 434, 665, 31471, 3293, 927, 22, 99, 566, 5, 75, 31, 336, 160, 120, 496, 102, 5, 15, 5, 2677, 0], [552, 1078, 3076, 105, 21, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3621, 799, 19, 20, 5, 117, 32, 5, 7, 473, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [879, 7, 1131, 7, 272, 965, 7, 3179, 7, 4130, 11, 230, 7, 1131, 165, 38, 7, 4900, 165, 38, 7, 122, 27046, 7, 122, 4900, 5, 19397, 21, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3445, 7, 155, 7, 565, 5, 2135, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2359, 93, 210, 22, 182, 227, 65, 425, 6, 31, 200, 202, 11439, 102, 5, 112, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [629, 641, 7, 6597, 3664, 7, 3262, 4189, 7, 678, 11, 662, 7, 99, 1522, 232, 942, 7, 5156, 7, 10564, 5, 289, 21, 5, 1932, 42, 0, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [5885, 3314, 15, 5, 6793, 5, 35, 14, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1959, 6453, 574, 216, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1084, 7, 5102, 18, 155, 18, 126, 1194, 5, 18, 9, 836, 5, 8069, 21, 5, 7, 724, 5121, 7, 15791, 9343, 7, 7504, 7, 14954, 4204, 7, 5855, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [12124, 11, 228, 112, 21, 5, 22, 1692, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1532, 19, 20, 5, 7, 1255, 7, 940, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [408, 99, 1024, 15, 5, 29, 5, 37, 5, 136, 141, 46, 5612, 13, 1763, 7, 3228, 7, 4673, 7, 6008, 7, 6644, 0, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [1111, 285, 5, 75, 31, 336, 5, 10467, 21, 5, 7, 1149, 504, 21, 7, 1719, 6, 646, 7, 5122, 6, 1486, 0, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1163, 712, 1063, 3313, 2145, 3686, 27, 5, 7, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1562, 11858, 9, 2968, 68, 21, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [50781, 17910, 5, 967, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [932, 11768, 21, 5, 7, 140, 7, 420, 5, 1787, 5, 168, 104, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [37395, 79, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1879, 531, 112, 21, 5, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2766, 54, 1050, 5, 384, 216, 21, 5, 6020, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5067, 3007, 19, 20, 235, 32, 5, 520, 184, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5157, 3302, 5, 5331, 21, 5, 4025, 42, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1243, 514, 552, 1078, 5, 1253, 21, 5, 7, 7988, 7, 2233, 7, 620, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3043, 1816, 1117, 392, 19, 20, 5, 67, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [720, 1282, 3235, 7, 7534, 6646, 5, 380, 720, 108, 1946, 851, 11, 7256, 65, 1721, 33, 1877, 6, 62, 108, 262, 22, 582, 444, 6, 248, 6, 300, 0], [3005, 879, 5, 10794, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4564, 514, 6, 3161, 16, 3498, 2192, 999, 74, 2103, 18, 449, 18, 984, 18, 7, 18, 155, 18, 6725, 2233, 5, 7, 4163, 21, 5, 18, 18, 18, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1587, 3925, 21, 5, 18, 152, 18, 465, 5, 688, 336, 5, 7, 727, 7, 800, 7, 1761, 2026, 7, 189, 9, 518, 7, 2168, 7, 272, 1004, 7, 0], [6463, 6, 2100, 6, 3911, 16, 5446, 232, 331, 3665, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [31470, 16, 39749, 9397, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2482, 963, 19, 20, 112, 32, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1172, 1932, 42, 5, 7, 1516, 7, 665, 1265, 7, 229, 665, 2795, 2779, 7, 6325, 7, 6587, 7, 2510, 5635, 7, 5515, 7, 2999, 2614, 7, 491, 5419, 0], [25462, 89, 5, 79, 21, 5, 1009, 1713, 9, 2756, 6, 279, 5, 4045, 5210, 5, 2968, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1362, 16, 3494, 4462, 34761, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [882, 248, 68, 21, 5, 7, 152, 404, 7, 649, 18, 151, 675, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2634, 9977, 21, 5, 3302, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3772, 3048, 65, 27, 5, 7, 6182, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [544, 7, 5380, 18045, 7, 12625, 18045, 7, 1728, 5258, 7, 37396, 2019, 7, 17613, 7, 506, 10565, 7, 50782, 7, 699, 2019, 7, 699, 4398, 5, 528, 108, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [21862, 990, 19, 20, 16992, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1675, 24, 25, 5, 7, 733, 7, 1087, 7, 1850, 68, 32, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [759, 3054, 5985, 21, 5, 7, 712, 1792, 7, 759, 155, 7, 759, 1362, 7, 2730, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [16001, 1534, 21, 5, 7, 5380, 7, 6645, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1900, 404, 252, 207, 5, 7, 971, 248, 18, 155, 18, 4707, 5, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1557, 4407, 15, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [9588, 68, 5, 7, 1445, 7, 515, 18330, 7, 378, 417, 7, 1095, 1510, 417, 5, 7406, 21, 5, 31473, 11122, 160, 1002, 9879, 16, 3531, 1808, 5, 1377, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [189, 11, 1363, 14233, 471, 21, 5, 358, 99, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1963, 99, 5, 175, 17, 5, 3006, 13, 2519, 6, 3430, 358, 16, 9428, 13, 1288, 1335, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [882, 248, 7, 578, 5, 79, 21, 5, 93, 210, 22, 182, 227, 57, 425, 6, 31, 200, 202, 7012, 102, 5, 75, 31, 336, 160, 0, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [129, 1269, 416, 13535, 692, 5, 29, 5, 2689, 62, 33, 1480, 160, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [463, 7, 5, 3329, 21, 5, 7, 3292, 7, 25769, 7, 25770, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2763, 7, 284, 314, 5, 18, 626, 18, 363, 18, 415, 5, 168, 104, 5008, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [7987, 401, 964, 32, 5, 1932, 42, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1882, 642, 68, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1172, 7, 12675, 7, 1878, 29642, 7, 1878, 14856, 5, 278, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [463, 125, 5, 66, 21, 5, 11121, 1190, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [856, 30, 17, 5, 840, 2608, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1296, 66, 21, 5, 11, 230, 5, 7, 393, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [2621, 13403, 21, 5, 7, 3828, 2621, 7, 11914, 2621, 5, 629, 641, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1704, 705, 5, 105, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2874, 799, 19, 20, 5, 1307, 32, 5, 7, 473, 7, 876, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [1030, 247, 189, 278, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [5984, 2268, 6357, 307, 2268, 22, 77, 2268, 13, 13, 385, 570, 912, 4880, 5, 912, 5, 7, 5, 7293, 12, 2901, 483, 62048, 5, 7, 5, 7725, 12, 0], [449, 1154, 278, 21, 5, 2046, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [247, 9238, 74, 2243, 5, 682, 38, 89, 5, 68, 21, 5, 910, 1674, 31, 151, 649, 269, 148, 910, 160, 3354, 8, 2771, 11, 3735, 11, 3457, 5, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [821, 3687, 21, 5, 579, 5, 137, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1030, 7, 1190, 7, 965, 5, 79, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3283, 148, 819, 7, 11, 207, 7, 11, 1982, 5, 7569, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3579, 16, 22539, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1016, 1044, 35, 29, 5, 7, 290, 7, 457, 7, 2327, 5, 863, 5, 15, 5, 305, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [5259, 1180, 68, 32, 5, 7, 862, 7, 328, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [345, 2168, 89, 5, 211, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18785, 118, 21, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5353, 20580, 38, 5, 79, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]  [14, 71, 78, 75, 116, 16, 79, 121, 148, 101, 49, 174, 13, 53, 62, 155, 65, 159, 167, 6, 94, 114, 18, 120, 32, 12, 166, 150, 44, 165, 183, 63, 198, 8, 98, 23, 84, 151, 192, 163, 72, 15, 47, 189, 129, 99, 97, 73, 34, 117, 125, 135, 38, 19, 95, 164, 83, 92, 102, 37, 170, 199, 122, 188, 112, 186, 157, 138, 195, 184, 179, 132, 145, 144, 181, 36, 141, 178, 20, 142, 115, 175, 77, 130, 24, 128, 21, 113, 70, 27, 152, 29, 96, 93, 173, 60, 42, 86, 194, 30, 39, 68, 57, 131, 5, 127, 22, 76, 59, 197, 149, 11, 52, 74, 111, 168, 26, 182, 3, 106, 46, 104, 140, 169, 119, 162, 35, 118, 45, 51, 193, 9, 156, 103, 90, 160, 58, 81, 67, 196, 143, 133, 134, 85, 82, 69, 43, 1, 107, 137, 66, 177, 91, 124, 108, 180, 61, 54, 7, 41, 50, 87, 33, 28, 89, 64, 154, 158, 17, 0, 187, 40, 126, 190, 185, 191, 147, 172, 80, 139, 171, 100, 31, 56, 153, 2, 109, 4, 176, 161, 136, 123, 48, 55, 10, 88, 146, 105, 25, 110]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_catalogs = pd.read_csv(config['path_in_df_catalog_csv'], sep=';')\n",
    "df_catalogs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11063"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_catalogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload feature csv's split into train and test\n",
    "df_catalogs_train = pd.read_csv(config['path_in_df_catalog_train_csv'], sep=';')\n",
    "# df_catalogs_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_catalogs_test = pd.read_csv(config['path_in_df_catalog_test_csv'], sep=';')\n",
    "# df_catalogs_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8850, 2212)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_catalogs_train), len(df_catalogs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Meta Resources (dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?EOS?', 0),\n",
       " ('?PAD?', 1),\n",
       " ('?UNK?', 2),\n",
       " ('?PAGE_BREAK?', 3),\n",
       " ('?NOT_REAL_OFFER?', 4)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read word2idx dictionary\n",
    "with open(config['path_in_dictionary'], 'rb') as f:\n",
    "    word2idx = pickle.load(f)\n",
    "list(word2idx.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0003leq', {'0003leq_5', '0003leq_3', '0003leq_4', '0003leq_1', '0003leq_6', '0003leq_2', '0003leq_7'}), ('0007YiY', {'0007YiY_5', '0007YiY_14', '0007YiY_1', '0007YiY_11', '0007YiY_12', '0007YiY_16', '0007YiY_3', '0007YiY_2', '0007YiY_9', '0007YiY_15', '0007YiY_6', '0007YiY_7', '0007YiY_10', '0007YiY_13', '0007YiY_4', '0007YiY_8'})]\n"
     ]
    }
   ],
   "source": [
    "# read catalog id to section ids\n",
    "with open(config['path_in_catalog_id_to_section_ids'], 'rb') as f:\n",
    "    catalog_id_to_section_ids = pickle.load(f)\n",
    "print(list(catalog_id_to_section_ids.items())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0003leq_1', ['fed3AqfY', '799dzqfY', 'b8a3DqfY', 'a4c88qfY', '3cf8qqfY', '88a5UqfY', '6d6e0qfY', 'ef59YqfY', 'ab38CqfY', '0cbffqfY', '0a4eEqfY']), ('0003leq_2', ['0ef3QqfY', 'a3abpqfY', 'ce94wqfY', 'e545VqfY', '11aaxqfY', 'e4e12qfY', '431baqfY', '3030ZqfY', 'db3fNqfY', 'd638dqfY', '539csqfY', 'b25flqfY', '18cdFqfY', '50b5vqfY'])]\n"
     ]
    }
   ],
   "source": [
    "# read section maps\n",
    "with open(config['path_in_section_id_to_offer_ids'], 'rb') as f:\n",
    "    section_id_to_offer_ids = pickle.load(f)\n",
    "print(list(section_id_to_offer_ids.items())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0003leq_1', [[10912, 250, 50, 5, 16874, 18, 16874, 5, 35, 250, 5, 82, 128, 5, 267, 46, 2199, 147, 41453, 5, 93, 210, 22, 182, 227, 106, 3845, 6, 31, 0], [408, 99, 1024, 15, 5, 29, 5, 37, 5, 136, 141, 46, 5612, 13, 1763, 7, 3228, 7, 4673, 7, 6008, 7, 6644, 0, 1, 1, 1, 1, 1, 1], [50781, 17910, 5, 967, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1163, 712, 1063, 3313, 2145, 3686, 27, 5, 7, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1362, 16, 3494, 4462, 34761, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1585, 26725, 5, 19, 20, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [932, 11768, 21, 5, 7, 140, 7, 420, 5, 1787, 5, 168, 104, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3772, 3048, 65, 27, 5, 7, 6182, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [882, 248, 7, 578, 5, 79, 21, 5, 93, 210, 22, 182, 227, 57, 425, 6, 31, 200, 202, 7012, 102, 5, 75, 31, 336, 160, 0, 1, 1, 1], [1587, 3925, 21, 5, 18, 152, 18, 465, 5, 688, 336, 5, 7, 727, 7, 800, 7, 1761, 2026, 7, 189, 9, 518, 7, 2168, 7, 272, 1004, 7, 0], [2359, 93, 210, 22, 182, 227, 65, 425, 6, 31, 200, 202, 11439, 102, 5, 112, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "with open(config['path_in_section_id_to_offer_vectors'], 'rb') as f:\n",
    "    section_id_to_offers_as_vectors = pickle.load(f)\n",
    "print(list(section_id_to_offers_as_vectors.items())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0003leq_1', 1), ('0003leq_2', 2), ('0003leq_3', 3), ('0003leq_4', 4), ('0003leq_5', 5)]\n"
     ]
    }
   ],
   "source": [
    "with open(config['path_in_section_id_to_section_num'], 'rb') as f:\n",
    "    section_id_to_section_num = pickle.load(f)\n",
    "print(list(section_id_to_section_num.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0003leq_1', [2, 2, 1, 1, 2, 1, 1, 1, 3, 3, 2]), ('0003leq_2', [3, 3, 1, 2, 1, 1, 2, 1, 3, 3, 1, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "with open(config['path_in_section_id_to_offer_priorities'], 'rb') as f:\n",
    "    section_ids_to_offers_as_priorities = pickle.load(f)\n",
    "print(list(section_ids_to_offers_as_priorities.items())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('fed3AqfY', 2), ('799dzqfY', 2)]\n"
     ]
    }
   ],
   "source": [
    "# read offer maps\n",
    "with open(config['path_in_offer_id_to_priority'], 'rb') as f:\n",
    "    offer_id_to_priority = pickle.load(f)\n",
    "print(list(offer_id_to_priority.items())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('fed3AqfY', [10912, 250, 50, 5, 16874, 18, 16874, 5, 35, 250, 5, 82, 128, 5, 267, 46, 2199, 147, 41453, 5, 93, 210, 22, 182, 227, 106, 3845, 6, 31, 0]), ('799dzqfY', [408, 99, 1024, 15, 5, 29, 5, 37, 5, 136, 141, 46, 5612, 13, 1763, 7, 3228, 7, 4673, 7, 6008, 7, 6644, 0, 1, 1, 1, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "with open(config['path_in_offer_id_to_vector'], 'rb') as f:\n",
    "    offer_id_to_vector = pickle.load(f)\n",
    "print(list(offer_id_to_vector.items())[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Numpy Matrices (X & Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8850, 200, 30),\n",
       " (8850, 200),\n",
       " array([[    4,     4,     4, ...,     4,     4,     4],\n",
       "        [    4,     4,     4, ...,     4,     4,     4],\n",
       "        [    4,     4,     4, ...,     4,     4,     4],\n",
       "        ...,\n",
       "        [    4,     4,     4, ...,     4,     4,     4],\n",
       "        [18785,   118,    21, ...,     1,     1,     1],\n",
       "        [ 5353, 20580,    38, ...,     1,     1,     1]], dtype=int32),\n",
       " array([ 14,  71,  78,  75, 116,  16,  79, 121, 148, 101,  49, 174,  13,\n",
       "         53,  62, 155,  65, 159, 167,   6,  94, 114,  18, 120,  32,  12,\n",
       "        166, 150,  44, 165, 183,  63, 198,   8,  98,  23,  84, 151, 192,\n",
       "        163,  72,  15,  47, 189, 129,  99,  97,  73,  34, 117, 125, 135,\n",
       "         38,  19,  95, 164,  83,  92, 102,  37, 170, 199, 122, 188, 112,\n",
       "        186, 157, 138, 195, 184, 179, 132, 145, 144, 181,  36, 141, 178,\n",
       "         20, 142, 115, 175,  77, 130,  24, 128,  21, 113,  70,  27, 152,\n",
       "         29,  96,  93, 173,  60,  42,  86, 194,  30,  39,  68,  57, 131,\n",
       "          5, 127,  22,  76,  59, 197, 149,  11,  52,  74, 111, 168,  26,\n",
       "        182,   3, 106,  46, 104, 140, 169, 119, 162,  35, 118,  45,  51,\n",
       "        193,   9, 156, 103,  90, 160,  58,  81,  67, 196, 143, 133, 134,\n",
       "         85,  82,  69,  43,   1, 107, 137,  66, 177,  91, 124, 108, 180,\n",
       "         61,  54,   7,  41,  50,  87,  33,  28,  89,  64, 154, 158,  17,\n",
       "          0, 187,  40, 126, 190, 185, 191, 147, 172,  80, 139, 171, 100,\n",
       "         31,  56, 153,   2, 109,   4, 176, 161, 136, 123,  48,  55,  10,\n",
       "         88, 146, 105,  25, 110], dtype=int32))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set\n",
    "X_train = np.load(config['path_in_np_X_train'])\n",
    "Y_train = np.load(config['path_in_np_Y_train'])\n",
    "X_train.shape, Y_train.shape, X_train[0], Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2212, 200, 30),\n",
       " (2212, 200),\n",
       " array([[    4,     4,     4, ...,     4,     4,     4],\n",
       "        [ 7090,    68,    21, ...,     1,     1,     1],\n",
       "        [ 3487, 10083,     7, ...,     1,     1,     1],\n",
       "        ...,\n",
       "        [ 5873,  4054,  1274, ...,     1,     1,     1],\n",
       "        [    4,     4,     4, ...,     4,     4,     4],\n",
       "        [  552,  2849,  2494, ...,     1,     1,     1]], dtype=int32),\n",
       " array([169,  22,  51,  88,  63,  42, 152,   7, 188,  66, 196, 111, 109,\n",
       "        155, 133, 162,  61, 117, 142, 192, 105, 166, 137, 181,   1,  21,\n",
       "        106, 160,  43,  73,  40, 178, 146, 173,   2, 161,  45, 129, 197,\n",
       "        112, 123, 118, 104, 145,  38, 186, 195,  56,   3,  24,  41,  78,\n",
       "         86, 141,  54,  28, 115, 150, 187, 107,  33, 148,  60,  25,  70,\n",
       "        135, 134,   5,   9,  10,  59,  46, 154,  72, 132, 127,  18,  92,\n",
       "         31, 103,  67,  36,  87, 126,  71,  50,  65, 124, 171,   6, 114,\n",
       "        102,  27, 138,  32, 101, 185,  53,  95,  16, 147,  99,  94, 139,\n",
       "        158, 156, 119,  39,  17,  52, 182, 199,  80, 176, 174,  14, 163,\n",
       "        175, 157,  12, 113,  26,  35, 130,  79, 180, 131,  37, 140,  75,\n",
       "         68, 198, 159,  91,  84, 170, 144,  11, 121,  55,  90,  15,  96,\n",
       "        164, 143,  82, 172,  89,  29,  83,  64,  97,  57,  20,   0, 167,\n",
       "        120, 110,  93, 184,  77,  98,  74,  23,  48, 151, 149, 189, 165,\n",
       "         44, 116, 100,  30,  58, 177,  34, 136,  19, 193, 168,  69, 191,\n",
       "        153,  49, 190,  47, 183, 125, 179,  76,  85,   4,  62, 128,  81,\n",
       "        122, 108, 194,  13,   8], dtype=int32))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set\n",
    "X_test = np.load(config['path_in_np_X_test'])\n",
    "Y_test = np.load(config['path_in_np_Y_test'])\n",
    "X_test.shape, Y_test.shape, X_test[0], Y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Torch Tensors (X & Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8850, 200, 30]), torch.Size([8850, 200]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set\n",
    "X_train_torch = torch.load(config['path_in_torch_X_train'])\n",
    "Y_train_torch = torch.load(config['path_in_torch_Y_train'])\n",
    "X_train_torch.size(), Y_train_torch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2212, 200, 30]), torch.Size([2212, 200]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full test set\n",
    "X_test_full_torch = torch.load(config['path_in_torch_X_test'])\n",
    "Y_test_full_torch = torch.load(config['path_in_torch_Y_test'])\n",
    "X_test_full_torch.size(), Y_test_full_torch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y needs to be a long\n",
    "Y_train_torch = Y_train_torch.long()\n",
    "Y_test_full_torch = Y_test_full_torch.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('torch.LongTensor', 'torch.LongTensor')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_torch.type(), Y_test_full_torch.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smaller test set\n",
    "For validation here, due to memory size problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['test_small_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([300, 200, 30]), torch.Size([300, 200]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split\n",
    "X_test_torch = X_test_full_torch[:config['test_small_size']]\n",
    "Y_test_torch = Y_test_full_torch[:config['test_small_size']]\n",
    "X_test_torch.size(), Y_test_torch.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn into Torch Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# into datasets\n",
    "dataset_train = TensorDataset(X_train_torch, Y_train_torch)\n",
    "dataset_test = TensorDataset(X_test_torch, Y_test_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "train_dataloader = DataLoader(dataset_train, batch_size=config['batch_size'], shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(dataset_test, batch_size=config['batch_size'], shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model PtrNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from procat_models import PointerCatalogNetwork, \\\n",
    "    PointerEncoder, PointerAttention, PointerDecoder, PointerOfferEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointerCatalogNetwork(\n",
       "  (word_embedding): Embedding(300005, 32)\n",
       "  (offer_embedding): PointerOfferEmbedder(\n",
       "    (offer_rnn): GRU(32, 64, num_layers=2, batch_first=True, dropout=0.05)\n",
       "  )\n",
       "  (encoder): PointerEncoder(\n",
       "    (lstm): LSTM(64, 32, num_layers=2, batch_first=True, dropout=0.05, bidirectional=True)\n",
       "  )\n",
       "  (decoder): PointerDecoder(\n",
       "    (input_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (att): PointerAttention(\n",
       "      (input_linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (context_linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the model\n",
    "model_ptrnet = PointerCatalogNetwork(\n",
    "    word_embedding_dim=config['ptr_word_emb_dim'],\n",
    "    offer_embedding_dim=config['ptr_offer_emb_dim'],\n",
    "    hidden_dim=config['ptr_hid_dim'],\n",
    "    offer_rnn_layers=config['ptr_offer_rnn_layers'],\n",
    "    catalog_rnn_layers=config['ptr_catalog_rnn_layers'],\n",
    "    dropout_offers=config['ptr_dropout_offers'],\n",
    "    dropout_catalogs=config['ptr_dropout_catalogs'],\n",
    "    bidir_offers=config['ptr_bidir_offers'],  # not handled 2021 04\n",
    "    bidir_catalogs=config['ptr_bidir_catalogs'],\n",
    "    masking=config['ptr_mask'],\n",
    "    vocab_size=len(word2idx),\n",
    ")\n",
    "\n",
    "model_ptrnet.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 9,744,032 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# how many params\n",
    "count_params(model_ptrnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-elem batch\n",
    "batch_x = X_train_torch[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 200, 200]) torch.Size([2, 200])\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "_ = model_ptrnet(batch_x)\n",
    "print(_[0].size(), _[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "print(_[1].type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "CCE = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer_ptrnet = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model_ptrnet.parameters()),\n",
    "    lr=config['learning_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training | PtrNet"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# test untrained model\n",
    "results_ptrnet, _ = test_model_custom(model_ptrnet, test_dataloader, compare_solved_sort_unique, print_every=999999, x_name=0, y_name=1)\n",
    "print('Result: {:.4f}'.format(results_ptrnet))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show rank correlations only with mask on\n",
    "print('K-Tau: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_ptrnet, get_single_kendall_tau, print_every=999999)))\n",
    "print('S-Rho: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_ptrnet, get_single_spearman_rho, print_every=999999)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available, using GPU:\n",
      "Quadro P6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 5: 100%|██████████| 139/139 [02:47<00:00,  1.20s/ batches, avg_loss=5.29612]\n",
      "Epoch 2 / 5: 100%|██████████| 139/139 [02:45<00:00,  1.19s/ batches, avg_loss=5.29450]\n",
      "Epoch 3 / 5: 100%|██████████| 139/139 [02:46<00:00,  1.20s/ batches, avg_loss=5.29431]\n",
      "Epoch 4 / 5: 100%|██████████| 139/139 [02:47<00:00,  1.21s/ batches, avg_loss=5.29430]\n",
      "Epoch 5 / 5: 100%|██████████| 139/139 [02:47<00:00,  1.20s/ batches, avg_loss=5.29432]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "last_loss_ptrnet = train_epochs(\n",
    "    model_ptrnet,\n",
    "    optimizer_ptrnet,\n",
    "    CCE,\n",
    "    train_dataloader,\n",
    "    config['num_epochs'],\n",
    "    allow_gpu=True,\n",
    "    x_name=0,\n",
    "    y_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.294321060180664"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_loss_ptrnet.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing | PtrNet\n",
    "Put the model in eval() mode first (prevents dropout and such from predicting sth else from the same permuted x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointerCatalogNetwork(\n",
       "  (word_embedding): Embedding(300005, 32)\n",
       "  (offer_embedding): PointerOfferEmbedder(\n",
       "    (offer_rnn): GRU(32, 64, num_layers=2, batch_first=True, dropout=0.05)\n",
       "  )\n",
       "  (encoder): PointerEncoder(\n",
       "    (lstm): LSTM(64, 32, num_layers=2, batch_first=True, dropout=0.05, bidirectional=True)\n",
       "  )\n",
       "  (decoder): PointerDecoder(\n",
       "    (input_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (att): PointerAttention(\n",
       "      (input_linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (context_linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ptrnet.eval()  # if we had dropout or batchnorm, we must do this"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# actual metrics\n",
    "results_ptrnet, _ = test_model_custom(model_ptrnet, test_dataloader, compare_solved_sort_unique, print_every=999999, x_name=0, y_name=1)\n",
    "print('Result: {:.4f}'.format(results_ptrnet))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show rank correlations only with mask on\n",
    "print('K-Tau: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_ptrnet, get_single_kendall_tau, print_every=999999)))\n",
    "print('S-Rho: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_ptrnet, get_single_spearman_rho, print_every=999999)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sacred Experiment | Model PtrNet\n",
    "We'll want to track the dataset, model params and the result of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - real_catalogs_PROCAT_mask_True - Running command 'run_model_tests'\n",
      "INFO - real_catalogs_PROCAT_mask_True - Started run with ID \"90\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'procat_models.PointerCatalogNetwork'>\n",
      "Result: 0.0091\n",
      "K-Tau: 0.2968, perc_valid: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - real_catalogs_PROCAT_mask_True - Result: 0.00908\n",
      "INFO - real_catalogs_PROCAT_mask_True - Completed after 0:02:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-Rho: 0.4414, perc_valid: 100.0\n"
     ]
    }
   ],
   "source": [
    "# experiment config\n",
    "current_tested_model = model_ptrnet\n",
    "current_optimizer = optimizer_ptrnet\n",
    "current_last_loss = last_loss_ptrnet\n",
    "\n",
    "config_update = {\n",
    "    'model': current_tested_model.__class__.__name__,\n",
    "    'final_training_loss': round(current_last_loss.item(), 10),\n",
    "    'optimizer': current_optimizer.__class__.__name__,\n",
    "    'cfg': config,\n",
    "}\n",
    "\n",
    "# run the experiment, with updated config\n",
    "run_info = ex.run(config_updates=config_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show predictions\n",
    "See what it predicts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specific catalog prediction, with offer text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a catalog\n",
    "chosen_catalog_id = '0003leq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tfed3AqfY h: Påskebryg 33 cl. KYLLE - KYLLE. 3 33. + , d: 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælg\n",
      "\t799dzqfY h: Frisk dansk mælk PR. LITER. Max. 24 time, d: PR. LITER. Max. 24 timer fra gård til bu\n",
      "\tb8a3DqfY h: Sukkervafler BELGISKE. 550 gram, d: BELGISKE. 550 gram\n",
      "\ta4c88qfY h: Hatting fransk hotdog  gigant burgerboll, d: 4-6 stk. •\n",
      "\t3cf8qqfY h: Oreo eller prince chokoladekiks 154-240 , d: 154-240 gram. Flere varianter\n",
      "\t88a5UqfY h: Knækbrød LEKSANDS. Flere varianter 200 g, d: LEKSANDS. Flere varianter 200 gram\n",
      "\t6d6e0qfY h: Carletti 73,5 gram. • Lys • Mørk. PÅLÆGS, d: 73,5 gram. • Lys • Mørk. PÅLÆGSCHOKOLADE\n",
      "\tef59YqfY h: Corny müslibars 6 stk. • Nuts, d: 6 stk. • Nuts\n",
      "\tab38CqfY h: BKI KAFFE  • Extra. 400 gram. Ved køb af, d: • Extra. 400 gram. Ved køb af mere end 1\n",
      "\t0cbffqfY h: Pålækker 80-90 gram. - Classic - Tomat. , d: 80-90 gram. - Classic - Tomat. VILDT BIL\n",
      "\t0a4eEqfY h: Havregryn Ved køb af mere end 6 poser, e, d: Ved køb af mere end 6 poser, er prisen h\n",
      "------------------------\n",
      "\t0ef3QqfY h: Kyllingelår KUN 11,66 KR. PR. KG DET ER , d: KUN 11,66 KR. PR. KG DET ER BILLIGT. HEL\n",
      "\ta3abpqfY h: Steff houlberg • Brændende kærlighed • F, d: • Brændende kærlighed • Forloren hare • \n",
      "\tce94wqfY h: Ice cap rejer 125 gram, d: 125 gram\n",
      "\te545VqfY h: Viennetta is 650 ml. ISKOLD PRIS, d: 650 ml. ISKOLD PRIS\n",
      "\t11aaxqfY h: Kyllingeburger I alt 1000 gram. Af kylli, d: I alt 1000 gram. Af kyllingebrystfilet\n",
      "\te4e12qfY h: Frigodan • Bønnemix • Grønt m/karry • Gr, d: • Bønnemix • Grønt m/karry • Grønt m/tom\n",
      "\t431baqfY h: Toast 200-290 gram. • Pariser toast • Co, d: 200-290 gram. • Pariser toast • Cowboy t\n",
      "\t3030ZqfY h: Mou luksus suppe 1000 gram. Mange varian, d: 1000 gram. Mange varianter\n",
      "\tdb3fNqfY h: Andelår JULIUS. 160-200 gram. CHOK PRIS, d: JULIUS. 160-200 gram. CHOK PRIS\n",
      "\td638dqfY h: Frigodan ISKOLD PRIS. • Broccoli • Fine , d: ISKOLD PRIS. • Broccoli • Fine ærter • M\n",
      "\t539csqfY h: Mou kødboller 650 gram, d: 650 gram\n",
      "\tb25flqfY h: Andebryst 130-150 gram. JULIUS, d: 130-150 gram. JULIUS\n",
      "\t18cdFqfY h: Hønskød i tern 400 gram. Kogt og klar ti, d: 400 gram. Kogt og klar til brug i f.eks.\n",
      "\t50b5vqfY h: Hvidløgsbaguettes PR. 525 gram, d: PR. 525 gram\n",
      "------------------------\n",
      "\tdb9dGqfY h: God morgen juice Appelsin/blodgrape Appe, d: Appelsin/blodgrape Appelsin. LITER. FIND\n",
      "\t4daaRqfY h: 3-stjernet • Kødpølse • Røget medister •, d: • Kødpølse • Røget medister • Jægerpølse\n",
      "\tbd0fXqfY h: Riberhus 200 gram. I SKIVER. • Mellemlag, d: 200 gram. I SKIVER. • Mellemlagret\n",
      "\t9937SqfY h: Salater 150-175 gram. GRAASTEN. Mange va, d: 150-175 gram. GRAASTEN. Mange varianter\n",
      "\ta3ddnqfY h: Schulstad • Skovmand - Original - Ekstra, d: • Skovmand - Original - Ekstra grov. - M\n",
      "\t59cchqfY h: Flødehavarti 300 gram. VILDT BILLIGT, d: 300 gram. VILDT BILLIGT\n",
      "\td8f9oqfY h: Margarine •. 500 gram. BINE. BILLIGST PÅ, d: •. 500 gram. BINE. BILLIGST PÅ HELE INDK\n",
      "\t0be3HqfY h: Spegepølser 3-STJERNET. 200-230 gram. Fl, d: 3-STJERNET. 200-230 gram. Flere variante\n",
      "\tb3acOqfY h: Xl lagret ost Ca. 1400 gram, d: Ca. 1400 gram\n",
      "\taeberqfY h: Yoggi yoghurt 1000 gram. . Flere variant, d: 1000 gram. . Flere varianter\n",
      "\t44a2IqfY h: Tulip •. 300-350 gram. • Baconpostej • K, d: •. 300-350 gram. • Baconpostej • Krydder\n",
      "\t708e7qfY h: Cultura drik 500 ml. • Blåbær • Jordbær, d: 500 ml. • Blåbær • Jordbær\n",
      "\tf4f4MqfY h: Tulip PAKKE. 200 gram. MIDDAGS- FRIKADEL, d: PAKKE. 200 gram. MIDDAGS- FRIKADELLER\n",
      "------------------------\n",
      "\t2502x0fY h: Leeuwenkuil TA' • Chenin Blanc • Shiraz , d: TA' • Chenin Blanc • Shiraz • Lion's Lai\n",
      "\t070eU0fY h: Ribena • Original • Light. 850 ml, d: • Original • Light. 850 ml\n",
      "\ta6a7Z0fY h: Diamond hill 3 LITER. • Chardonnay • Shi, d: 3 LITER. • Chardonnay • Shiraz • Shiraz/\n",
      "\t183cY0fY h: Marabou chokoladebars 35-46 gram. • Fran, d: 35-46 gram. • Fransk Nougat • Marabou Or\n",
      "\t257as0fY h: Lays chips, bugles eller doritos Sour Cr, d: Sour Cream & Onion - BBQ - Salt - • - Or\n",
      "\t0da4f0fY h: Primitivo di manduria • Carlo Sani. Denn, d: • Carlo Sani. Denne Primitivo har været \n",
      "\t4809E0fY h: Haribo POSE. DET ER BILLIGT. 100-135 gra, d: POSE. DET ER BILLIGT. 100-135 gram. • Sl\n",
      "\t4815F0fY h: Sodavand 150 cl. Flere varianter. + PANT, d: 150 cl. Flere varianter. + PANT. 3. • Ni\n",
      "\tf1a9z0fY h: Bki kaffe 500 gram. • Classic Gold • ABC, d: 500 gram. • Classic Gold • ABC - hele bø\n",
      "\t3672p0fY h: Duyvis nødder Flere varianter 175-225 gr, d: Flere varianter 175-225 gram\n",
      "\t283c80fY h: Nescafé gold STORT GLAS. • Instant kaffe, d: STORT GLAS. • Instant kaffe - Original -\n",
      "------------------------\n",
      "\t29c0BqfY h: stærk chili sauce, sur/sød sauce eller s, d: 200-250 ml. 100 gram\n",
      "\t9381iqfY h: Tortilla chips SANTA MARIA. 185 gram. • , d: SANTA MARIA. 185 gram. • Salted • Cheese\n",
      "\t907ajqfY h: Æbler 2 kg. pink lady. vildt billigt, d: 2 kg. pink lady. vildt billigt\n",
      "\t28d5kqfY h: Babymajs 400 gram, d: 400 gram\n",
      "\t280auqfY h: Kartoffelmos 4 breve. á 125 gram. QUEEN, d: 4 breve. á 125 gram. QUEEN\n",
      "\t00b64qfY h: avokado, squash, forårsløg eller radiser, d: Bundt\n",
      "\t1864JqfY h: Santa maria nudler 250 gram. VILDT BILLI, d: 250 gram. VILDT BILLIGT\n",
      "\te2835qfY h: Asparges FRISKE. 250 gram, d: FRISKE. 250 gram\n",
      "\t7c1eeqfY h: Kokosmælk 17-19%. 400 ml, d: 17-19%. 400 ml\n",
      "\t067bTqfY h: Knorr • Orientalsk risret • Indisk risre, d: • Orientalsk risret • Indisk risret • Ch\n",
      "\t46df6qfY h: kalanchoe eller potteroser, d: \n",
      "\tb84a9qfY h: bambusskud eller vandkastanjer 227 gram, d: 227 gram\n",
      "\t614ebqfY h: Hellmann's mayonnaise • I glas • I tube., d: • I glas • I tube. 225-400 gram\n",
      "\t11bbPqfY h: Blomme tomater 500 gram, d: 500 gram\n",
      "------------------------\n",
      "\tb553q0fY h: Helt kalkunbryst Ca. 800 gram, d: Ca. 800 gram\n",
      "\t36f3y0fY h: Danpo • Frikadeller • Medister. 400 gram, d: • Frikadeller • Medister. 400 gram\n",
      "\t222fcqfY h: Bbq mørbrad 450 gram. JENSENS, d: 450 gram. JENSENS\n",
      "\t5cb900fY h: Skinkestege 700-800 gram. • Orientalsk •, d: 700-800 gram. • Orientalsk • Mexico\n",
      "\t7d7a10fY h: Nakkefilet DANSK. 1/2 KG. Skæres til nak, d: DANSK. 1/2 KG. Skæres til nakkekotelette\n",
      "\t97f9K0fY h: Kylling I ovnklar stegepose 1500 gram. H, d: I ovnklar stegepose 1500 gram. HEL DANSK\n",
      "\tfc78C0fY h: Hakket kalv- & flæsk . 8-12% Ca. 500 gra, d: . 8-12% Ca. 500 gram. SLAGTER NORLYK ER \n",
      "\tc90d30fY h: Steaks Ca. 1000 gram. AF UNGKVÆG. Små fi, d: Ca. 1000 gram. AF UNGKVÆG. Små fine hver\n",
      "\t5b2ag0fY h: Amanda luksusrogn Pr, d: Pr\n",
      "\tc941A0fY h: Weekend menu tilberedt Komplet MENU af d, d: tilberedt Komplet MENU af de menu TIL ti\n",
      "\ta259L0fY h: Sild i spand 800/400-700 gram. • Mariner, d: 800/400-700 gram. • Marinerede hele file\n",
      "\t6429tqfY h: Nordjyder 500. • Frankfurter • Røde knæk, d: 500. • Frankfurter • Røde knækpølser • G\n",
      "\ta5caD0fY h: Jægerkoteletter Ca. 400 gram. Marinerede, d: Ca. 400 gram. Marinerede koteletter med \n",
      "\t08cfm0fY h: Danpo hakket kylling 450 gram, d: 450 gram\n",
      "\t22edWqfY h: Flensted kartoffelgratin med fløde 500 g, d: med fløde 500 gram.\n",
      "------------------------\n",
      "\tb7fcb0fY h: Harpic Wc-blåt, d: \n",
      "\td4f0v0fY h: Zendium FRIT VALG. • Tandpasta • Tandbør, d: FRIT VALG. • Tandpasta • Tandbørster • M\n",
      "\tfb3cQ0fY h: Libero bleer • Comfort • UP&GO. 38-68 st, d: • Comfort • UP&GO. 38-68 stk. • •. 400. \n",
      "\t0ba1i0fY h: Bamseline skyllemiddel Flere varianter 1, d: Flere varianter 1000 ml.\n",
      "\ta367w0fY h: Libresse Flere varianter. • Trusseindlæg, d: Flere varianter. • Trusseindlæg • Bind\n",
      "\tac74V0fY h: Hårspray ELNETT. • Extra kraftig • Stron, d: ELNETT. • Extra kraftig • Strong hold. 4\n",
      "\t3531u0fY h: Bio-tex • Flydende vask. - Color - White, d: • Flydende vask. - Color - White - Black\n",
      "\tfbff20fY h: Elvital Alle varianter. 200-250 ml. • Sh, d: Alle varianter. 200-250 ml. • Shampoo • \n",
      "\te4b8a0fY h: L'oréal triple active creme Flere varian, d: Flere varianter. 50 ml\n",
      "\t3956N0fY h: Harpic wc-rens Flere varianter 750 ml. K, d: Flere varianter 750 ml. KÆMPE PARTI\n",
      "\t0d81d0fY h: Rexona deodoranter Flere varianter. 50-1, d: Flere varianter. 50-150 ml. • Spray • Ro\n",
      "\t029aT0fY h: Abena affaldsposer PR. SAM-PAK. 3 x, d: PR. SAM-PAK. 3 x\n",
      "\t5dbdl0fY h: Axe deodoranter Flere varianter. 150 ml., d: Flere varianter. 150 ml. • Spray\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n"
     ]
    }
   ],
   "source": [
    "# show correct\n",
    "show_correct_catalog(\n",
    "    catalog_id=chosen_catalog_id,\n",
    "    catalogs_dataframe=df_catalogs,\n",
    "    offers_dataframe=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use premade function to nicely display a single prediction.\n",
    "\n",
    "**Models that do not properly ensure permutation invariance will give different prediction on each run** regardless of being put in .eval() mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t4809E0fY h: Haribo POSE. DET ER BILLIGT. 100-135 gra, d: POSE. DET ER BILLIGT. 100-135 gram. • Sl\n",
      "\tce94wqfY h: Ice cap rejer 125 gram, d: 125 gram\n",
      "\t0ba1i0fY h: Bamseline skyllemiddel Flere varianter 1, d: Flere varianter 1000 ml.\n",
      "\t97f9K0fY h: Kylling I ovnklar stegepose 1500 gram. H, d: I ovnklar stegepose 1500 gram. HEL DANSK\n",
      "\tf4f4MqfY h: Tulip PAKKE. 200 gram. MIDDAGS- FRIKADEL, d: PAKKE. 200 gram. MIDDAGS- FRIKADELLER\n",
      "\tb553q0fY h: Helt kalkunbryst Ca. 800 gram, d: Ca. 800 gram\n",
      "\tef59YqfY h: Corny müslibars 6 stk. • Nuts, d: 6 stk. • Nuts\n",
      "\t9381iqfY h: Tortilla chips SANTA MARIA. 185 gram. • , d: SANTA MARIA. 185 gram. • Salted • Cheese\n",
      "\taeberqfY h: Yoggi yoghurt 1000 gram. . Flere variant, d: 1000 gram. . Flere varianter\n",
      "\t614ebqfY h: Hellmann's mayonnaise • I glas • I tube., d: • I glas • I tube. 225-400 gram\n",
      "\t44a2IqfY h: Tulip •. 300-350 gram. • Baconpostej • K, d: •. 300-350 gram. • Baconpostej • Krydder\n",
      "\t59cchqfY h: Flødehavarti 300 gram. VILDT BILLIGT, d: 300 gram. VILDT BILLIGT\n",
      "\t50b5vqfY h: Hvidløgsbaguettes PR. 525 gram, d: PR. 525 gram\n",
      "\t0be3HqfY h: Spegepølser 3-STJERNET. 200-230 gram. Fl, d: 3-STJERNET. 200-230 gram. Flere variante\n",
      "\t3030ZqfY h: Mou luksus suppe 1000 gram. Mange varian, d: 1000 gram. Mange varianter\n",
      "\te4e12qfY h: Frigodan • Bønnemix • Grønt m/karry • Gr, d: • Bønnemix • Grønt m/karry • Grønt m/tom\n",
      "\t3531u0fY h: Bio-tex • Flydende vask. - Color - White, d: • Flydende vask. - Color - White - Black\n",
      "\t00b64qfY h: avokado, squash, forårsløg eller radiser, d: Bundt\n",
      "\t257as0fY h: Lays chips, bugles eller doritos Sour Cr, d: Sour Cream & Onion - BBQ - Salt - • - Or\n",
      "\t4daaRqfY h: 3-stjernet • Kødpølse • Røget medister •, d: • Kødpølse • Røget medister • Jægerpølse\n",
      "\t708e7qfY h: Cultura drik 500 ml. • Blåbær • Jordbær, d: 500 ml. • Blåbær • Jordbær\n",
      "\t4815F0fY h: Sodavand 150 cl. Flere varianter. + PANT, d: 150 cl. Flere varianter. + PANT. 3. • Ni\n",
      "\tfc78C0fY h: Hakket kalv- & flæsk . 8-12% Ca. 500 gra, d: . 8-12% Ca. 500 gram. SLAGTER NORLYK ER \n",
      "\t3cf8qqfY h: Oreo eller prince chokoladekiks 154-240 , d: 154-240 gram. Flere varianter\n",
      "\t1864JqfY h: Santa maria nudler 250 gram. VILDT BILLI, d: 250 gram. VILDT BILLIGT\n",
      "\t0cbffqfY h: Pålækker 80-90 gram. - Classic - Tomat. , d: 80-90 gram. - Classic - Tomat. VILDT BIL\n",
      "\tdb3fNqfY h: Andelår JULIUS. 160-200 gram. CHOK PRIS, d: JULIUS. 160-200 gram. CHOK PRIS\n",
      "\t36f3y0fY h: Danpo • Frikadeller • Medister. 400 gram, d: • Frikadeller • Medister. 400 gram\n",
      "\t280auqfY h: Kartoffelmos 4 breve. á 125 gram. QUEEN, d: 4 breve. á 125 gram. QUEEN\n",
      "\t283c80fY h: Nescafé gold STORT GLAS. • Instant kaffe, d: STORT GLAS. • Instant kaffe - Original -\n",
      "\t6429tqfY h: Nordjyder 500. • Frankfurter • Røde knæk, d: 500. • Frankfurter • Røde knækpølser • G\n",
      "\td8f9oqfY h: Margarine •. 500 gram. BINE. BILLIGST PÅ, d: •. 500 gram. BINE. BILLIGST PÅ HELE INDK\n",
      "\t907ajqfY h: Æbler 2 kg. pink lady. vildt billigt, d: 2 kg. pink lady. vildt billigt\n",
      "\t0ef3QqfY h: Kyllingelår KUN 11,66 KR. PR. KG DET ER , d: KUN 11,66 KR. PR. KG DET ER BILLIGT. HEL\n",
      "\tb7fcb0fY h: Harpic Wc-blåt, d: \n",
      "\ta259L0fY h: Sild i spand 800/400-700 gram. • Mariner, d: 800/400-700 gram. • Marinerede hele file\n",
      "\t7d7a10fY h: Nakkefilet DANSK. 1/2 KG. Skæres til nak, d: DANSK. 1/2 KG. Skæres til nakkekotelette\n",
      "\tb84a9qfY h: bambusskud eller vandkastanjer 227 gram, d: 227 gram\n",
      "\ta4c88qfY h: Hatting fransk hotdog  gigant burgerboll, d: 4-6 stk. •\n",
      "\t88a5UqfY h: Knækbrød LEKSANDS. Flere varianter 200 g, d: LEKSANDS. Flere varianter 200 gram\n",
      "\te4b8a0fY h: L'oréal triple active creme Flere varian, d: Flere varianter. 50 ml\n",
      "\t431baqfY h: Toast 200-290 gram. • Pariser toast • Co, d: 200-290 gram. • Pariser toast • Cowboy t\n",
      "\tb3acOqfY h: Xl lagret ost Ca. 1400 gram, d: Ca. 1400 gram\n",
      "\tfed3AqfY h: Påskebryg 33 cl. KYLLE - KYLLE. 3 33. + , d: 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælg\n",
      "\tb8a3DqfY h: Sukkervafler BELGISKE. 550 gram, d: BELGISKE. 550 gram\n",
      "\t5b2ag0fY h: Amanda luksusrogn Pr, d: Pr\n",
      "\tf1a9z0fY h: Bki kaffe 500 gram. • Classic Gold • ABC, d: 500 gram. • Classic Gold • ABC - hele bø\n",
      "\t11bbPqfY h: Blomme tomater 500 gram, d: 500 gram\n",
      "\tb25flqfY h: Andebryst 130-150 gram. JULIUS, d: 130-150 gram. JULIUS\n",
      "\t6d6e0qfY h: Carletti 73,5 gram. • Lys • Mørk. PÅLÆGS, d: 73,5 gram. • Lys • Mørk. PÅLÆGSCHOKOLADE\n",
      "\t5dbdl0fY h: Axe deodoranter Flere varianter. 150 ml., d: Flere varianter. 150 ml. • Spray\n",
      "\te545VqfY h: Viennetta is 650 ml. ISKOLD PRIS, d: 650 ml. ISKOLD PRIS\n",
      "\t29c0BqfY h: stærk chili sauce, sur/sød sauce eller s, d: 200-250 ml. 100 gram\n",
      "\t18cdFqfY h: Hønskød i tern 400 gram. Kogt og klar ti, d: 400 gram. Kogt og klar til brug i f.eks.\n",
      "\ta367w0fY h: Libresse Flere varianter. • Trusseindlæg, d: Flere varianter. • Trusseindlæg • Bind\n",
      "\t0d81d0fY h: Rexona deodoranter Flere varianter. 50-1, d: Flere varianter. 50-150 ml. • Spray • Ro\n",
      "\td4f0v0fY h: Zendium FRIT VALG. • Tandpasta • Tandbør, d: FRIT VALG. • Tandpasta • Tandbørster • M\n",
      "\t0a4eEqfY h: Havregryn Ved køb af mere end 6 poser, e, d: Ved køb af mere end 6 poser, er prisen h\n",
      "\t0da4f0fY h: Primitivo di manduria • Carlo Sani. Denn, d: • Carlo Sani. Denne Primitivo har været \n",
      "\t070eU0fY h: Ribena • Original • Light. 850 ml, d: • Original • Light. 850 ml\n",
      "\tfbff20fY h: Elvital Alle varianter. 200-250 ml. • Sh, d: Alle varianter. 200-250 ml. • Shampoo • \n",
      "\tbd0fXqfY h: Riberhus 200 gram. I SKIVER. • Mellemlag, d: 200 gram. I SKIVER. • Mellemlagret\n",
      "\t222fcqfY h: Bbq mørbrad 450 gram. JENSENS, d: 450 gram. JENSENS\n",
      "\tfb3cQ0fY h: Libero bleer • Comfort • UP&GO. 38-68 st, d: • Comfort • UP&GO. 38-68 stk. • •. 400. \n",
      "\t2502x0fY h: Leeuwenkuil TA' • Chenin Blanc • Shiraz , d: TA' • Chenin Blanc • Shiraz • Lion's Lai\n",
      "\t08cfm0fY h: Danpo hakket kylling 450 gram, d: 450 gram\n",
      "\t183cY0fY h: Marabou chokoladebars 35-46 gram. • Fran, d: 35-46 gram. • Fransk Nougat • Marabou Or\n",
      "\ta5caD0fY h: Jægerkoteletter Ca. 400 gram. Marinerede, d: Ca. 400 gram. Marinerede koteletter med \n",
      "\t28d5kqfY h: Babymajs 400 gram, d: 400 gram\n",
      "\t539csqfY h: Mou kødboller 650 gram, d: 650 gram\n",
      "\te2835qfY h: Asparges FRISKE. 250 gram, d: FRISKE. 250 gram\n",
      "\t9937SqfY h: Salater 150-175 gram. GRAASTEN. Mange va, d: 150-175 gram. GRAASTEN. Mange varianter\n",
      "\tdb9dGqfY h: God morgen juice Appelsin/blodgrape Appe, d: Appelsin/blodgrape Appelsin. LITER. FIND\n",
      "\tac74V0fY h: Hårspray ELNETT. • Extra kraftig • Stron, d: ELNETT. • Extra kraftig • Strong hold. 4\n",
      "\ta6a7Z0fY h: Diamond hill 3 LITER. • Chardonnay • Shi, d: 3 LITER. • Chardonnay • Shiraz • Shiraz/\n",
      "\tab38CqfY h: BKI KAFFE  • Extra. 400 gram. Ved køb af, d: • Extra. 400 gram. Ved køb af mere end 1\n",
      "\t3672p0fY h: Duyvis nødder Flere varianter 175-225 gr, d: Flere varianter 175-225 gram\n",
      "\tc941A0fY h: Weekend menu tilberedt Komplet MENU af d, d: tilberedt Komplet MENU af de menu TIL ti\n",
      "\t3956N0fY h: Harpic wc-rens Flere varianter 750 ml. K, d: Flere varianter 750 ml. KÆMPE PARTI\n",
      "\td638dqfY h: Frigodan ISKOLD PRIS. • Broccoli • Fine , d: ISKOLD PRIS. • Broccoli • Fine ærter • M\n",
      "\t799dzqfY h: Frisk dansk mælk PR. LITER. Max. 24 time, d: PR. LITER. Max. 24 timer fra gård til bu\n",
      "\t029aT0fY h: Abena affaldsposer PR. SAM-PAK. 3 x, d: PR. SAM-PAK. 3 x\n",
      "\t7c1eeqfY h: Kokosmælk 17-19%. 400 ml, d: 17-19%. 400 ml\n",
      "\t22edWqfY h: Flensted kartoffelgratin med fløde 500 g, d: med fløde 500 gram.\n",
      "\ta3abpqfY h: Steff houlberg • Brændende kærlighed • F, d: • Brændende kærlighed • Forloren hare • \n",
      "\ta3ddnqfY h: Schulstad • Skovmand - Original - Ekstra, d: • Skovmand - Original - Ekstra grov. - M\n",
      "\t5cb900fY h: Skinkestege 700-800 gram. • Orientalsk •, d: 700-800 gram. • Orientalsk • Mexico\n",
      "\tc90d30fY h: Steaks Ca. 1000 gram. AF UNGKVÆG. Små fi, d: Ca. 1000 gram. AF UNGKVÆG. Små fine hver\n",
      "\t46df6qfY h: kalanchoe eller potteroser, d: \n",
      "\t11aaxqfY h: Kyllingeburger I alt 1000 gram. Af kylli, d: I alt 1000 gram. Af kyllingebrystfilet\n",
      "\t067bTqfY h: Knorr • Orientalsk risret • Indisk risre, d: • Orientalsk risret • Indisk risret • Ch\n",
      "------------------------\n",
      "------------------------\n",
      "------------------------\n",
      "------------------------\n",
      "------------------------\n",
      "------------------------\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n"
     ]
    }
   ],
   "source": [
    "# show predicted\n",
    "# if the model is not permutation invariant, it will predict sth else\n",
    "# for every random permutation of the source catalog\n",
    "model_ptrnet.eval()\n",
    "show_predicted_catalog(\n",
    "    catalog_id='0003leq',\n",
    "    a_model=model_ptrnet,\n",
    "    catalogs_dataframe=df_catalogs,\n",
    "    offers_dataframe=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model DeepSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from procat_models import DeepSets, DeepSetsPointerCatalogNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepSetsPointerCatalogNetwork(\n",
       "  (word_embedding): Embedding(300005, 32)\n",
       "  (offer_embedding): PointerOfferEmbedder(\n",
       "    (offer_rnn): GRU(32, 64, num_layers=2, batch_first=True, dropout=0.05)\n",
       "  )\n",
       "  (set_embedding): DeepSets(\n",
       "    (encode): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (13): ReLU()\n",
       "    )\n",
       "    (out): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (7): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (encoder): PointerEncoder(\n",
       "    (lstm): LSTM(128, 32, num_layers=2, batch_first=True, dropout=0.05, bidirectional=True)\n",
       "  )\n",
       "  (decoder): PointerDecoder(\n",
       "    (input_to_hidden): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (hidden_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (att): PointerAttention(\n",
       "      (input_linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (context_linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the model\n",
    "model_deepsets = DeepSetsPointerCatalogNetwork(\n",
    "    word_embedding_dim=config['ptr_word_emb_dim'],\n",
    "    offer_embedding_dim=config['ptr_offer_emb_dim'],\n",
    "    hidden_dim=config['ptr_hid_dim'],\n",
    "    offer_rnn_layers=config['ptr_offer_rnn_layers'],\n",
    "    catalog_rnn_layers=config['ptr_catalog_rnn_layers'],\n",
    "    dropout_offers=config['ptr_dropout_offers'],\n",
    "    dropout_catalogs=config['ptr_dropout_catalogs'],\n",
    "    bidir_offers=config['ptr_bidir_offers'],  # not handled 2021 04\n",
    "    bidir_catalogs=config['ptr_bidir_catalogs'],\n",
    "    masking=config['ptr_mask'],\n",
    "    vocab_size=len(word2idx),\n",
    ")\n",
    "\n",
    "model_deepsets.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 9,863,776 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# how many params\n",
    "count_params(model_deepsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-elem batch\n",
    "batch_x = X_train_torch[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 200, 200]) torch.Size([2, 200])\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "_ = model_deepsets(batch_x)\n",
    "print(_[0].size(), _[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "print(_[1].type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "CCE = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer_deepsets = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model_deepsets.parameters()),\n",
    "    lr=config['learning_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training | DeepSets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# test untrained model\n",
    "results_deepsets, _ = test_model_custom(model_deepsets, test_dataloader, compare_solved_sort_unique, print_every=999999, x_name=0, y_name=1)\n",
    "print('Result: {:.4f}'.format(results_deepsets))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show rank correlations only with mask on\n",
    "print('K-Tau: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_deepsets, get_single_kendall_tau, print_every=999999)))\n",
    "print('S-Rho: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_deepsets, get_single_spearman_rho, print_every=999999)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available, using GPU:\n",
      "Quadro P6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 5: 100%|██████████| 139/139 [03:04<00:00,  1.32s/ batches, avg_loss=5.29838]\n",
      "Epoch 2 / 5: 100%|██████████| 139/139 [03:03<00:00,  1.32s/ batches, avg_loss=5.29820]\n",
      "Epoch 3 / 5: 100%|██████████| 139/139 [03:04<00:00,  1.32s/ batches, avg_loss=5.29646]\n",
      "Epoch 4 / 5: 100%|██████████| 139/139 [03:04<00:00,  1.33s/ batches, avg_loss=5.29783]\n",
      "Epoch 5 / 5: 100%|██████████| 139/139 [03:05<00:00,  1.33s/ batches, avg_loss=5.29586]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "last_loss_deepsets = train_epochs(\n",
    "    model_deepsets,\n",
    "    optimizer_deepsets,\n",
    "    CCE,\n",
    "    train_dataloader,\n",
    "    config['num_epochs'],\n",
    "    allow_gpu=True,\n",
    "    x_name=0,\n",
    "    y_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.295864105224609"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_loss_deepsets.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing | DeepSets\n",
    "Put the model in eval() mode first (prevents dropout and such from predicting sth else from the same permuted x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepSetsPointerCatalogNetwork(\n",
       "  (word_embedding): Embedding(300005, 32)\n",
       "  (offer_embedding): PointerOfferEmbedder(\n",
       "    (offer_rnn): GRU(32, 64, num_layers=2, batch_first=True, dropout=0.05)\n",
       "  )\n",
       "  (set_embedding): DeepSets(\n",
       "    (encode): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (13): ReLU()\n",
       "    )\n",
       "    (out): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (7): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (encoder): PointerEncoder(\n",
       "    (lstm): LSTM(128, 32, num_layers=2, batch_first=True, dropout=0.05, bidirectional=True)\n",
       "  )\n",
       "  (decoder): PointerDecoder(\n",
       "    (input_to_hidden): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (hidden_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (att): PointerAttention(\n",
       "      (input_linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (context_linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_deepsets.eval()  # if we had dropout or batchnorm, we must do this"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# actual metrics\n",
    "results_deepsets, _ = test_model_custom(model_deepsets, test_dataloader, compare_solved_sort_unique, print_every=999999, x_name=0, y_name=1)\n",
    "print('Result: {:.4f}'.format(results_deepsets))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show rank correlations only with mask on\n",
    "print('K-Tau: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_deepsets, get_single_kendall_tau, print_every=999999)))\n",
    "print('S-Rho: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_deepsets, get_single_spearman_rho, print_every=999999)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sacred Experiment | Model DeepSets\n",
    "We'll want to track the dataset, model params and the result of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - real_catalogs_PROCAT_mask_True - Running command 'run_model_tests'\n",
      "INFO - real_catalogs_PROCAT_mask_True - Started run with ID \"91\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'procat_models.DeepSetsPointerCatalogNetwork'>\n",
      "Result: 0.0092\n",
      "K-Tau: 0.2857, perc_valid: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - real_catalogs_PROCAT_mask_True - Result: 0.00918\n",
      "INFO - real_catalogs_PROCAT_mask_True - Completed after 0:03:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-Rho: 0.4263, perc_valid: 100.0\n"
     ]
    }
   ],
   "source": [
    "# experiment config\n",
    "current_tested_model = model_deepsets\n",
    "current_optimizer = optimizer_deepsets\n",
    "current_last_loss = last_loss_deepsets\n",
    "\n",
    "config_update = {\n",
    "    'model': current_tested_model.__class__.__name__,\n",
    "    'final_training_loss': round(current_last_loss.item(), 10),\n",
    "    'optimizer': current_optimizer.__class__.__name__,\n",
    "    'cfg': config,\n",
    "}\n",
    "\n",
    "# run the experiment, with updated config\n",
    "run_info = ex.run(config_updates=config_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show predictions\n",
    "See what it predicts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specific catalog prediction, with offer text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a catalog\n",
    "chosen_catalog_id = '0003leq'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show correct\n",
    "show_correct_catalog(\n",
    "    catalog_id=chosen_catalog_id,\n",
    "    catalogs_dataframe=df_catalogs,\n",
    "    offers_dataframe=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use premade function to nicely display a single prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t88a5UqfY h: Knækbrød LEKSANDS. Flere varianter 200 g, d: LEKSANDS. Flere varianter 200 gram\n",
      "\td8f9oqfY h: Margarine •. 500 gram. BINE. BILLIGST PÅ, d: •. 500 gram. BINE. BILLIGST PÅ HELE INDK\n",
      "\t5b2ag0fY h: Amanda luksusrogn Pr, d: Pr\n",
      "\t029aT0fY h: Abena affaldsposer PR. SAM-PAK. 3 x, d: PR. SAM-PAK. 3 x\n",
      "\t907ajqfY h: Æbler 2 kg. pink lady. vildt billigt, d: 2 kg. pink lady. vildt billigt\n",
      "\t2502x0fY h: Leeuwenkuil TA' • Chenin Blanc • Shiraz , d: TA' • Chenin Blanc • Shiraz • Lion's Lai\n",
      "\tb7fcb0fY h: Harpic Wc-blåt, d: \n",
      "\t799dzqfY h: Frisk dansk mælk PR. LITER. Max. 24 time, d: PR. LITER. Max. 24 timer fra gård til bu\n",
      "\ta367w0fY h: Libresse Flere varianter. • Trusseindlæg, d: Flere varianter. • Trusseindlæg • Bind\n",
      "\t22edWqfY h: Flensted kartoffelgratin med fløde 500 g, d: med fløde 500 gram.\n",
      "\t9381iqfY h: Tortilla chips SANTA MARIA. 185 gram. • , d: SANTA MARIA. 185 gram. • Salted • Cheese\n",
      "\t4809E0fY h: Haribo POSE. DET ER BILLIGT. 100-135 gra, d: POSE. DET ER BILLIGT. 100-135 gram. • Sl\n",
      "\tb8a3DqfY h: Sukkervafler BELGISKE. 550 gram, d: BELGISKE. 550 gram\n",
      "\tfbff20fY h: Elvital Alle varianter. 200-250 ml. • Sh, d: Alle varianter. 200-250 ml. • Shampoo • \n",
      "\t070eU0fY h: Ribena • Original • Light. 850 ml, d: • Original • Light. 850 ml\n",
      "\te545VqfY h: Viennetta is 650 ml. ISKOLD PRIS, d: 650 ml. ISKOLD PRIS\n",
      "\tac74V0fY h: Hårspray ELNETT. • Extra kraftig • Stron, d: ELNETT. • Extra kraftig • Strong hold. 4\n",
      "\t3956N0fY h: Harpic wc-rens Flere varianter 750 ml. K, d: Flere varianter 750 ml. KÆMPE PARTI\n",
      "------------------------\n",
      "------------------------\n",
      "\tf4f4MqfY h: Tulip PAKKE. 200 gram. MIDDAGS- FRIKADEL, d: PAKKE. 200 gram. MIDDAGS- FRIKADELLER\n",
      "\t08cfm0fY h: Danpo hakket kylling 450 gram, d: 450 gram\n",
      "\t0a4eEqfY h: Havregryn Ved køb af mere end 6 poser, e, d: Ved køb af mere end 6 poser, er prisen h\n",
      "\tf1a9z0fY h: Bki kaffe 500 gram. • Classic Gold • ABC, d: 500 gram. • Classic Gold • ABC - hele bø\n",
      "\t9937SqfY h: Salater 150-175 gram. GRAASTEN. Mange va, d: 150-175 gram. GRAASTEN. Mange varianter\n",
      "\t36f3y0fY h: Danpo • Frikadeller • Medister. 400 gram, d: • Frikadeller • Medister. 400 gram\n",
      "\t708e7qfY h: Cultura drik 500 ml. • Blåbær • Jordbær, d: 500 ml. • Blåbær • Jordbær\n",
      "\te2835qfY h: Asparges FRISKE. 250 gram, d: FRISKE. 250 gram\n",
      "\t614ebqfY h: Hellmann's mayonnaise • I glas • I tube., d: • I glas • I tube. 225-400 gram\n",
      "\t46df6qfY h: kalanchoe eller potteroser, d: \n",
      "\tef59YqfY h: Corny müslibars 6 stk. • Nuts, d: 6 stk. • Nuts\n",
      "\t3531u0fY h: Bio-tex • Flydende vask. - Color - White, d: • Flydende vask. - Color - White - Black\n",
      "\t222fcqfY h: Bbq mørbrad 450 gram. JENSENS, d: 450 gram. JENSENS\n",
      "\t0ef3QqfY h: Kyllingelår KUN 11,66 KR. PR. KG DET ER , d: KUN 11,66 KR. PR. KG DET ER BILLIGT. HEL\n",
      "\tdb9dGqfY h: God morgen juice Appelsin/blodgrape Appe, d: Appelsin/blodgrape Appelsin. LITER. FIND\n",
      "\t7d7a10fY h: Nakkefilet DANSK. 1/2 KG. Skæres til nak, d: DANSK. 1/2 KG. Skæres til nakkekotelette\n",
      "\tce94wqfY h: Ice cap rejer 125 gram, d: 125 gram\n",
      "------------------------\n",
      "\tbd0fXqfY h: Riberhus 200 gram. I SKIVER. • Mellemlag, d: 200 gram. I SKIVER. • Mellemlagret\n",
      "\tab38CqfY h: BKI KAFFE  • Extra. 400 gram. Ved køb af, d: • Extra. 400 gram. Ved køb af mere end 1\n",
      "\t1864JqfY h: Santa maria nudler 250 gram. VILDT BILLI, d: 250 gram. VILDT BILLIGT\n",
      "\t28d5kqfY h: Babymajs 400 gram, d: 400 gram\n",
      "\t5dbdl0fY h: Axe deodoranter Flere varianter. 150 ml., d: Flere varianter. 150 ml. • Spray\n",
      "\tb553q0fY h: Helt kalkunbryst Ca. 800 gram, d: Ca. 800 gram\n",
      "\t0da4f0fY h: Primitivo di manduria • Carlo Sani. Denn, d: • Carlo Sani. Denne Primitivo har været \n",
      "\taeberqfY h: Yoggi yoghurt 1000 gram. . Flere variant, d: 1000 gram. . Flere varianter\n",
      "\tb84a9qfY h: bambusskud eller vandkastanjer 227 gram, d: 227 gram\n",
      "\t0be3HqfY h: Spegepølser 3-STJERNET. 200-230 gram. Fl, d: 3-STJERNET. 200-230 gram. Flere variante\n",
      "\t3672p0fY h: Duyvis nødder Flere varianter 175-225 gr, d: Flere varianter 175-225 gram\n",
      "\t00b64qfY h: avokado, squash, forårsløg eller radiser, d: Bundt\n",
      "\tc90d30fY h: Steaks Ca. 1000 gram. AF UNGKVÆG. Små fi, d: Ca. 1000 gram. AF UNGKVÆG. Små fine hver\n",
      "------------------------\n",
      "\tfb3cQ0fY h: Libero bleer • Comfort • UP&GO. 38-68 st, d: • Comfort • UP&GO. 38-68 stk. • •. 400. \n",
      "\t50b5vqfY h: Hvidløgsbaguettes PR. 525 gram, d: PR. 525 gram\n",
      "------------------------\n",
      "\t44a2IqfY h: Tulip •. 300-350 gram. • Baconpostej • K, d: •. 300-350 gram. • Baconpostej • Krydder\n",
      "\t11aaxqfY h: Kyllingeburger I alt 1000 gram. Af kylli, d: I alt 1000 gram. Af kyllingebrystfilet\n",
      "\t59cchqfY h: Flødehavarti 300 gram. VILDT BILLIGT, d: 300 gram. VILDT BILLIGT\n",
      "\t5cb900fY h: Skinkestege 700-800 gram. • Orientalsk •, d: 700-800 gram. • Orientalsk • Mexico\n",
      "\t067bTqfY h: Knorr • Orientalsk risret • Indisk risre, d: • Orientalsk risret • Indisk risret • Ch\n",
      "\t18cdFqfY h: Hønskød i tern 400 gram. Kogt og klar ti, d: 400 gram. Kogt og klar til brug i f.eks.\n",
      "\t0d81d0fY h: Rexona deodoranter Flere varianter. 50-1, d: Flere varianter. 50-150 ml. • Spray • Ro\n",
      "------------------------\n",
      "\t3cf8qqfY h: Oreo eller prince chokoladekiks 154-240 , d: 154-240 gram. Flere varianter\n",
      "\tdb3fNqfY h: Andelår JULIUS. 160-200 gram. CHOK PRIS, d: JULIUS. 160-200 gram. CHOK PRIS\n",
      "\t6d6e0qfY h: Carletti 73,5 gram. • Lys • Mørk. PÅLÆGS, d: 73,5 gram. • Lys • Mørk. PÅLÆGSCHOKOLADE\n",
      "\tfed3AqfY h: Påskebryg 33 cl. KYLLE - KYLLE. 3 33. + , d: 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælg\n",
      "\ta5caD0fY h: Jægerkoteletter Ca. 400 gram. Marinerede, d: Ca. 400 gram. Marinerede koteletter med \n",
      "\te4b8a0fY h: L'oréal triple active creme Flere varian, d: Flere varianter. 50 ml\n",
      "\t7c1eeqfY h: Kokosmælk 17-19%. 400 ml, d: 17-19%. 400 ml\n",
      "\tb3acOqfY h: Xl lagret ost Ca. 1400 gram, d: Ca. 1400 gram\n",
      "\t11bbPqfY h: Blomme tomater 500 gram, d: 500 gram\n",
      "\t3030ZqfY h: Mou luksus suppe 1000 gram. Mange varian, d: 1000 gram. Mange varianter\n",
      "\td638dqfY h: Frigodan ISKOLD PRIS. • Broccoli • Fine , d: ISKOLD PRIS. • Broccoli • Fine ærter • M\n",
      "\t6429tqfY h: Nordjyder 500. • Frankfurter • Røde knæk, d: 500. • Frankfurter • Røde knækpølser • G\n",
      "\t257as0fY h: Lays chips, bugles eller doritos Sour Cr, d: Sour Cream & Onion - BBQ - Salt - • - Or\n",
      "\t97f9K0fY h: Kylling I ovnklar stegepose 1500 gram. H, d: I ovnklar stegepose 1500 gram. HEL DANSK\n",
      "\t280auqfY h: Kartoffelmos 4 breve. á 125 gram. QUEEN, d: 4 breve. á 125 gram. QUEEN\n",
      "\t431baqfY h: Toast 200-290 gram. • Pariser toast • Co, d: 200-290 gram. • Pariser toast • Cowboy t\n",
      "\t283c80fY h: Nescafé gold STORT GLAS. • Instant kaffe, d: STORT GLAS. • Instant kaffe - Original -\n",
      "\t183cY0fY h: Marabou chokoladebars 35-46 gram. • Fran, d: 35-46 gram. • Fransk Nougat • Marabou Or\n",
      "\te4e12qfY h: Frigodan • Bønnemix • Grønt m/karry • Gr, d: • Bønnemix • Grønt m/karry • Grønt m/tom\n",
      "\td4f0v0fY h: Zendium FRIT VALG. • Tandpasta • Tandbør, d: FRIT VALG. • Tandpasta • Tandbørster • M\n",
      "\tfc78C0fY h: Hakket kalv- & flæsk . 8-12% Ca. 500 gra, d: . 8-12% Ca. 500 gram. SLAGTER NORLYK ER \n",
      "\t29c0BqfY h: stærk chili sauce, sur/sød sauce eller s, d: 200-250 ml. 100 gram\n",
      "\ta3abpqfY h: Steff houlberg • Brændende kærlighed • F, d: • Brændende kærlighed • Forloren hare • \n",
      "\t4daaRqfY h: 3-stjernet • Kødpølse • Røget medister •, d: • Kødpølse • Røget medister • Jægerpølse\n",
      "\tc941A0fY h: Weekend menu tilberedt Komplet MENU af d, d: tilberedt Komplet MENU af de menu TIL ti\n",
      "\t4815F0fY h: Sodavand 150 cl. Flere varianter. + PANT, d: 150 cl. Flere varianter. + PANT. 3. • Ni\n",
      "\t0cbffqfY h: Pålækker 80-90 gram. - Classic - Tomat. , d: 80-90 gram. - Classic - Tomat. VILDT BIL\n",
      "\ta3ddnqfY h: Schulstad • Skovmand - Original - Ekstra, d: • Skovmand - Original - Ekstra grov. - M\n",
      "\t539csqfY h: Mou kødboller 650 gram, d: 650 gram\n",
      "\tb25flqfY h: Andebryst 130-150 gram. JULIUS, d: 130-150 gram. JULIUS\n",
      "------------------------\n",
      "\ta4c88qfY h: Hatting fransk hotdog  gigant burgerboll, d: 4-6 stk. •\n",
      "\t0ba1i0fY h: Bamseline skyllemiddel Flere varianter 1, d: Flere varianter 1000 ml.\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\ta6a7Z0fY h: Diamond hill 3 LITER. • Chardonnay • Shi, d: 3 LITER. • Chardonnay • Shiraz • Shiraz/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ta259L0fY h: Sild i spand 800/400-700 gram. • Mariner, d: 800/400-700 gram. • Marinerede hele file\n"
     ]
    }
   ],
   "source": [
    "# show predicted\n",
    "# if the model is not permutation invariant, it will predict sth else\n",
    "# for every random permutation of the source catalog\n",
    "show_predicted_catalog(\n",
    "    catalog_id='0003leq',\n",
    "    a_model=model_deepsets,\n",
    "    catalogs_dataframe=df_catalogs,\n",
    "    offers_dataframe=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model SetTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from procat_models import SetTransformer, SetTransformerPointerCatalogNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SetTransformerPointerCatalogNetwork(\n",
       "  (word_embedding): Embedding(300005, 32)\n",
       "  (offer_embedding): PointerOfferEmbedder(\n",
       "    (offer_rnn): GRU(32, 64, num_layers=2, batch_first=True, dropout=0.05)\n",
       "  )\n",
       "  (set_embedding): SetTransformer(\n",
       "    (emb): Sequential(\n",
       "      (0): SAB(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SAB(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (enc): Sequential(\n",
       "      (0): PMA(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SAB(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): SAB(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder): PointerEncoder(\n",
       "    (lstm): LSTM(128, 32, num_layers=2, batch_first=True, dropout=0.05, bidirectional=True)\n",
       "  )\n",
       "  (decoder): PointerDecoder(\n",
       "    (input_to_hidden): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (hidden_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (att): PointerAttention(\n",
       "      (input_linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (context_linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the model\n",
    "model_settrans = SetTransformerPointerCatalogNetwork(\n",
    "    word_embedding_dim=config['ptr_word_emb_dim'],\n",
    "    offer_embedding_dim=config['ptr_offer_emb_dim'],\n",
    "    hidden_dim=config['ptr_hid_dim'],\n",
    "    offer_rnn_layers=config['ptr_offer_rnn_layers'],\n",
    "    catalog_rnn_layers=config['ptr_catalog_rnn_layers'],\n",
    "    dropout_offers=config['ptr_dropout_offers'],\n",
    "    dropout_catalogs=config['ptr_dropout_catalogs'],\n",
    "    bidir_offers=config['ptr_bidir_offers'],  # not handled 2021 04\n",
    "    bidir_catalogs=config['ptr_bidir_catalogs'],\n",
    "    masking=config['ptr_mask'],\n",
    "    vocab_size=len(word2idx),\n",
    ")\n",
    "\n",
    "model_settrans.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 9,864,224 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# how many params\n",
    "count_params(model_settrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-elem batch\n",
    "batch_x = X_train_torch[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 200, 200]) torch.Size([2, 200])\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "_ = model_settrans(batch_x)\n",
    "print(_[0].size(), _[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "print(_[1].type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "CCE = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer_settrans = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model_settrans.parameters()),\n",
    "    lr=config['learning_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training | Set Transformer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# test untrained model\n",
    "results_settrans, _ = test_model_custom(model_settrans, test_dataloader, compare_solved_sort_unique, print_every=999999, x_name=0, y_name=1)\n",
    "print('Result: {:.4f}'.format(results_settrans))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show rank correlations only with mask on\n",
    "print('K-Tau: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_settrans, get_single_kendall_tau, print_every=999999)))\n",
    "print('S-Rho: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_settrans, get_single_spearman_rho, print_every=999999)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available, using GPU:\n",
      "Quadro P6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 5: 100%|██████████| 139/139 [03:11<00:00,  1.38s/ batches, avg_loss=5.29621]\n",
      "Epoch 2 / 5: 100%|██████████| 139/139 [03:11<00:00,  1.38s/ batches, avg_loss=5.29511]\n",
      "Epoch 3 / 5: 100%|██████████| 139/139 [03:11<00:00,  1.38s/ batches, avg_loss=5.29453]\n",
      "Epoch 4 / 5: 100%|██████████| 139/139 [03:12<00:00,  1.38s/ batches, avg_loss=5.29431]\n",
      "Epoch 5 / 5: 100%|██████████| 139/139 [03:12<00:00,  1.38s/ batches, avg_loss=5.29431]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "last_loss_settrans = train_epochs(\n",
    "    model_settrans,\n",
    "    optimizer_settrans,\n",
    "    CCE,\n",
    "    train_dataloader,\n",
    "    config['num_epochs'],\n",
    "    allow_gpu=True,\n",
    "    x_name=0,\n",
    "    y_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.294308185577393"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_loss_settrans.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing | Set Transformer\n",
    "Put the model in eval() mode first (prevents dropout and such from predicting sth else from the same permuted x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SetTransformerPointerCatalogNetwork(\n",
       "  (word_embedding): Embedding(300005, 32)\n",
       "  (offer_embedding): PointerOfferEmbedder(\n",
       "    (offer_rnn): GRU(32, 64, num_layers=2, batch_first=True, dropout=0.05)\n",
       "  )\n",
       "  (set_embedding): SetTransformer(\n",
       "    (emb): Sequential(\n",
       "      (0): SAB(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SAB(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (enc): Sequential(\n",
       "      (0): PMA(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SAB(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): SAB(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder): PointerEncoder(\n",
       "    (lstm): LSTM(128, 32, num_layers=2, batch_first=True, dropout=0.05, bidirectional=True)\n",
       "  )\n",
       "  (decoder): PointerDecoder(\n",
       "    (input_to_hidden): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (hidden_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (att): PointerAttention(\n",
       "      (input_linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (context_linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_settrans.eval()  # if we had dropout or batchnorm, we must do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 0.0090\n"
     ]
    }
   ],
   "source": [
    "# actual metrics\n",
    "results_settrans, _ = test_model_custom(model_settrans, test_dataloader, compare_solved_sort_unique, print_every=999999, x_name=0, y_name=1)\n",
    "print('Result: {:.4f}'.format(results_settrans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Tau: 0.2983, % valid: 100.0\n",
      "S-Rho: 0.4430, % valid: 100.0\n"
     ]
    }
   ],
   "source": [
    "# show rank correlations only with mask on\n",
    "print('K-Tau: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_settrans, get_single_kendall_tau, print_every=999999)))\n",
    "print('S-Rho: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_settrans, get_single_spearman_rho, print_every=999999)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sacred Experiment | Model Set Transformer\n",
    "We'll want to track the dataset, model params and the result of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - real_catalogs_PROCAT_mask_True - Running command 'run_model_tests'\n",
      "INFO - real_catalogs_PROCAT_mask_True - Started run with ID \"92\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'procat_models.SetTransformerPointerCatalogNetwork'>\n",
      "Result: 0.0090\n",
      "K-Tau: 0.2983, perc_valid: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - real_catalogs_PROCAT_mask_True - Result: 0.00902\n",
      "INFO - real_catalogs_PROCAT_mask_True - Completed after 0:03:18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-Rho: 0.4430, perc_valid: 100.0\n"
     ]
    }
   ],
   "source": [
    "# experiment config\n",
    "current_tested_model = model_settrans\n",
    "current_optimizer = optimizer_settrans\n",
    "current_last_loss = last_loss_settrans\n",
    "\n",
    "config_update = {\n",
    "    'model': current_tested_model.__class__.__name__,\n",
    "    'final_training_loss': round(current_last_loss.item(), 10),\n",
    "    'optimizer': current_optimizer.__class__.__name__,\n",
    "    'cfg': config,\n",
    "}\n",
    "\n",
    "# run the experiment, with updated config\n",
    "run_info = ex.run(config_updates=config_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show predictions\n",
    "See what it predicts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specific catalog prediction, with offer text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a catalog\n",
    "chosen_catalog_id = '0003leq'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show correct\n",
    "show_correct_catalog(\n",
    "    catalog_id=chosen_catalog_id,\n",
    "    catalogs_dataframe=df_catalogs,\n",
    "    offers_dataframe=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use premade function to nicely display a single prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t3cf8qqfY h: Oreo eller prince chokoladekiks 154-240 , d: 154-240 gram. Flere varianter\n",
      "\t5dbdl0fY h: Axe deodoranter Flere varianter. 150 ml., d: Flere varianter. 150 ml. • Spray\n",
      "\tdb9dGqfY h: God morgen juice Appelsin/blodgrape Appe, d: Appelsin/blodgrape Appelsin. LITER. FIND\n",
      "\t22edWqfY h: Flensted kartoffelgratin med fløde 500 g, d: med fløde 500 gram.\n",
      "\taeberqfY h: Yoggi yoghurt 1000 gram. . Flere variant, d: 1000 gram. . Flere varianter\n",
      "\t08cfm0fY h: Danpo hakket kylling 450 gram, d: 450 gram\n",
      "\t539csqfY h: Mou kødboller 650 gram, d: 650 gram\n",
      "\tac74V0fY h: Hårspray ELNETT. • Extra kraftig • Stron, d: ELNETT. • Extra kraftig • Strong hold. 4\n",
      "\t2502x0fY h: Leeuwenkuil TA' • Chenin Blanc • Shiraz , d: TA' • Chenin Blanc • Shiraz • Lion's Lai\n",
      "\t907ajqfY h: Æbler 2 kg. pink lady. vildt billigt, d: 2 kg. pink lady. vildt billigt\n",
      "\t7d7a10fY h: Nakkefilet DANSK. 1/2 KG. Skæres til nak, d: DANSK. 1/2 KG. Skæres til nakkekotelette\n",
      "\tf1a9z0fY h: Bki kaffe 500 gram. • Classic Gold • ABC, d: 500 gram. • Classic Gold • ABC - hele bø\n",
      "\t070eU0fY h: Ribena • Original • Light. 850 ml, d: • Original • Light. 850 ml\n",
      "\t0d81d0fY h: Rexona deodoranter Flere varianter. 50-1, d: Flere varianter. 50-150 ml. • Spray • Ro\n",
      "\t799dzqfY h: Frisk dansk mælk PR. LITER. Max. 24 time, d: PR. LITER. Max. 24 timer fra gård til bu\n",
      "\t183cY0fY h: Marabou chokoladebars 35-46 gram. • Fran, d: 35-46 gram. • Fransk Nougat • Marabou Or\n",
      "\t5cb900fY h: Skinkestege 700-800 gram. • Orientalsk •, d: 700-800 gram. • Orientalsk • Mexico\n",
      "\tb7fcb0fY h: Harpic Wc-blåt, d: \n",
      "\t59cchqfY h: Flødehavarti 300 gram. VILDT BILLIGT, d: 300 gram. VILDT BILLIGT\n",
      "\ta3abpqfY h: Steff houlberg • Brændende kærlighed • F, d: • Brændende kærlighed • Forloren hare • \n",
      "\te2835qfY h: Asparges FRISKE. 250 gram, d: FRISKE. 250 gram\n",
      "\tbd0fXqfY h: Riberhus 200 gram. I SKIVER. • Mellemlag, d: 200 gram. I SKIVER. • Mellemlagret\n",
      "\t18cdFqfY h: Hønskød i tern 400 gram. Kogt og klar ti, d: 400 gram. Kogt og klar til brug i f.eks.\n",
      "\t614ebqfY h: Hellmann's mayonnaise • I glas • I tube., d: • I glas • I tube. 225-400 gram\n",
      "\t1864JqfY h: Santa maria nudler 250 gram. VILDT BILLI, d: 250 gram. VILDT BILLIGT\n",
      "\tdb3fNqfY h: Andelår JULIUS. 160-200 gram. CHOK PRIS, d: JULIUS. 160-200 gram. CHOK PRIS\n",
      "\t97f9K0fY h: Kylling I ovnklar stegepose 1500 gram. H, d: I ovnklar stegepose 1500 gram. HEL DANSK\n",
      "\t3956N0fY h: Harpic wc-rens Flere varianter 750 ml. K, d: Flere varianter 750 ml. KÆMPE PARTI\n",
      "\te4e12qfY h: Frigodan • Bønnemix • Grønt m/karry • Gr, d: • Bønnemix • Grønt m/karry • Grønt m/tom\n",
      "\tc90d30fY h: Steaks Ca. 1000 gram. AF UNGKVÆG. Små fi, d: Ca. 1000 gram. AF UNGKVÆG. Små fine hver\n",
      "\t44a2IqfY h: Tulip •. 300-350 gram. • Baconpostej • K, d: •. 300-350 gram. • Baconpostej • Krydder\n",
      "\tce94wqfY h: Ice cap rejer 125 gram, d: 125 gram\n",
      "\t3531u0fY h: Bio-tex • Flydende vask. - Color - White, d: • Flydende vask. - Color - White - Black\n",
      "\t280auqfY h: Kartoffelmos 4 breve. á 125 gram. QUEEN, d: 4 breve. á 125 gram. QUEEN\n",
      "\t00b64qfY h: avokado, squash, forårsløg eller radiser, d: Bundt\n",
      "\t5b2ag0fY h: Amanda luksusrogn Pr, d: Pr\n",
      "\t36f3y0fY h: Danpo • Frikadeller • Medister. 400 gram, d: • Frikadeller • Medister. 400 gram\n",
      "\t7c1eeqfY h: Kokosmælk 17-19%. 400 ml, d: 17-19%. 400 ml\n",
      "\t0ef3QqfY h: Kyllingelår KUN 11,66 KR. PR. KG DET ER , d: KUN 11,66 KR. PR. KG DET ER BILLIGT. HEL\n",
      "\t46df6qfY h: kalanchoe eller potteroser, d: \n",
      "\t6d6e0qfY h: Carletti 73,5 gram. • Lys • Mørk. PÅLÆGS, d: 73,5 gram. • Lys • Mørk. PÅLÆGSCHOKOLADE\n",
      "\t0be3HqfY h: Spegepølser 3-STJERNET. 200-230 gram. Fl, d: 3-STJERNET. 200-230 gram. Flere variante\n",
      "\ta4c88qfY h: Hatting fransk hotdog  gigant burgerboll, d: 4-6 stk. •\n",
      "\tf4f4MqfY h: Tulip PAKKE. 200 gram. MIDDAGS- FRIKADEL, d: PAKKE. 200 gram. MIDDAGS- FRIKADELLER\n",
      "\tb84a9qfY h: bambusskud eller vandkastanjer 227 gram, d: 227 gram\n",
      "\t3030ZqfY h: Mou luksus suppe 1000 gram. Mange varian, d: 1000 gram. Mange varianter\n",
      "\t9937SqfY h: Salater 150-175 gram. GRAASTEN. Mange va, d: 150-175 gram. GRAASTEN. Mange varianter\n",
      "\ta367w0fY h: Libresse Flere varianter. • Trusseindlæg, d: Flere varianter. • Trusseindlæg • Bind\n",
      "\te4b8a0fY h: L'oréal triple active creme Flere varian, d: Flere varianter. 50 ml\n",
      "\td4f0v0fY h: Zendium FRIT VALG. • Tandpasta • Tandbør, d: FRIT VALG. • Tandpasta • Tandbørster • M\n",
      "\t88a5UqfY h: Knækbrød LEKSANDS. Flere varianter 200 g, d: LEKSANDS. Flere varianter 200 gram\n",
      "\t29c0BqfY h: stærk chili sauce, sur/sød sauce eller s, d: 200-250 ml. 100 gram\n",
      "\t0a4eEqfY h: Havregryn Ved køb af mere end 6 poser, e, d: Ved køb af mere end 6 poser, er prisen h\n",
      "\te545VqfY h: Viennetta is 650 ml. ISKOLD PRIS, d: 650 ml. ISKOLD PRIS\n",
      "\t283c80fY h: Nescafé gold STORT GLAS. • Instant kaffe, d: STORT GLAS. • Instant kaffe - Original -\n",
      "\t708e7qfY h: Cultura drik 500 ml. • Blåbær • Jordbær, d: 500 ml. • Blåbær • Jordbær\n",
      "\t28d5kqfY h: Babymajs 400 gram, d: 400 gram\n",
      "\tfb3cQ0fY h: Libero bleer • Comfort • UP&GO. 38-68 st, d: • Comfort • UP&GO. 38-68 stk. • •. 400. \n",
      "\t3672p0fY h: Duyvis nødder Flere varianter 175-225 gr, d: Flere varianter 175-225 gram\n",
      "\tb8a3DqfY h: Sukkervafler BELGISKE. 550 gram, d: BELGISKE. 550 gram\n",
      "\tb3acOqfY h: Xl lagret ost Ca. 1400 gram, d: Ca. 1400 gram\n",
      "\t029aT0fY h: Abena affaldsposer PR. SAM-PAK. 3 x, d: PR. SAM-PAK. 3 x\n",
      "\tfbff20fY h: Elvital Alle varianter. 200-250 ml. • Sh, d: Alle varianter. 200-250 ml. • Shampoo • \n",
      "\td8f9oqfY h: Margarine •. 500 gram. BINE. BILLIGST PÅ, d: •. 500 gram. BINE. BILLIGST PÅ HELE INDK\n",
      "\ta5caD0fY h: Jægerkoteletter Ca. 400 gram. Marinerede, d: Ca. 400 gram. Marinerede koteletter med \n",
      "\tef59YqfY h: Corny müslibars 6 stk. • Nuts, d: 6 stk. • Nuts\n",
      "\tc941A0fY h: Weekend menu tilberedt Komplet MENU af d, d: tilberedt Komplet MENU af de menu TIL ti\n",
      "\t50b5vqfY h: Hvidløgsbaguettes PR. 525 gram, d: PR. 525 gram\n",
      "\t4809E0fY h: Haribo POSE. DET ER BILLIGT. 100-135 gra, d: POSE. DET ER BILLIGT. 100-135 gram. • Sl\n",
      "\t11aaxqfY h: Kyllingeburger I alt 1000 gram. Af kylli, d: I alt 1000 gram. Af kyllingebrystfilet\n",
      "\tb553q0fY h: Helt kalkunbryst Ca. 800 gram, d: Ca. 800 gram\n",
      "\ta259L0fY h: Sild i spand 800/400-700 gram. • Mariner, d: 800/400-700 gram. • Marinerede hele file\n",
      "\t0ba1i0fY h: Bamseline skyllemiddel Flere varianter 1, d: Flere varianter 1000 ml.\n",
      "\t4daaRqfY h: 3-stjernet • Kødpølse • Røget medister •, d: • Kødpølse • Røget medister • Jægerpølse\n",
      "\ta6a7Z0fY h: Diamond hill 3 LITER. • Chardonnay • Shi, d: 3 LITER. • Chardonnay • Shiraz • Shiraz/\n",
      "\t431baqfY h: Toast 200-290 gram. • Pariser toast • Co, d: 200-290 gram. • Pariser toast • Cowboy t\n",
      "\tb25flqfY h: Andebryst 130-150 gram. JULIUS, d: 130-150 gram. JULIUS\n",
      "\t9381iqfY h: Tortilla chips SANTA MARIA. 185 gram. • , d: SANTA MARIA. 185 gram. • Salted • Cheese\n",
      "\t11bbPqfY h: Blomme tomater 500 gram, d: 500 gram\n",
      "\tfc78C0fY h: Hakket kalv- & flæsk . 8-12% Ca. 500 gra, d: . 8-12% Ca. 500 gram. SLAGTER NORLYK ER \n",
      "\tfed3AqfY h: Påskebryg 33 cl. KYLLE - KYLLE. 3 33. + , d: 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælg\n",
      "\t6429tqfY h: Nordjyder 500. • Frankfurter • Røde knæk, d: 500. • Frankfurter • Røde knækpølser • G\n",
      "\t067bTqfY h: Knorr • Orientalsk risret • Indisk risre, d: • Orientalsk risret • Indisk risret • Ch\n",
      "\t222fcqfY h: Bbq mørbrad 450 gram. JENSENS, d: 450 gram. JENSENS\n",
      "\t0cbffqfY h: Pålækker 80-90 gram. - Classic - Tomat. , d: 80-90 gram. - Classic - Tomat. VILDT BIL\n",
      "\tab38CqfY h: BKI KAFFE  • Extra. 400 gram. Ved køb af, d: • Extra. 400 gram. Ved køb af mere end 1\n",
      "\t4815F0fY h: Sodavand 150 cl. Flere varianter. + PANT, d: 150 cl. Flere varianter. + PANT. 3. • Ni\n",
      "\t257as0fY h: Lays chips, bugles eller doritos Sour Cr, d: Sour Cream & Onion - BBQ - Salt - • - Or\n",
      "\t0da4f0fY h: Primitivo di manduria • Carlo Sani. Denn, d: • Carlo Sani. Denne Primitivo har været \n",
      "\ta3ddnqfY h: Schulstad • Skovmand - Original - Ekstra, d: • Skovmand - Original - Ekstra grov. - M\n",
      "\td638dqfY h: Frigodan ISKOLD PRIS. • Broccoli • Fine , d: ISKOLD PRIS. • Broccoli • Fine ærter • M\n",
      "------------------------\n",
      "------------------------\n",
      "------------------------\n",
      "------------------------\n",
      "------------------------\n",
      "------------------------\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n"
     ]
    }
   ],
   "source": [
    "# show predicted\n",
    "# if the model is not permutation invariant, it will predict sth else\n",
    "# for every random permutation of the source catalog\n",
    "show_predicted_catalog(\n",
    "    catalog_id='0003leq',\n",
    "    a_model=model_settrans,\n",
    "    catalogs_dataframe=df_catalogs,\n",
    "    offers_dataframe=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist & reload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_settrans, config['model_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Tau: 0.2983, % valid: 100.0\n",
      "S-Rho: 0.4430, % valid: 100.0\n"
     ]
    }
   ],
   "source": [
    "# reload and check\n",
    "model_settrans = torch.load(config['model_path'])\n",
    "model_settrans.eval()\n",
    "print('K-Tau: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_settrans, get_single_kendall_tau, print_every=999999)))\n",
    "print('S-Rho: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_settrans, get_single_spearman_rho, print_every=999999)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from procat_models import CustomAttentionSetLayer, CustomAttentionSetEmbedder, CustomAttentionPointerCatalogNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomAttentionPointerCatalogNetwork(\n",
       "  (word_embedding): Embedding(300005, 32)\n",
       "  (offer_embedding): PointerOfferEmbedder(\n",
       "    (offer_rnn): GRU(32, 64, num_layers=2, batch_first=True, dropout=0.05)\n",
       "  )\n",
       "  (set_embedding): CustomAttentionSetEmbedder(\n",
       "    (l1): CustomAttentionSetLayer(\n",
       "      (e): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (s): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (a): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (l2): CustomAttentionSetLayer(\n",
       "      (e): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (s): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (a): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (l3): CustomAttentionSetLayer(\n",
       "      (e): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (s): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (a): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (l4): CustomAttentionSetLayer(\n",
       "      (e): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (s): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (a): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): PointerEncoder(\n",
       "    (lstm): LSTM(128, 32, num_layers=2, batch_first=True, dropout=0.05, bidirectional=True)\n",
       "  )\n",
       "  (decoder): PointerDecoder(\n",
       "    (input_to_hidden): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (hidden_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (att): PointerAttention(\n",
       "      (input_linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (context_linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the model\n",
    "model_custom = CustomAttentionPointerCatalogNetwork(\n",
    "    word_embedding_dim=config['ptr_word_emb_dim'],\n",
    "    offer_embedding_dim=config['ptr_offer_emb_dim'],\n",
    "    hidden_dim=config['ptr_hid_dim'],\n",
    "    offer_rnn_layers=config['ptr_offer_rnn_layers'],\n",
    "    catalog_rnn_layers=config['ptr_catalog_rnn_layers'],\n",
    "    dropout_offers=config['ptr_dropout_offers'],\n",
    "    dropout_catalogs=config['ptr_dropout_catalogs'],\n",
    "    bidir_offers=config['ptr_bidir_offers'],  # not handled 2021 04\n",
    "    bidir_catalogs=config['ptr_bidir_catalogs'],\n",
    "    masking=config['ptr_mask'],\n",
    "    vocab_size=len(word2idx),\n",
    ")\n",
    "\n",
    "model_custom.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 9,860,260 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# how many params\n",
    "count_params(model_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-elem batch\n",
    "batch_x = X_train_torch[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 200, 200]) torch.Size([2, 200])\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "_ = model_custom(batch_x)\n",
    "print(_[0].size(), _[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "print(_[1].type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "CCE = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer_custom = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model_custom.parameters()),\n",
    "    lr=config['learning_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training | Custom"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# test untrained model\n",
    "results, _ = test_model_custom(model_custom, test_dataloader, compare_solved_sort_unique, print_every=999999, x_name=0, y_name=1)\n",
    "print('Result: {:.4f}'.format(results))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show rank correlations only with mask on\n",
    "print('K-Tau: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_custom, get_single_kendall_tau, print_every=999999)))\n",
    "print('S-Rho: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_custom, get_single_spearman_rho, print_every=999999)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available, using GPU:\n",
      "Quadro P6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 5: 100%|██████████| 139/139 [03:15<00:00,  1.41s/ batches, avg_loss=5.29840]\n",
      "Epoch 2 / 5: 100%|██████████| 139/139 [03:15<00:00,  1.41s/ batches, avg_loss=5.29840]\n",
      "Epoch 3 / 5: 100%|██████████| 139/139 [03:15<00:00,  1.40s/ batches, avg_loss=5.29839]\n",
      "Epoch 4 / 5: 100%|██████████| 139/139 [03:14<00:00,  1.40s/ batches, avg_loss=5.29840]\n",
      "Epoch 5 / 5: 100%|██████████| 139/139 [03:14<00:00,  1.40s/ batches, avg_loss=5.29841]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "last_loss_custom = train_epochs(\n",
    "    model_custom,\n",
    "    optimizer_custom,\n",
    "    CCE,\n",
    "    train_dataloader,\n",
    "    config['num_epochs'],\n",
    "    allow_gpu=True,\n",
    "    x_name=0,\n",
    "    y_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.298410892486572"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_loss_custom.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing | Custom\n",
    "Put the model in eval() mode first (prevents dropout and such from predicting sth else from the same permuted x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomAttentionPointerCatalogNetwork(\n",
       "  (word_embedding): Embedding(300005, 32)\n",
       "  (offer_embedding): PointerOfferEmbedder(\n",
       "    (offer_rnn): GRU(32, 64, num_layers=2, batch_first=True, dropout=0.05)\n",
       "  )\n",
       "  (set_embedding): CustomAttentionSetEmbedder(\n",
       "    (l1): CustomAttentionSetLayer(\n",
       "      (e): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (s): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (a): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (l2): CustomAttentionSetLayer(\n",
       "      (e): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (s): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (a): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (l3): CustomAttentionSetLayer(\n",
       "      (e): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (s): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (a): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (l4): CustomAttentionSetLayer(\n",
       "      (e): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (s): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (a): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): PointerEncoder(\n",
       "    (lstm): LSTM(128, 32, num_layers=2, batch_first=True, dropout=0.05, bidirectional=True)\n",
       "  )\n",
       "  (decoder): PointerDecoder(\n",
       "    (input_to_hidden): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (hidden_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (att): PointerAttention(\n",
       "      (input_linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (context_linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_custom.eval()  # if we had dropout or batchnorm, we must do this"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# actual metrics\n",
    "results, _ = test_model_custom(model_custom, test_dataloader, compare_solved_sort_unique, print_every=999999, x_name=0, y_name=1)\n",
    "print('Result: {:.4f}'.format(results))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show rank correlations only with mask on\n",
    "print('K-Tau: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_custom, get_single_kendall_tau, print_every=999999)))\n",
    "print('S-Rho: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_custom, get_single_spearman_rho, print_every=999999)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sacred Experiment | Model Custom\n",
    "We'll want to track the dataset, model params and the result of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - real_catalogs_PROCAT_mask_True - Running command 'run_model_tests'\n",
      "INFO - real_catalogs_PROCAT_mask_True - Started run with ID \"93\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'procat_models.CustomAttentionPointerCatalogNetwork'>\n",
      "Result: 0.0050\n",
      "K-Tau: 0.0133, perc_valid: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - real_catalogs_PROCAT_mask_True - Result: 0.00497\n",
      "INFO - real_catalogs_PROCAT_mask_True - Completed after 0:03:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-Rho: 0.0174, perc_valid: 100.0\n"
     ]
    }
   ],
   "source": [
    "# experiment config\n",
    "current_tested_model = model_custom\n",
    "current_optimizer = optimizer_custom\n",
    "current_last_loss = last_loss_custom\n",
    "\n",
    "config_update = {\n",
    "    'model': current_tested_model.__class__.__name__,\n",
    "    'final_training_loss': round(current_last_loss.item(), 10),\n",
    "    'optimizer': current_optimizer.__class__.__name__,\n",
    "    'cfg': config,\n",
    "}\n",
    "\n",
    "# run the experiment, with updated config\n",
    "run_info = ex.run(config_updates=config_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show predictions\n",
    "See what it predicts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specific catalog prediction, with offer text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a catalog\n",
    "chosen_catalog_id = '0003leq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tfed3AqfY h: Påskebryg 33 cl. KYLLE - KYLLE. 3 33. + , d: 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælg\n",
      "\t799dzqfY h: Frisk dansk mælk PR. LITER. Max. 24 time, d: PR. LITER. Max. 24 timer fra gård til bu\n",
      "\tb8a3DqfY h: Sukkervafler BELGISKE. 550 gram, d: BELGISKE. 550 gram\n",
      "\ta4c88qfY h: Hatting fransk hotdog  gigant burgerboll, d: 4-6 stk. •\n",
      "\t3cf8qqfY h: Oreo eller prince chokoladekiks 154-240 , d: 154-240 gram. Flere varianter\n",
      "\t88a5UqfY h: Knækbrød LEKSANDS. Flere varianter 200 g, d: LEKSANDS. Flere varianter 200 gram\n",
      "\t6d6e0qfY h: Carletti 73,5 gram. • Lys • Mørk. PÅLÆGS, d: 73,5 gram. • Lys • Mørk. PÅLÆGSCHOKOLADE\n",
      "\tef59YqfY h: Corny müslibars 6 stk. • Nuts, d: 6 stk. • Nuts\n",
      "\tab38CqfY h: BKI KAFFE  • Extra. 400 gram. Ved køb af, d: • Extra. 400 gram. Ved køb af mere end 1\n",
      "\t0cbffqfY h: Pålækker 80-90 gram. - Classic - Tomat. , d: 80-90 gram. - Classic - Tomat. VILDT BIL\n",
      "\t0a4eEqfY h: Havregryn Ved køb af mere end 6 poser, e, d: Ved køb af mere end 6 poser, er prisen h\n",
      "------------------------\n",
      "\t0ef3QqfY h: Kyllingelår KUN 11,66 KR. PR. KG DET ER , d: KUN 11,66 KR. PR. KG DET ER BILLIGT. HEL\n",
      "\ta3abpqfY h: Steff houlberg • Brændende kærlighed • F, d: • Brændende kærlighed • Forloren hare • \n",
      "\tce94wqfY h: Ice cap rejer 125 gram, d: 125 gram\n",
      "\te545VqfY h: Viennetta is 650 ml. ISKOLD PRIS, d: 650 ml. ISKOLD PRIS\n",
      "\t11aaxqfY h: Kyllingeburger I alt 1000 gram. Af kylli, d: I alt 1000 gram. Af kyllingebrystfilet\n",
      "\te4e12qfY h: Frigodan • Bønnemix • Grønt m/karry • Gr, d: • Bønnemix • Grønt m/karry • Grønt m/tom\n",
      "\t431baqfY h: Toast 200-290 gram. • Pariser toast • Co, d: 200-290 gram. • Pariser toast • Cowboy t\n",
      "\t3030ZqfY h: Mou luksus suppe 1000 gram. Mange varian, d: 1000 gram. Mange varianter\n",
      "\tdb3fNqfY h: Andelår JULIUS. 160-200 gram. CHOK PRIS, d: JULIUS. 160-200 gram. CHOK PRIS\n",
      "\td638dqfY h: Frigodan ISKOLD PRIS. • Broccoli • Fine , d: ISKOLD PRIS. • Broccoli • Fine ærter • M\n",
      "\t539csqfY h: Mou kødboller 650 gram, d: 650 gram\n",
      "\tb25flqfY h: Andebryst 130-150 gram. JULIUS, d: 130-150 gram. JULIUS\n",
      "\t18cdFqfY h: Hønskød i tern 400 gram. Kogt og klar ti, d: 400 gram. Kogt og klar til brug i f.eks.\n",
      "\t50b5vqfY h: Hvidløgsbaguettes PR. 525 gram, d: PR. 525 gram\n",
      "------------------------\n",
      "\tdb9dGqfY h: God morgen juice Appelsin/blodgrape Appe, d: Appelsin/blodgrape Appelsin. LITER. FIND\n",
      "\t4daaRqfY h: 3-stjernet • Kødpølse • Røget medister •, d: • Kødpølse • Røget medister • Jægerpølse\n",
      "\tbd0fXqfY h: Riberhus 200 gram. I SKIVER. • Mellemlag, d: 200 gram. I SKIVER. • Mellemlagret\n",
      "\t9937SqfY h: Salater 150-175 gram. GRAASTEN. Mange va, d: 150-175 gram. GRAASTEN. Mange varianter\n",
      "\ta3ddnqfY h: Schulstad • Skovmand - Original - Ekstra, d: • Skovmand - Original - Ekstra grov. - M\n",
      "\t59cchqfY h: Flødehavarti 300 gram. VILDT BILLIGT, d: 300 gram. VILDT BILLIGT\n",
      "\td8f9oqfY h: Margarine •. 500 gram. BINE. BILLIGST PÅ, d: •. 500 gram. BINE. BILLIGST PÅ HELE INDK\n",
      "\t0be3HqfY h: Spegepølser 3-STJERNET. 200-230 gram. Fl, d: 3-STJERNET. 200-230 gram. Flere variante\n",
      "\tb3acOqfY h: Xl lagret ost Ca. 1400 gram, d: Ca. 1400 gram\n",
      "\taeberqfY h: Yoggi yoghurt 1000 gram. . Flere variant, d: 1000 gram. . Flere varianter\n",
      "\t44a2IqfY h: Tulip •. 300-350 gram. • Baconpostej • K, d: •. 300-350 gram. • Baconpostej • Krydder\n",
      "\t708e7qfY h: Cultura drik 500 ml. • Blåbær • Jordbær, d: 500 ml. • Blåbær • Jordbær\n",
      "\tf4f4MqfY h: Tulip PAKKE. 200 gram. MIDDAGS- FRIKADEL, d: PAKKE. 200 gram. MIDDAGS- FRIKADELLER\n",
      "------------------------\n",
      "\t2502x0fY h: Leeuwenkuil TA' • Chenin Blanc • Shiraz , d: TA' • Chenin Blanc • Shiraz • Lion's Lai\n",
      "\t070eU0fY h: Ribena • Original • Light. 850 ml, d: • Original • Light. 850 ml\n",
      "\ta6a7Z0fY h: Diamond hill 3 LITER. • Chardonnay • Shi, d: 3 LITER. • Chardonnay • Shiraz • Shiraz/\n",
      "\t183cY0fY h: Marabou chokoladebars 35-46 gram. • Fran, d: 35-46 gram. • Fransk Nougat • Marabou Or\n",
      "\t257as0fY h: Lays chips, bugles eller doritos Sour Cr, d: Sour Cream & Onion - BBQ - Salt - • - Or\n",
      "\t0da4f0fY h: Primitivo di manduria • Carlo Sani. Denn, d: • Carlo Sani. Denne Primitivo har været \n",
      "\t4809E0fY h: Haribo POSE. DET ER BILLIGT. 100-135 gra, d: POSE. DET ER BILLIGT. 100-135 gram. • Sl\n",
      "\t4815F0fY h: Sodavand 150 cl. Flere varianter. + PANT, d: 150 cl. Flere varianter. + PANT. 3. • Ni\n",
      "\tf1a9z0fY h: Bki kaffe 500 gram. • Classic Gold • ABC, d: 500 gram. • Classic Gold • ABC - hele bø\n",
      "\t3672p0fY h: Duyvis nødder Flere varianter 175-225 gr, d: Flere varianter 175-225 gram\n",
      "\t283c80fY h: Nescafé gold STORT GLAS. • Instant kaffe, d: STORT GLAS. • Instant kaffe - Original -\n",
      "------------------------\n",
      "\t29c0BqfY h: stærk chili sauce, sur/sød sauce eller s, d: 200-250 ml. 100 gram\n",
      "\t9381iqfY h: Tortilla chips SANTA MARIA. 185 gram. • , d: SANTA MARIA. 185 gram. • Salted • Cheese\n",
      "\t907ajqfY h: Æbler 2 kg. pink lady. vildt billigt, d: 2 kg. pink lady. vildt billigt\n",
      "\t28d5kqfY h: Babymajs 400 gram, d: 400 gram\n",
      "\t280auqfY h: Kartoffelmos 4 breve. á 125 gram. QUEEN, d: 4 breve. á 125 gram. QUEEN\n",
      "\t00b64qfY h: avokado, squash, forårsløg eller radiser, d: Bundt\n",
      "\t1864JqfY h: Santa maria nudler 250 gram. VILDT BILLI, d: 250 gram. VILDT BILLIGT\n",
      "\te2835qfY h: Asparges FRISKE. 250 gram, d: FRISKE. 250 gram\n",
      "\t7c1eeqfY h: Kokosmælk 17-19%. 400 ml, d: 17-19%. 400 ml\n",
      "\t067bTqfY h: Knorr • Orientalsk risret • Indisk risre, d: • Orientalsk risret • Indisk risret • Ch\n",
      "\t46df6qfY h: kalanchoe eller potteroser, d: \n",
      "\tb84a9qfY h: bambusskud eller vandkastanjer 227 gram, d: 227 gram\n",
      "\t614ebqfY h: Hellmann's mayonnaise • I glas • I tube., d: • I glas • I tube. 225-400 gram\n",
      "\t11bbPqfY h: Blomme tomater 500 gram, d: 500 gram\n",
      "------------------------\n",
      "\tb553q0fY h: Helt kalkunbryst Ca. 800 gram, d: Ca. 800 gram\n",
      "\t36f3y0fY h: Danpo • Frikadeller • Medister. 400 gram, d: • Frikadeller • Medister. 400 gram\n",
      "\t222fcqfY h: Bbq mørbrad 450 gram. JENSENS, d: 450 gram. JENSENS\n",
      "\t5cb900fY h: Skinkestege 700-800 gram. • Orientalsk •, d: 700-800 gram. • Orientalsk • Mexico\n",
      "\t7d7a10fY h: Nakkefilet DANSK. 1/2 KG. Skæres til nak, d: DANSK. 1/2 KG. Skæres til nakkekotelette\n",
      "\t97f9K0fY h: Kylling I ovnklar stegepose 1500 gram. H, d: I ovnklar stegepose 1500 gram. HEL DANSK\n",
      "\tfc78C0fY h: Hakket kalv- & flæsk . 8-12% Ca. 500 gra, d: . 8-12% Ca. 500 gram. SLAGTER NORLYK ER \n",
      "\tc90d30fY h: Steaks Ca. 1000 gram. AF UNGKVÆG. Små fi, d: Ca. 1000 gram. AF UNGKVÆG. Små fine hver\n",
      "\t5b2ag0fY h: Amanda luksusrogn Pr, d: Pr\n",
      "\tc941A0fY h: Weekend menu tilberedt Komplet MENU af d, d: tilberedt Komplet MENU af de menu TIL ti\n",
      "\ta259L0fY h: Sild i spand 800/400-700 gram. • Mariner, d: 800/400-700 gram. • Marinerede hele file\n",
      "\t6429tqfY h: Nordjyder 500. • Frankfurter • Røde knæk, d: 500. • Frankfurter • Røde knækpølser • G\n",
      "\ta5caD0fY h: Jægerkoteletter Ca. 400 gram. Marinerede, d: Ca. 400 gram. Marinerede koteletter med \n",
      "\t08cfm0fY h: Danpo hakket kylling 450 gram, d: 450 gram\n",
      "\t22edWqfY h: Flensted kartoffelgratin med fløde 500 g, d: med fløde 500 gram.\n",
      "------------------------\n",
      "\tb7fcb0fY h: Harpic Wc-blåt, d: \n",
      "\td4f0v0fY h: Zendium FRIT VALG. • Tandpasta • Tandbør, d: FRIT VALG. • Tandpasta • Tandbørster • M\n",
      "\tfb3cQ0fY h: Libero bleer • Comfort • UP&GO. 38-68 st, d: • Comfort • UP&GO. 38-68 stk. • •. 400. \n",
      "\t0ba1i0fY h: Bamseline skyllemiddel Flere varianter 1, d: Flere varianter 1000 ml.\n",
      "\ta367w0fY h: Libresse Flere varianter. • Trusseindlæg, d: Flere varianter. • Trusseindlæg • Bind\n",
      "\tac74V0fY h: Hårspray ELNETT. • Extra kraftig • Stron, d: ELNETT. • Extra kraftig • Strong hold. 4\n",
      "\t3531u0fY h: Bio-tex • Flydende vask. - Color - White, d: • Flydende vask. - Color - White - Black\n",
      "\tfbff20fY h: Elvital Alle varianter. 200-250 ml. • Sh, d: Alle varianter. 200-250 ml. • Shampoo • \n",
      "\te4b8a0fY h: L'oréal triple active creme Flere varian, d: Flere varianter. 50 ml\n",
      "\t3956N0fY h: Harpic wc-rens Flere varianter 750 ml. K, d: Flere varianter 750 ml. KÆMPE PARTI\n",
      "\t0d81d0fY h: Rexona deodoranter Flere varianter. 50-1, d: Flere varianter. 50-150 ml. • Spray • Ro\n",
      "\t029aT0fY h: Abena affaldsposer PR. SAM-PAK. 3 x, d: PR. SAM-PAK. 3 x\n",
      "\t5dbdl0fY h: Axe deodoranter Flere varianter. 150 ml., d: Flere varianter. 150 ml. • Spray\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n"
     ]
    }
   ],
   "source": [
    "# show correct\n",
    "show_correct_catalog(\n",
    "    catalog_id=chosen_catalog_id,\n",
    "    catalogs_dataframe=df_catalogs,\n",
    "    offers_dataframe=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t5cb900fY h: Skinkestege 700-800 gram. • Orientalsk •, d: 700-800 gram. • Orientalsk • Mexico\n",
      "\t0ef3QqfY h: Kyllingelår KUN 11,66 KR. PR. KG DET ER , d: KUN 11,66 KR. PR. KG DET ER BILLIGT. HEL\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tc90d30fY h: Steaks Ca. 1000 gram. AF UNGKVÆG. Små fi, d: Ca. 1000 gram. AF UNGKVÆG. Små fine hver\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t431baqfY h: Toast 200-290 gram. • Pariser toast • Co, d: 200-290 gram. • Pariser toast • Cowboy t\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t11bbPqfY h: Blomme tomater 500 gram, d: 500 gram\n",
      "\ta4c88qfY h: Hatting fransk hotdog  gigant burgerboll, d: 4-6 stk. •\n",
      "\ta5caD0fY h: Jægerkoteletter Ca. 400 gram. Marinerede, d: Ca. 400 gram. Marinerede koteletter med \n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tb553q0fY h: Helt kalkunbryst Ca. 800 gram, d: Ca. 800 gram\n",
      "\t3956N0fY h: Harpic wc-rens Flere varianter 750 ml. K, d: Flere varianter 750 ml. KÆMPE PARTI\n",
      "\t283c80fY h: Nescafé gold STORT GLAS. • Instant kaffe, d: STORT GLAS. • Instant kaffe - Original -\n",
      "\t88a5UqfY h: Knækbrød LEKSANDS. Flere varianter 200 g, d: LEKSANDS. Flere varianter 200 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\ta6a7Z0fY h: Diamond hill 3 LITER. • Chardonnay • Shi, d: 3 LITER. • Chardonnay • Shiraz • Shiraz/\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t9381iqfY h: Tortilla chips SANTA MARIA. 185 gram. • , d: SANTA MARIA. 185 gram. • Salted • Cheese\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\ta3abpqfY h: Steff houlberg • Brændende kærlighed • F, d: • Brændende kærlighed • Forloren hare • \n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t22edWqfY h: Flensted kartoffelgratin med fløde 500 g, d: med fløde 500 gram.\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tb3acOqfY h: Xl lagret ost Ca. 1400 gram, d: Ca. 1400 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t614ebqfY h: Hellmann's mayonnaise • I glas • I tube., d: • I glas • I tube. 225-400 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t1864JqfY h: Santa maria nudler 250 gram. VILDT BILLI, d: 250 gram. VILDT BILLIGT\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t29c0BqfY h: stærk chili sauce, sur/sød sauce eller s, d: 200-250 ml. 100 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "------------------------\n",
      "\t5dbdl0fY h: Axe deodoranter Flere varianter. 150 ml., d: Flere varianter. 150 ml. • Spray\n",
      "\t539csqfY h: Mou kødboller 650 gram, d: 650 gram\n",
      "\t0cbffqfY h: Pålækker 80-90 gram. - Classic - Tomat. , d: 80-90 gram. - Classic - Tomat. VILDT BIL\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t28d5kqfY h: Babymajs 400 gram, d: 400 gram\n",
      "\t6429tqfY h: Nordjyder 500. • Frankfurter • Røde knæk, d: 500. • Frankfurter • Røde knækpølser • G\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t97f9K0fY h: Kylling I ovnklar stegepose 1500 gram. H, d: I ovnklar stegepose 1500 gram. HEL DANSK\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\te4b8a0fY h: L'oréal triple active creme Flere varian, d: Flere varianter. 50 ml\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tab38CqfY h: BKI KAFFE  • Extra. 400 gram. Ved køb af, d: • Extra. 400 gram. Ved køb af mere end 1\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t3672p0fY h: Duyvis nødder Flere varianter 175-225 gr, d: Flere varianter 175-225 gram\n",
      "\tac74V0fY h: Hårspray ELNETT. • Extra kraftig • Stron, d: ELNETT. • Extra kraftig • Strong hold. 4\n",
      "\t ?NOT_REAL_OFFER?\n",
      "------------------------\n",
      "\t08cfm0fY h: Danpo hakket kylling 450 gram, d: 450 gram\n",
      "\tf1a9z0fY h: Bki kaffe 500 gram. • Classic Gold • ABC, d: 500 gram. • Classic Gold • ABC - hele bø\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\te545VqfY h: Viennetta is 650 ml. ISKOLD PRIS, d: 650 ml. ISKOLD PRIS\n",
      "\tfbff20fY h: Elvital Alle varianter. 200-250 ml. • Sh, d: Alle varianter. 200-250 ml. • Shampoo • \n",
      "\t ?NOT_REAL_OFFER?\n",
      "\ta367w0fY h: Libresse Flere varianter. • Trusseindlæg, d: Flere varianter. • Trusseindlæg • Bind\n",
      "\tb84a9qfY h: bambusskud eller vandkastanjer 227 gram, d: 227 gram\n",
      "\t59cchqfY h: Flødehavarti 300 gram. VILDT BILLIGT, d: 300 gram. VILDT BILLIGT\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t3531u0fY h: Bio-tex • Flydende vask. - Color - White, d: • Flydende vask. - Color - White - Black\n",
      "\tdb3fNqfY h: Andelår JULIUS. 160-200 gram. CHOK PRIS, d: JULIUS. 160-200 gram. CHOK PRIS\n",
      "\tfb3cQ0fY h: Libero bleer • Comfort • UP&GO. 38-68 st, d: • Comfort • UP&GO. 38-68 stk. • •. 400. \n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t11aaxqfY h: Kyllingeburger I alt 1000 gram. Af kylli, d: I alt 1000 gram. Af kyllingebrystfilet\n",
      "\t0da4f0fY h: Primitivo di manduria • Carlo Sani. Denn, d: • Carlo Sani. Denne Primitivo har været \n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\ta259L0fY h: Sild i spand 800/400-700 gram. • Mariner, d: 800/400-700 gram. • Marinerede hele file\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t0be3HqfY h: Spegepølser 3-STJERNET. 200-230 gram. Fl, d: 3-STJERNET. 200-230 gram. Flere variante\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t3030ZqfY h: Mou luksus suppe 1000 gram. Mange varian, d: 1000 gram. Mange varianter\n",
      "\t0ba1i0fY h: Bamseline skyllemiddel Flere varianter 1, d: Flere varianter 1000 ml.\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\taeberqfY h: Yoggi yoghurt 1000 gram. . Flere variant, d: 1000 gram. . Flere varianter\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t708e7qfY h: Cultura drik 500 ml. • Blåbær • Jordbær, d: 500 ml. • Blåbær • Jordbær\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\td4f0v0fY h: Zendium FRIT VALG. • Tandpasta • Tandbør, d: FRIT VALG. • Tandpasta • Tandbørster • M\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t3cf8qqfY h: Oreo eller prince chokoladekiks 154-240 , d: 154-240 gram. Flere varianter\n",
      "\t257as0fY h: Lays chips, bugles eller doritos Sour Cr, d: Sour Cream & Onion - BBQ - Salt - • - Or\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t5b2ag0fY h: Amanda luksusrogn Pr, d: Pr\n",
      "\t00b64qfY h: avokado, squash, forårsløg eller radiser, d: Bundt\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t070eU0fY h: Ribena • Original • Light. 850 ml, d: • Original • Light. 850 ml\n",
      "\t183cY0fY h: Marabou chokoladebars 35-46 gram. • Fran, d: 35-46 gram. • Fransk Nougat • Marabou Or\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tfc78C0fY h: Hakket kalv- & flæsk . 8-12% Ca. 500 gra, d: . 8-12% Ca. 500 gram. SLAGTER NORLYK ER \n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t280auqfY h: Kartoffelmos 4 breve. á 125 gram. QUEEN, d: 4 breve. á 125 gram. QUEEN\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\te4e12qfY h: Frigodan • Bønnemix • Grønt m/karry • Gr, d: • Bønnemix • Grønt m/karry • Grønt m/tom\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t4daaRqfY h: 3-stjernet • Kødpølse • Røget medister •, d: • Kødpølse • Røget medister • Jægerpølse\n",
      "\t50b5vqfY h: Hvidløgsbaguettes PR. 525 gram, d: PR. 525 gram\n",
      "\t4809E0fY h: Haribo POSE. DET ER BILLIGT. 100-135 gra, d: POSE. DET ER BILLIGT. 100-135 gram. • Sl\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tc941A0fY h: Weekend menu tilberedt Komplet MENU af d, d: tilberedt Komplet MENU af de menu TIL ti\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tce94wqfY h: Ice cap rejer 125 gram, d: 125 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t6d6e0qfY h: Carletti 73,5 gram. • Lys • Mørk. PÅLÆGS, d: 73,5 gram. • Lys • Mørk. PÅLÆGSCHOKOLADE\n",
      "\t067bTqfY h: Knorr • Orientalsk risret • Indisk risre, d: • Orientalsk risret • Indisk risret • Ch\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t7d7a10fY h: Nakkefilet DANSK. 1/2 KG. Skæres til nak, d: DANSK. 1/2 KG. Skæres til nakkekotelette\n",
      "\t029aT0fY h: Abena affaldsposer PR. SAM-PAK. 3 x, d: PR. SAM-PAK. 3 x\n",
      "\tfed3AqfY h: Påskebryg 33 cl. KYLLE - KYLLE. 3 33. + , d: 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælg\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t2502x0fY h: Leeuwenkuil TA' • Chenin Blanc • Shiraz , d: TA' • Chenin Blanc • Shiraz • Lion's Lai\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tb8a3DqfY h: Sukkervafler BELGISKE. 550 gram, d: BELGISKE. 550 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tb25flqfY h: Andebryst 130-150 gram. JULIUS, d: 130-150 gram. JULIUS\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tb7fcb0fY h: Harpic Wc-blåt, d: \n",
      "\tbd0fXqfY h: Riberhus 200 gram. I SKIVER. • Mellemlag, d: 200 gram. I SKIVER. • Mellemlagret\n",
      "\te2835qfY h: Asparges FRISKE. 250 gram, d: FRISKE. 250 gram\n",
      "\t907ajqfY h: Æbler 2 kg. pink lady. vildt billigt, d: 2 kg. pink lady. vildt billigt\n",
      "\t9937SqfY h: Salater 150-175 gram. GRAASTEN. Mange va, d: 150-175 gram. GRAASTEN. Mange varianter\n",
      "\t7c1eeqfY h: Kokosmælk 17-19%. 400 ml, d: 17-19%. 400 ml\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tf4f4MqfY h: Tulip PAKKE. 200 gram. MIDDAGS- FRIKADEL, d: PAKKE. 200 gram. MIDDAGS- FRIKADELLER\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tef59YqfY h: Corny müslibars 6 stk. • Nuts, d: 6 stk. • Nuts\n",
      "\t18cdFqfY h: Hønskød i tern 400 gram. Kogt og klar ti, d: 400 gram. Kogt og klar til brug i f.eks.\n",
      "\td8f9oqfY h: Margarine •. 500 gram. BINE. BILLIGST PÅ, d: •. 500 gram. BINE. BILLIGST PÅ HELE INDK\n",
      "\t44a2IqfY h: Tulip •. 300-350 gram. • Baconpostej • K, d: •. 300-350 gram. • Baconpostej • Krydder\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t4815F0fY h: Sodavand 150 cl. Flere varianter. + PANT, d: 150 cl. Flere varianter. + PANT. 3. • Ni\n",
      "\t799dzqfY h: Frisk dansk mælk PR. LITER. Max. 24 time, d: PR. LITER. Max. 24 timer fra gård til bu\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\td638dqfY h: Frigodan ISKOLD PRIS. • Broccoli • Fine , d: ISKOLD PRIS. • Broccoli • Fine ærter • M\n",
      "\t36f3y0fY h: Danpo • Frikadeller • Medister. 400 gram, d: • Frikadeller • Medister. 400 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tdb9dGqfY h: God morgen juice Appelsin/blodgrape Appe, d: Appelsin/blodgrape Appelsin. LITER. FIND\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\ta3ddnqfY h: Schulstad • Skovmand - Original - Ekstra, d: • Skovmand - Original - Ekstra grov. - M\n",
      "\t0d81d0fY h: Rexona deodoranter Flere varianter. 50-1, d: Flere varianter. 50-150 ml. • Spray • Ro\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t46df6qfY h: kalanchoe eller potteroser, d: \n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t222fcqfY h: Bbq mørbrad 450 gram. JENSENS, d: 450 gram. JENSENS\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t0a4eEqfY h: Havregryn Ved køb af mere end 6 poser, e, d: Ved køb af mere end 6 poser, er prisen h\n"
     ]
    }
   ],
   "source": [
    "# show predicted\n",
    "# if the model is not permutation invariant, it will predict sth else\n",
    "# for every random permutation of the source catalog\n",
    "show_predicted_catalog(\n",
    "    catalog_id='0003leq',\n",
    "    a_model=model_custom,\n",
    "    catalogs_dataframe=df_catalogs,\n",
    "    offers_dataframe=df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

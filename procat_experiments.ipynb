{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCAT Experiments\n",
    "\n",
    "In this notebook, we run experiments on the 10K set of real catalogues from the PROCAT dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn import Parameter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# sacred\n",
    "from sacred import Experiment\n",
    "from sacred.observers import MongoObserver\n",
    "\n",
    "# text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from itertools import chain\n",
    "import nltk  # had to also run nltk.download('punkt')\n",
    "\n",
    "# visuals\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show full width tables\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom utils\n",
    "from utils import count_params, train_epochs\n",
    "from data import test_model_custom, compare_solved_sort_unique, \\\n",
    "    get_single_kendall_tau, get_single_spearman_rho, get_batch_rank_correlation, get_batch_rank_correlation_and_perc_valid\n",
    "from procat_utils import get_catalogs_with_full_info, show_predicted_catalog, show_correct_catalog, get_prediction_as_offers, print_predicted_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload if saved changes in modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacred experiment\n",
    "config['ptr_mask'] = True\n",
    "config['dataset_folder'] = 'PROCAT_mini'\n",
    "config['dataset_name'] = config['dataset_folder']\n",
    "config['task'] = 'real_catalogs'\n",
    "config['experiment_name'] = config['task'] + '_' + config['dataset_folder'] + '_mask_' + str(config['ptr_mask'])\n",
    "config['db_name'] = 'sacred'\n",
    "config['db_url'] = 'localhost:27017'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture\n",
    "config['ptr_word_emb_dim'] = 32\n",
    "config['ptr_offer_emb_dim'] = 64\n",
    "config['ptr_hid_dim'] = 64\n",
    "config['ptr_offer_rnn_layers'] = 2\n",
    "config['ptr_catalog_rnn_layers'] = 2\n",
    "config['ptr_dropout_catalogs'] = 0.05\n",
    "config['ptr_dropout_offers'] = 0.05\n",
    "config['ptr_bidir_catalogs'] = True\n",
    "config['ptr_bidir_offers'] = False  # not handled 2021 04\n",
    "\n",
    "# training\n",
    "config['batch_size'] = 64\n",
    "config['learning_rate'] =  0.0001\n",
    "config['num_epochs'] = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv size\n",
    "config['test_small_size'] = 300\n",
    "\n",
    "# text preprocessing\n",
    "config['vocab_max'] =  300000 # vocabulary cap (for tokens)\n",
    "config['unknown_token'] = '?UNK?'\n",
    "config['eos_token'] = '?EOS?'\n",
    "config['pad_token'] = '?PAD?'\n",
    "config['max_tokens'] = 30\n",
    "\n",
    "# catalog preprocessing\n",
    "config['page_break_token'] = '?PAGE_BREAK?'\n",
    "config['page_break_priority'] = 0\n",
    "config['max_offer_tokens_per_catalog'] = 200  # choose based on distributions, includes page-breaks\n",
    "config['pad_not_real_offer'] = '?NOT_REAL_OFFER?'\n",
    "config['pad_not_real_offer_priority'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Config paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "config['path_in_df_offers_csv'] = 'data/real_catalogs/{}/offer_features.csv'.format(config['dataset_folder'])\n",
    "config['path_in_df_sections_csv'] = 'data/real_catalogs/{}/section_features.csv'.format(config['dataset_folder'])\n",
    "config['path_in_df_catalog_csv'] = 'data/real_catalogs/{}/catalog_features.csv'.format(config['dataset_folder'])\n",
    "\n",
    "config['path_in_df_catalog_train_csv'] = 'data/real_catalogs/{}/catalog_train_set_features.csv'.format(config['dataset_folder'])\n",
    "config['path_in_df_catalog_test_csv'] = 'data/real_catalogs/{}/catalog_test_set_features.csv'.format(config['dataset_folder'])\n",
    "\n",
    "config['path_in_dictionary'] = 'data/real_catalogs/{}/dictionary.pickle'.format(config['dataset_folder'])\n",
    "config['path_in_catalog_id_to_section_ids'] = 'data/real_catalogs/{}/catalog_to_sections.pickle'.format(config['dataset_folder'])\n",
    "\n",
    "config['path_in_section_id_to_offer_ids'] = 'data/real_catalogs/{}/section_to_offers.pickle'.format(config['dataset_folder'])\n",
    "config['path_in_section_id_to_offer_vectors'] = 'data/real_catalogs/{}/section_id_to_offer_vectors.pickle'.format(config['dataset_folder'])\n",
    "config['path_in_section_id_to_section_num'] = 'data/real_catalogs/{}/section_to_number.pickle'.format(config['dataset_folder'])\n",
    "config['path_in_section_id_to_offer_priorities'] = 'data/real_catalogs/{}/section_id_to_offer_priorities.pickle'.format(config['dataset_folder'])\n",
    "\n",
    "config['path_in_offer_id_to_priority'] = 'data/real_catalogs/{}/offer_to_priority.pickle'.format(config['dataset_folder'])\n",
    "config['path_in_offer_id_to_vector'] = 'data/real_catalogs/{}/offer_to_vector.pickle'.format(config['dataset_folder'])\n",
    "\n",
    "config['path_in_np_X_train'] = 'data/real_catalogs/{}/X_train.npy'.format(config['dataset_folder'])\n",
    "config['path_in_np_Y_train'] = 'data/real_catalogs/{}/Y_train.npy'.format(config['dataset_folder'])\n",
    "config['path_in_np_X_test'] = 'data/real_catalogs/{}/X_test.npy'.format(config['dataset_folder'])\n",
    "config['path_in_np_Y_test'] = 'data/real_catalogs/{}/Y_test.npy'.format(config['dataset_folder'])\n",
    "\n",
    "config['path_in_torch_X_train'] = 'data/real_catalogs/{}/X_train.pb'.format(config['dataset_folder'])\n",
    "config['path_in_torch_Y_train'] = 'data/real_catalogs/{}/Y_train.pb'.format(config['dataset_folder'])\n",
    "config['path_in_torch_X_test'] = 'data/real_catalogs/{}/X_test.pb'.format(config['dataset_folder'])\n",
    "config['path_in_torch_Y_test'] = 'data/real_catalogs/{}/Y_test.pb'.format(config['dataset_folder'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ptr_mask': True,\n",
       " 'dataset_folder': 'SIGIR',\n",
       " 'dataset_name': 'SIGIR',\n",
       " 'task': 'real_catalogs',\n",
       " 'experiment_name': 'real_catalogs_SIGIR_mask_True',\n",
       " 'db_name': 'sacred',\n",
       " 'db_url': 'localhost:27017',\n",
       " 'ptr_word_emb_dim': 32,\n",
       " 'ptr_offer_emb_dim': 64,\n",
       " 'ptr_hid_dim': 64,\n",
       " 'ptr_offer_rnn_layers': 2,\n",
       " 'ptr_catalog_rnn_layers': 2,\n",
       " 'ptr_dropout_catalogs': 0.05,\n",
       " 'ptr_dropout_offers': 0.05,\n",
       " 'ptr_bidir_catalogs': True,\n",
       " 'ptr_bidir_offers': False,\n",
       " 'batch_size': 64,\n",
       " 'learning_rate': 0.0001,\n",
       " 'num_epochs': 150,\n",
       " 'test_small_size': 300,\n",
       " 'vocab_max': 300000,\n",
       " 'unknown_token': '?UNK?',\n",
       " 'eos_token': '?EOS?',\n",
       " 'pad_token': '?PAD?',\n",
       " 'max_tokens': 30,\n",
       " 'page_break_token': '?PAGE_BREAK?',\n",
       " 'page_break_priority': 0,\n",
       " 'max_offer_tokens_per_catalog': 200,\n",
       " 'pad_not_real_offer': '?NOT_REAL_OFFER?',\n",
       " 'pad_not_real_offer_priority': -1,\n",
       " 'path_in_df_offers_csv': 'data/real_catalogs/SIGIR/offer_features.csv',\n",
       " 'path_in_df_sections_csv': 'data/real_catalogs/SIGIR/section_features.csv',\n",
       " 'path_in_df_catalog_csv': 'data/real_catalogs/SIGIR/catalog_features.csv',\n",
       " 'path_in_df_catalog_train_csv': 'data/real_catalogs/SIGIR/catalog_train_set_features.csv',\n",
       " 'path_in_df_catalog_test_csv': 'data/real_catalogs/SIGIR/catalog_test_set_features.csv',\n",
       " 'path_in_dictionary': 'data/real_catalogs/SIGIR/dictionary.pickle',\n",
       " 'path_in_catalog_id_to_section_ids': 'data/real_catalogs/SIGIR/catalog_to_sections.pickle',\n",
       " 'path_in_section_id_to_offer_ids': 'data/real_catalogs/SIGIR/section_to_offers.pickle',\n",
       " 'path_in_section_id_to_offer_vectors': 'data/real_catalogs/SIGIR/section_id_to_offer_vectors.pickle',\n",
       " 'path_in_section_id_to_section_num': 'data/real_catalogs/SIGIR/section_to_number.pickle',\n",
       " 'path_in_section_id_to_offer_priorities': 'data/real_catalogs/SIGIR/section_id_to_offer_priorities.pickle',\n",
       " 'path_in_offer_id_to_priority': 'data/real_catalogs/SIGIR/offer_to_priority.pickle',\n",
       " 'path_in_offer_id_to_vector': 'data/real_catalogs/SIGIR/offer_to_vector.pickle',\n",
       " 'path_in_np_X_train': 'data/real_catalogs/SIGIR/X_train.npy',\n",
       " 'path_in_np_Y_train': 'data/real_catalogs/SIGIR/Y_train.npy',\n",
       " 'path_in_np_X_test': 'data/real_catalogs/SIGIR/X_test.npy',\n",
       " 'path_in_np_Y_test': 'data/real_catalogs/SIGIR/Y_test.npy',\n",
       " 'path_in_torch_X_train': 'data/real_catalogs/SIGIR/X_train.pb',\n",
       " 'path_in_torch_Y_train': 'data/real_catalogs/SIGIR/Y_train.pb',\n",
       " 'path_in_torch_X_test': 'data/real_catalogs/SIGIR/X_test.pb',\n",
       " 'path_in_torch_Y_test': 'data/real_catalogs/SIGIR/Y_test.pb'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Tracking via Sacred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the experiment\n",
    "ex = Experiment(name=config['experiment_name'], interactive=True)\n",
    "\n",
    "# add an observer, storing experiment info\n",
    "ex.observers.append(MongoObserver(url=config['db_url'], db_name=config['db_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment config\n",
    "@ex.config\n",
    "def ex_config():\n",
    "    \n",
    "    # general\n",
    "    learning_rate = config['learning_rate']\n",
    "    dataset = config['dataset_name'] \n",
    "    epochs = config['num_epochs']\n",
    "    cfg = config\n",
    "    \n",
    "    # model\n",
    "    model = None\n",
    "    final_training_loss = None\n",
    "    optimizer = None\n",
    "    \n",
    "    # db \n",
    "    db_name = config['db_name']\n",
    "    db_url = config['db_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment run function\n",
    "@ex.main\n",
    "def run_model_tests():\n",
    "\n",
    "    # run all tests, get all results\n",
    "    result_general, result_tau, result_spearman, rank_valid_perc = run_tests(current_tested_model, test_dataloader, config)\n",
    "    \n",
    "    # log params and results\n",
    "    log_experiment_results(result_general, result_tau, result_spearman, rank_valid_perc)\n",
    "    \n",
    "    return round(result_general, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests(a_model, a_dataloader, a_config):\n",
    "    \n",
    "    print('Model: ', a_model.__class__)\n",
    "\n",
    "    a_model.eval() \n",
    "    \n",
    "    # general accuracy\n",
    "    result_general, _ = test_model_custom(a_model, a_dataloader, compare_solved_sort_unique, print_every=999999, x_name=0, y_name=1)\n",
    "    print('Result: {:.4f}'.format(result_general))\n",
    "    \n",
    "    result_tau, rank_valid_perc = get_batch_rank_correlation_and_perc_valid(a_dataloader, a_model, get_single_kendall_tau, print_every=999999)\n",
    "    print('K-Tau: {:.4f}, perc_valid: {}'.format(result_tau, rank_valid_perc))\n",
    "\n",
    "    result_spearman, rank_valid_perc = get_batch_rank_correlation_and_perc_valid(a_dataloader, a_model, get_single_spearman_rho, print_every=999999)\n",
    "    print('S-Rho: {:.4f}, perc_valid: {}'.format(result_spearman, rank_valid_perc))\n",
    "\n",
    "    a_model.train()\n",
    "    \n",
    "    return result_general, result_tau, result_spearman, rank_valid_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_experiment_results(r_general, r_tau, r_spearman, rank_valid_perc):\n",
    "    \n",
    "    # round if not none\n",
    "    if r_tau:\n",
    "        r_tau = round(r_tau, 5)\n",
    "    if r_spearman:\n",
    "        r_spearman = round(r_spearman, 5)\n",
    "    \n",
    "    # log the results\n",
    "    ex.log_scalar('test.general', r_general)\n",
    "    ex.log_scalar('test.rank_correlation_valid_perc', rank_valid_perc)\n",
    "    ex.log_scalar('test.tau', r_tau, 5)\n",
    "    ex.log_scalar('test.rho', r_spearman, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_unshuffled_x(x, y):\n",
    "    r = [x[i] for i in y]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(220788)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example(a_dataloader, x_name=0, y_name=1):\n",
    "    \"\"\"\n",
    "    Take a torch dataloader and get a single example.\n",
    "    \"\"\"\n",
    "    a_batch = next(iter(a_dataloader))\n",
    "    example_points = a_batch[x_name][0]\n",
    "    example_solution = a_batch[y_name][0]\n",
    "\n",
    "    return example_points, example_solution\n",
    "\n",
    "\n",
    "def get_batch(a_dataloader, x_name=0, y_name=1):\n",
    "    \"\"\"\n",
    "    Get a batch of points and solutions from a torch dataloader.\n",
    "    \"\"\"\n",
    "    a_batch = next(iter(a_dataloader))\n",
    "    batch_points = a_batch[x_name]\n",
    "    batch_solutions = a_batch[y_name]\n",
    "\n",
    "    return batch_points, batch_solutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "Load all needed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload Data\n",
    "Including:\n",
    "- **SIGIR csv's**\n",
    "    - df_offers\n",
    "    - df_sections\n",
    "    - df_catalogs\n",
    "- **any meta-resources**:\n",
    "    - (word2idx)\n",
    "    - section to offer ids etc?\n",
    "- **numpy X and Y**\n",
    "    - train and test separately\n",
    "- **torch dataloaders**\n",
    "    - the actual torch dataloaders (for myself?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog_id</th>\n",
       "      <th>section</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>priority</th>\n",
       "      <th>heading</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>token_length</th>\n",
       "      <th>offer_as_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0003leq</td>\n",
       "      <td>1</td>\n",
       "      <td>fed3AqfY</td>\n",
       "      <td>2</td>\n",
       "      <td>Påskebryg</td>\n",
       "      <td>33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælges fra fredag d. 17/3. Ved køb af mere end 60 stk., er prisen herefter 4,98 kr</td>\n",
       "      <td>Påskebryg 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælges fra fredag d. 17/3. Ved køb af mere end 60 stk., er prisen herefter 4,98 kr</td>\n",
       "      <td>['påskebryg', '33', 'cl', '.', 'kylle', '-', 'kylle', '.', '3', '33', '.', '+', 'pant', '.', 'sælges', 'fra', 'fredag', 'd.', '17/3', '.', 'ved', 'køb', 'af', 'mere', 'end', '60', 'stk.', ',', 'er', '?EOS?']</td>\n",
       "      <td>33</td>\n",
       "      <td>[10912, 250, 50, 5, 16874, 18, 16874, 5, 35, 250, 5, 82, 128, 5, 267, 46, 2199, 147, 41453, 5, 93, 210, 22, 182, 227, 106, 3845, 6, 31, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  catalog_id  section  offer_id  priority    heading                                                                                                             description                                                                                                                              text                                                                                                                                                                                                   text_tokenized  token_length                                                                                                                             offer_as_vector\n",
       "0  0003leq    1        fed3AqfY  2         Påskebryg  33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælges fra fredag d. 17/3. Ved køb af mere end 60 stk., er prisen herefter 4,98 kr  Påskebryg 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælges fra fredag d. 17/3. Ved køb af mere end 60 stk., er prisen herefter 4,98 kr  ['påskebryg', '33', 'cl', '.', 'kylle', '-', 'kylle', '.', '3', '33', '.', '+', 'pant', '.', 'sælges', 'fra', 'fredag', 'd.', '17/3', '.', 'ved', 'køb', 'af', 'mere', 'end', '60', 'stk.', ',', 'er', '?EOS?']  33            [10912, 250, 50, 5, 16874, 18, 16874, 5, 35, 250, 5, 82, 128, 5, 267, 46, 2199, 147, 41453, 5, 93, 210, 22, 182, 227, 106, 3845, 6, 31, 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(config['path_in_df_offers_csv'], sep=';')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1613686"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog_id</th>\n",
       "      <th>section_id</th>\n",
       "      <th>section_num</th>\n",
       "      <th>offer_ids</th>\n",
       "      <th>offer_vectors</th>\n",
       "      <th>offer_priorities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0003leq</td>\n",
       "      <td>0003leq_1</td>\n",
       "      <td>1</td>\n",
       "      <td>['fed3AqfY', '799dzqfY', 'b8a3DqfY', 'a4c88qfY', '3cf8qqfY', '88a5UqfY', '6d6e0qfY', 'ef59YqfY', 'ab38CqfY', '0cbffqfY', '0a4eEqfY']</td>\n",
       "      <td>[[10912, 250, 50, 5, 16874, 18, 16874, 5, 35, 250, 5, 82, 128, 5, 267, 46, 2199, 147, 41453, 5, 93, 210, 22, 182, 227, 106, 3845, 6, 31, 0], [408, 99, 1024, 15, 5, 29, 5, 37, 5, 136, 141, 46, 5612, 13, 1763, 7, 3228, 7, 4673, 7, 6008, 7, 6644, 0, 1, 1, 1, 1, 1, 1], [50781, 17910, 5, 967, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1163, 712, 1063, 3313, 2145, 3686, 27, 5, 7, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1362, 16, 3494, 4462, 34761, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1585, 26725, 5, 19, 20, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [932, 11768, 21, 5, 7, 140, 7, 420, 5, 1787, 5, 168, 104, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3772, 3048, 65, 27, 5, 7, 6182, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [882, 248, 7, 578, 5, 79, 21, 5, 93, 210, 22, 182, 227, 57, 425, 6, 31, 200, 202, 7012, 102, 5, 75, 31, 336, 160, 0, 1, 1, 1], [1587, 3925, 21, 5, 18, 152, 18, 465, 5, 688, 336, 5, 7, 727, 7, 800, 7, 1761, 2026, 7, 189, 9, 518, 7, 2168, 7, 272, 1004, 7, 0], [2359, 93, 210, 22, 182, 227, 65, 425, 6, 31, 200, 202, 11439, 102, 5, 112, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]</td>\n",
       "      <td>[2, 2, 1, 1, 2, 1, 1, 1, 3, 3, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  catalog_id section_id  section_num                                                                                                                             offer_ids                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      offer_vectors                   offer_priorities\n",
       "0  0003leq    0003leq_1  1            ['fed3AqfY', '799dzqfY', 'b8a3DqfY', 'a4c88qfY', '3cf8qqfY', '88a5UqfY', '6d6e0qfY', 'ef59YqfY', 'ab38CqfY', '0cbffqfY', '0a4eEqfY']  [[10912, 250, 50, 5, 16874, 18, 16874, 5, 35, 250, 5, 82, 128, 5, 267, 46, 2199, 147, 41453, 5, 93, 210, 22, 182, 227, 106, 3845, 6, 31, 0], [408, 99, 1024, 15, 5, 29, 5, 37, 5, 136, 141, 46, 5612, 13, 1763, 7, 3228, 7, 4673, 7, 6008, 7, 6644, 0, 1, 1, 1, 1, 1, 1], [50781, 17910, 5, 967, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1163, 712, 1063, 3313, 2145, 3686, 27, 5, 7, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1362, 16, 3494, 4462, 34761, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1585, 26725, 5, 19, 20, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [932, 11768, 21, 5, 7, 140, 7, 420, 5, 1787, 5, 168, 104, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3772, 3048, 65, 27, 5, 7, 6182, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [882, 248, 7, 578, 5, 79, 21, 5, 93, 210, 22, 182, 227, 57, 425, 6, 31, 200, 202, 7012, 102, 5, 75, 31, 336, 160, 0, 1, 1, 1], [1587, 3925, 21, 5, 18, 152, 18, 465, 5, 688, 336, 5, 7, 727, 7, 800, 7, 1761, 2026, 7, 189, 9, 518, 7, 2168, 7, 272, 1004, 7, 0], [2359, 93, 210, 22, 182, 227, 65, 425, 6, 31, 200, 202, 11439, 102, 5, 112, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]  [2, 2, 1, 1, 2, 1, 1, 1, 3, 3, 2]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sections = pd.read_csv(config['path_in_df_sections_csv'], sep=';')\n",
    "df_sections.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238256"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog_id</th>\n",
       "      <th>section_ids</th>\n",
       "      <th>offer_ids_with_pb</th>\n",
       "      <th>offer_vectors_with_pb</th>\n",
       "      <th>offer_priorities_with_pb</th>\n",
       "      <th>num_offers</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0003leq</td>\n",
       "      <td>{'0003leq_1', '0003leq_2', '0003leq_4', '0003leq_6', '0003leq_3', '0003leq_5', '0003leq_7'}</td>\n",
       "      <td>['fed3AqfY', '799dzqfY', 'b8a3DqfY', 'a4c88qfY', '3cf8qqfY', '88a5UqfY', '6d6e0qfY', 'ef59YqfY', 'ab38CqfY', '0cbffqfY', '0a4eEqfY', '?PAGE_BREAK?', '0ef3QqfY', 'a3abpqfY', 'ce94wqfY', 'e545VqfY', '11aaxqfY', 'e4e12qfY', '431baqfY', '3030ZqfY', 'db3fNqfY', 'd638dqfY', '539csqfY', 'b25flqfY', '18cdFqfY', '50b5vqfY', '?PAGE_BREAK?', 'db9dGqfY', '4daaRqfY', 'bd0fXqfY', '9937SqfY', 'a3ddnqfY', '59cchqfY', 'd8f9oqfY', '0be3HqfY', 'b3acOqfY', 'aeberqfY', '44a2IqfY', '708e7qfY', 'f4f4MqfY', '?PAGE_BREAK?', '2502x0fY', '070eU0fY', 'a6a7Z0fY', '183cY0fY', '257as0fY', '0da4f0fY', '4809E0fY', '4815F0fY', 'f1a9z0fY', '3672p0fY', '283c80fY', '?PAGE_BREAK?', '29c0BqfY', '9381iqfY', '907ajqfY', '28d5kqfY', '280auqfY', '00b64qfY', '1864JqfY', 'e2835qfY', '7c1eeqfY', '067bTqfY', '46df6qfY', 'b84a9qfY', '614ebqfY', '11bbPqfY', '?PAGE_BREAK?', 'b553q0fY', '36f3y0fY', '222fcqfY', '5cb900fY', '7d7a10fY', '97f9K0fY', 'fc78C0fY', 'c90d30fY', '5b2ag0fY', 'c941A0fY', 'a259L0fY', '6429tqfY', 'a5caD0fY', '08cfm0fY', '22edWqfY', '?PAGE_BREAK?', 'b7fcb0fY', 'd4f0v0fY', 'fb3cQ0fY', '0ba1i0fY', 'a367w0fY', 'ac74V0fY', '3531u0fY', 'fbff20fY', 'e4b8a0fY', '3956N0fY', '0d81d0fY', '029aT0fY', '5dbdl0fY', '?PAGE_BREAK?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?']</td>\n",
       "      <td>[[10912, 250, 50, 5, 16874, 18, 16874, 5, 35, 250, 5, 82, 128, 5, 267, 46, 2199, 147, 41453, 5, 93, 210, 22, 182, 227, 106, 3845, 6, 31, 0], [408, 99, 1024, 15, 5, 29, 5, 37, 5, 136, 141, 46, 5612, 13, 1763, 7, 3228, 7, 4673, 7, 6008, 7, 6644, 0, 1, 1, 1, 1, 1, 1], [50781, 17910, 5, 967, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1163, 712, 1063, 3313, 2145, 3686, 27, 5, 7, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1362, 16, 3494, 4462, 34761, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1585, 26725, 5, 19, 20, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [932, 11768, 21, 5, 7, 140, 7, 420, 5, 1787, 5, 168, 104, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3772, 3048, 65, 27, 5, 7, 6182, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [882, 248, 7, 578, 5, 79, 21, 5, 93, 210, 22, 182, 227, 57, 425, 6, 31, 200, 202, 7012, 102, 5, 75, 31, 336, 160, 0, 1, 1, 1], [1587, 3925, 21, 5, 18, 152, 18, 465, 5, 688, 336, 5, 7, 727, 7, 800, 7, 1761, 2026, 7, 189, 9, 518, 7, 2168, 7, 272, 1004, 7, 0], [2359, 93, 210, 22, 182, 227, 65, 425, 6, 31, 200, 202, 11439, 102, 5, 112, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [1791, 120, 44401, 102, 5, 15, 5, 17, 75, 31, 336, 5, 151, 5, 7, 9, 3376, 45, 38, 99, 5, 825, 21, 0, 1, 1, 1, 1, 1, 1], [629, 641, 7, 6597, 3664, 7, 3262, 4189, 7, 678, 11, 662, 7, 99, 1522, 232, 942, 7, 5156, 7, 10564, 5, 289, 21, 5, 1932, 42, 0, 1, 1], [1959, 6453, 574, 216, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [7987, 401, 964, 32, 5, 1932, 42, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [12124, 11, 228, 112, 21, 5, 22, 1692, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1172, 7, 12675, 7, 1878, 29642, 7, 1878, 14856, 5, 278, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2621, 13403, 21, 5, 7, 3828, 2621, 7, 11914, 2621, 5, 629, 641, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1038, 491, 1541, 112, 21, 5, 137, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5157, 3302, 5, 5331, 21, 5, 4025, 42, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1172, 1932, 42, 5, 7, 1516, 7, 665, 1265, 7, 229, 665, 2795, 2779, 7, 6325, 7, 6587, 7, 2510, 5635, 7, 5515, 7, 2999, 2614, 7, 491, 5419, 0], [1038, 2819, 964, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2634, 9977, 21, 5, 3302, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [46762, 11, 676, 79, 21, 5, 8696, 8, 220, 13, 123, 11, 110, 5, 5156, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [9487, 15, 5, 4286, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [129, 1269, 416, 13535, 692, 5, 29, 5, 2689, 62, 33, 1480, 160, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [879, 7, 1131, 7, 272, 965, 7, 3179, 7, 4130, 11, 230, 7, 1131, 165, 38, 7, 4900, 165, 38, 7, 122, 27046, 7, 122, 4900, 5, 19397, 21, 0], [1296, 66, 21, 5, 11, 230, 5, 7, 393, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [821, 3687, 21, 5, 579, 5, 137, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1084, 7, 5102, 18, 155, 18, 126, 1194, 5, 18, 9, 836, 5, 8069, 21, 5, 7, 724, 5121, 7, 15791, 9343, 7, 7504, 7, 14954, 4204, 7, 5855, 0], [18785, 118, 21, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3734, 7, 5, 68, 21, 5, 19094, 5, 2904, 33, 151, 4416, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3005, 879, 5, 10794, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [735, 851, 258, 89, 5, 972, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1879, 531, 112, 21, 5, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [463, 7, 5, 3329, 21, 5, 7, 3292, 7, 25769, 7, 25770, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5259, 1180, 68, 32, 5, 7, 862, 7, 328, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [463, 125, 5, 66, 21, 5, 11121, 1190, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [14167, 168, 104, 7, 3537, 628, 7, 457, 7, 4515, 148, 17238, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3445, 7, 155, 7, 565, 5, 2135, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1016, 1044, 35, 29, 5, 7, 290, 7, 457, 7, 2327, 5, 863, 5, 15, 5, 305, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [759, 3054, 5985, 21, 5, 7, 712, 1792, 7, 759, 155, 7, 759, 1362, 7, 2730, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4564, 514, 6, 3161, 16, 3498, 2192, 999, 74, 2103, 18, 449, 18, 984, 18, 7, 18, 155, 18, 6725, 2233, 5, 7, 4163, 21, 5, 18, 18, 18, 0], [720, 1282, 3235, 7, 7534, 6646, 5, 380, 720, 108, 1946, 851, 11, 7256, 65, 1721, 33, 1877, 6, 62, 108, 262, 22, 582, 444, 6, 248, 6, 300, 0], [1111, 285, 5, 75, 31, 336, 5, 10467, 21, 5, 7, 1149, 504, 21, 7, 1719, 6, 646, 7, 5122, 6, 1486, 0, 1, 1, 1, 1, 1, 1, 1], [547, 117, 50, 5, 19, 20, 5, 82, 128, 5, 35, 5, 7, 1041, 7, 677, 724, 7, 3872, 3868, 2576, 7, 648, 7, 648, 37, 7, 1940, 5, 0], [882, 248, 68, 21, 5, 7, 152, 404, 7, 649, 18, 151, 675, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [21862, 990, 19, 20, 16992, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1900, 404, 252, 207, 5, 7, 971, 248, 18, 155, 18, 4707, 5, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [576, 620, 410, 6, 46763, 410, 16, 34762, 36013, 524, 32, 5, 45, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1243, 514, 552, 1078, 5, 1253, 21, 5, 7, 7988, 7, 2233, 7, 620, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [856, 30, 17, 5, 840, 2608, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [37395, 79, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2766, 54, 1050, 5, 384, 216, 21, 5, 6020, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [6463, 6, 2100, 6, 3911, 16, 5446, 232, 331, 3665, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [552, 1078, 3076, 105, 21, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1704, 705, 5, 105, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5353, 20580, 38, 5, 79, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [544, 7, 5380, 18045, 7, 12625, 18045, 7, 1728, 5258, 7, 37396, 2019, 7, 17613, 7, 506, 10565, 7, 50782, 7, 699, 2019, 7, 699, 4398, 5, 528, 108, 0], [3579, 16, 22539, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [31470, 16, 39749, 9397, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3283, 148, 819, 7, 11, 207, 7, 11, 1982, 5, 7569, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1882, 642, 68, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [345, 2168, 89, 5, 211, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1030, 7, 1190, 7, 965, 5, 79, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [449, 1154, 278, 21, 5, 2046, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [16001, 1534, 21, 5, 7, 5380, 7, 6645, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1963, 99, 5, 175, 17, 5, 3006, 13, 2519, 6, 3430, 358, 16, 9428, 13, 1288, 1335, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [189, 11, 1363, 14233, 471, 21, 5, 358, 99, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [247, 9238, 74, 2243, 5, 682, 38, 89, 5, 68, 21, 5, 910, 1674, 31, 151, 649, 269, 148, 910, 160, 3354, 8, 2771, 11, 3735, 11, 3457, 5, 0], [3293, 89, 5, 112, 21, 5, 22, 566, 5, 434, 665, 31471, 3293, 927, 22, 99, 566, 5, 75, 31, 336, 160, 120, 496, 102, 5, 15, 5, 2677, 0], [1557, 4407, 15, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5984, 2268, 6357, 307, 2268, 22, 77, 2268, 13, 13, 385, 570, 912, 4880, 5, 912, 5, 7, 5, 7293, 12, 2901, 483, 62048, 5, 7, 5, 7725, 12, 0], [1042, 11, 1310, 62049, 21, 5, 7, 1009, 151, 4750, 7, 1009, 11, 2470, 7, 32474, 11, 2470, 7, 144, 844, 11, 2470, 0, 1, 1, 1, 1, 1, 1], [9588, 68, 5, 7, 1445, 7, 515, 18330, 7, 378, 417, 7, 1095, 1510, 417, 5, 7406, 21, 5, 31473, 11122, 160, 1002, 9879, 16, 3531, 1808, 5, 1377, 0], [25462, 89, 5, 79, 21, 5, 1009, 1713, 9, 2756, 6, 279, 5, 4045, 5210, 5, 2968, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1030, 247, 189, 278, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1562, 11858, 9, 2968, 68, 21, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [5067, 40622, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1675, 24, 25, 5, 7, 733, 7, 1087, 7, 1850, 68, 32, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2138, 1013, 7, 772, 7, 1021, 74, 796, 5, 11440, 27, 5, 7, 7, 5, 79, 5, 19, 20, 5, 75, 31, 336, 0, 1, 1, 1, 1, 1, 1], [2482, 963, 19, 20, 112, 32, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1532, 19, 20, 5, 7, 1255, 7, 940, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5867, 4372, 5, 7, 578, 164, 7, 6193, 2894, 5, 79, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2763, 7, 284, 314, 5, 18, 626, 18, 363, 18, 415, 5, 168, 104, 5008, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2253, 80, 20, 5, 524, 32, 5, 7, 306, 7, 362, 7, 2723, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3043, 1816, 1117, 392, 19, 20, 5, 67, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5067, 3007, 19, 20, 235, 32, 5, 520, 184, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2874, 799, 19, 20, 5, 1307, 32, 5, 7, 473, 7, 876, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5885, 3314, 15, 5, 6793, 5, 35, 14, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3621, 799, 19, 20, 5, 117, 32, 5, 7, 473, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]]</td>\n",
       "      <td>[2, 2, 1, 1, 2, 1, 1, 1, 3, 3, 2, 0, 3, 3, 1, 2, 1, 1, 2, 1, 3, 3, 1, 1, 1, 1, 0, 1, 2, 1, 2, 3, 2, 2, 1, 2, 2, 2, 1, 1, 0, 1, 1, 1, 2, 2, 3, 3, 2, 1, 1, 1, 0, 1, 2, 3, 1, 1, 3, 2, 1, 1, 3, 2, 1, 1, 1, 0, 2, 2, 1, 1, 2, 1, 3, 2, 2, 2, 2, 3, 1, 1, 1, 0, 2, 2, 3, 1, 1, 1, 3, 1, 1, 3, 2, 1, 2, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]</td>\n",
       "      <td>91</td>\n",
       "      <td>[[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1038, 491, 1541, 112, 21, 5, 137, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3734, 7, 5, 68, 21, 5, 19094, 5, 2904, 33, 151, 4416, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [9487, 15, 5, 4286, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1791, 120, 44401, 102, 5, 15, 5, 17, 75, 31, 336, 5, 151, 5, 7, 9, 3376, 45, 38, 99, 5, 825, 21, 0, 1, 1, 1, 1, 1, 1], [10912, 250, 50, 5, 16874, 18, 16874, 5, 35, 250, 5, 82, 128, 5, 267, 46, 2199, 147, 41453, 5, 93, 210, 22, 182, 227, 106, 3845, 6, 31, 0], [14167, 168, 104, 7, 3537, 628, 7, 457, 7, 4515, 148, 17238, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1585, 26725, 5, 19, 20, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1038, 2819, 964, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [576, 620, 410, 6, 46763, 410, 16, 34762, 36013, 524, 32, 5, 45, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1042, 11, 1310, 62049, 21, 5, 7, 1009, 151, 4750, 7, 1009, 11, 2470, 7, 32474, 11, 2470, 7, 144, 844, 11, 2470, 0, 1, 1, 1, 1, 1, 1], [2138, 1013, 7, 772, 7, 1021, 74, 796, 5, 11440, 27, 5, 7, 7, 5, 79, 5, 19, 20, 5, 75, 31, 336, 0, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [735, 851, 258, 89, 5, 972, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5067, 40622, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [5867, 4372, 5, 7, 578, 164, 7, 6193, 2894, 5, 79, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2253, 80, 20, 5, 524, 32, 5, 7, 306, 7, 362, 7, 2723, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [46762, 11, 676, 79, 21, 5, 8696, 8, 220, 13, 123, 11, 110, 5, 5156, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [547, 117, 50, 5, 19, 20, 5, 82, 128, 5, 35, 5, 7, 1041, 7, 677, 724, 7, 3872, 3868, 2576, 7, 648, 7, 648, 37, 7, 1940, 5, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3293, 89, 5, 112, 21, 5, 22, 566, 5, 434, 665, 31471, 3293, 927, 22, 99, 566, 5, 75, 31, 336, 160, 120, 496, 102, 5, 15, 5, 2677, 0], [552, 1078, 3076, 105, 21, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3621, 799, 19, 20, 5, 117, 32, 5, 7, 473, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [879, 7, 1131, 7, 272, 965, 7, 3179, 7, 4130, 11, 230, 7, 1131, 165, 38, 7, 4900, 165, 38, 7, 122, 27046, 7, 122, 4900, 5, 19397, 21, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3445, 7, 155, 7, 565, 5, 2135, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2359, 93, 210, 22, 182, 227, 65, 425, 6, 31, 200, 202, 11439, 102, 5, 112, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [629, 641, 7, 6597, 3664, 7, 3262, 4189, 7, 678, 11, 662, 7, 99, 1522, 232, 942, 7, 5156, 7, 10564, 5, 289, 21, 5, 1932, 42, 0, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [5885, 3314, 15, 5, 6793, 5, 35, 14, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1959, 6453, 574, 216, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1084, 7, 5102, 18, 155, 18, 126, 1194, 5, 18, 9, 836, 5, 8069, 21, 5, 7, 724, 5121, 7, 15791, 9343, 7, 7504, 7, 14954, 4204, 7, 5855, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [12124, 11, 228, 112, 21, 5, 22, 1692, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1532, 19, 20, 5, 7, 1255, 7, 940, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [408, 99, 1024, 15, 5, 29, 5, 37, 5, 136, 141, 46, 5612, 13, 1763, 7, 3228, 7, 4673, 7, 6008, 7, 6644, 0, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [1111, 285, 5, 75, 31, 336, 5, 10467, 21, 5, 7, 1149, 504, 21, 7, 1719, 6, 646, 7, 5122, 6, 1486, 0, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1163, 712, 1063, 3313, 2145, 3686, 27, 5, 7, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1562, 11858, 9, 2968, 68, 21, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [50781, 17910, 5, 967, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [932, 11768, 21, 5, 7, 140, 7, 420, 5, 1787, 5, 168, 104, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [37395, 79, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1879, 531, 112, 21, 5, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2766, 54, 1050, 5, 384, 216, 21, 5, 6020, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5067, 3007, 19, 20, 235, 32, 5, 520, 184, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5157, 3302, 5, 5331, 21, 5, 4025, 42, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1243, 514, 552, 1078, 5, 1253, 21, 5, 7, 7988, 7, 2233, 7, 620, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3043, 1816, 1117, 392, 19, 20, 5, 67, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [720, 1282, 3235, 7, 7534, 6646, 5, 380, 720, 108, 1946, 851, 11, 7256, 65, 1721, 33, 1877, 6, 62, 108, 262, 22, 582, 444, 6, 248, 6, 300, 0], [3005, 879, 5, 10794, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4564, 514, 6, 3161, 16, 3498, 2192, 999, 74, 2103, 18, 449, 18, 984, 18, 7, 18, 155, 18, 6725, 2233, 5, 7, 4163, 21, 5, 18, 18, 18, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1587, 3925, 21, 5, 18, 152, 18, 465, 5, 688, 336, 5, 7, 727, 7, 800, 7, 1761, 2026, 7, 189, 9, 518, 7, 2168, 7, 272, 1004, 7, 0], [6463, 6, 2100, 6, 3911, 16, 5446, 232, 331, 3665, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [31470, 16, 39749, 9397, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2482, 963, 19, 20, 112, 32, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1172, 1932, 42, 5, 7, 1516, 7, 665, 1265, 7, 229, 665, 2795, 2779, 7, 6325, 7, 6587, 7, 2510, 5635, 7, 5515, 7, 2999, 2614, 7, 491, 5419, 0], [25462, 89, 5, 79, 21, 5, 1009, 1713, 9, 2756, 6, 279, 5, 4045, 5210, 5, 2968, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1362, 16, 3494, 4462, 34761, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [882, 248, 68, 21, 5, 7, 152, 404, 7, 649, 18, 151, 675, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2634, 9977, 21, 5, 3302, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3772, 3048, 65, 27, 5, 7, 6182, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [544, 7, 5380, 18045, 7, 12625, 18045, 7, 1728, 5258, 7, 37396, 2019, 7, 17613, 7, 506, 10565, 7, 50782, 7, 699, 2019, 7, 699, 4398, 5, 528, 108, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [21862, 990, 19, 20, 16992, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1675, 24, 25, 5, 7, 733, 7, 1087, 7, 1850, 68, 32, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [759, 3054, 5985, 21, 5, 7, 712, 1792, 7, 759, 155, 7, 759, 1362, 7, 2730, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [16001, 1534, 21, 5, 7, 5380, 7, 6645, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1900, 404, 252, 207, 5, 7, 971, 248, 18, 155, 18, 4707, 5, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1557, 4407, 15, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [9588, 68, 5, 7, 1445, 7, 515, 18330, 7, 378, 417, 7, 1095, 1510, 417, 5, 7406, 21, 5, 31473, 11122, 160, 1002, 9879, 16, 3531, 1808, 5, 1377, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [189, 11, 1363, 14233, 471, 21, 5, 358, 99, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1963, 99, 5, 175, 17, 5, 3006, 13, 2519, 6, 3430, 358, 16, 9428, 13, 1288, 1335, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [882, 248, 7, 578, 5, 79, 21, 5, 93, 210, 22, 182, 227, 57, 425, 6, 31, 200, 202, 7012, 102, 5, 75, 31, 336, 160, 0, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [129, 1269, 416, 13535, 692, 5, 29, 5, 2689, 62, 33, 1480, 160, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [463, 7, 5, 3329, 21, 5, 7, 3292, 7, 25769, 7, 25770, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2763, 7, 284, 314, 5, 18, 626, 18, 363, 18, 415, 5, 168, 104, 5008, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [7987, 401, 964, 32, 5, 1932, 42, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1882, 642, 68, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1172, 7, 12675, 7, 1878, 29642, 7, 1878, 14856, 5, 278, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [463, 125, 5, 66, 21, 5, 11121, 1190, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [856, 30, 17, 5, 840, 2608, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1296, 66, 21, 5, 11, 230, 5, 7, 393, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [2621, 13403, 21, 5, 7, 3828, 2621, 7, 11914, 2621, 5, 629, 641, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1704, 705, 5, 105, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2874, 799, 19, 20, 5, 1307, 32, 5, 7, 473, 7, 876, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [1030, 247, 189, 278, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [5984, 2268, 6357, 307, 2268, 22, 77, 2268, 13, 13, 385, 570, 912, 4880, 5, 912, 5, 7, 5, 7293, 12, 2901, 483, 62048, 5, 7, 5, 7725, 12, 0], [449, 1154, 278, 21, 5, 2046, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [247, 9238, 74, 2243, 5, 682, 38, 89, 5, 68, 21, 5, 910, 1674, 31, 151, 649, 269, 148, 910, 160, 3354, 8, 2771, 11, 3735, 11, 3457, 5, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [821, 3687, 21, 5, 579, 5, 137, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1030, 7, 1190, 7, 965, 5, 79, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3283, 148, 819, 7, 11, 207, 7, 11, 1982, 5, 7569, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3579, 16, 22539, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1016, 1044, 35, 29, 5, 7, 290, 7, 457, 7, 2327, 5, 863, 5, 15, 5, 305, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [5259, 1180, 68, 32, 5, 7, 862, 7, 328, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [345, 2168, 89, 5, 211, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18785, 118, 21, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5353, 20580, 38, 5, 79, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]</td>\n",
       "      <td>[14, 71, 78, 75, 116, 16, 79, 121, 148, 101, 49, 174, 13, 53, 62, 155, 65, 159, 167, 6, 94, 114, 18, 120, 32, 12, 166, 150, 44, 165, 183, 63, 198, 8, 98, 23, 84, 151, 192, 163, 72, 15, 47, 189, 129, 99, 97, 73, 34, 117, 125, 135, 38, 19, 95, 164, 83, 92, 102, 37, 170, 199, 122, 188, 112, 186, 157, 138, 195, 184, 179, 132, 145, 144, 181, 36, 141, 178, 20, 142, 115, 175, 77, 130, 24, 128, 21, 113, 70, 27, 152, 29, 96, 93, 173, 60, 42, 86, 194, 30, 39, 68, 57, 131, 5, 127, 22, 76, 59, 197, 149, 11, 52, 74, 111, 168, 26, 182, 3, 106, 46, 104, 140, 169, 119, 162, 35, 118, 45, 51, 193, 9, 156, 103, 90, 160, 58, 81, 67, 196, 143, 133, 134, 85, 82, 69, 43, 1, 107, 137, 66, 177, 91, 124, 108, 180, 61, 54, 7, 41, 50, 87, 33, 28, 89, 64, 154, 158, 17, 0, 187, 40, 126, 190, 185, 191, 147, 172, 80, 139, 171, 100, 31, 56, 153, 2, 109, 4, 176, 161, 136, 123, 48, 55, 10, 88, 146, 105, 25, 110]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  catalog_id                                                                                  section_ids                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             offer_ids_with_pb                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  offer_vectors_with_pb                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        offer_priorities_with_pb  num_offers                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      x                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           y\n",
       "0  0003leq    {'0003leq_1', '0003leq_2', '0003leq_4', '0003leq_6', '0003leq_3', '0003leq_5', '0003leq_7'}  ['fed3AqfY', '799dzqfY', 'b8a3DqfY', 'a4c88qfY', '3cf8qqfY', '88a5UqfY', '6d6e0qfY', 'ef59YqfY', 'ab38CqfY', '0cbffqfY', '0a4eEqfY', '?PAGE_BREAK?', '0ef3QqfY', 'a3abpqfY', 'ce94wqfY', 'e545VqfY', '11aaxqfY', 'e4e12qfY', '431baqfY', '3030ZqfY', 'db3fNqfY', 'd638dqfY', '539csqfY', 'b25flqfY', '18cdFqfY', '50b5vqfY', '?PAGE_BREAK?', 'db9dGqfY', '4daaRqfY', 'bd0fXqfY', '9937SqfY', 'a3ddnqfY', '59cchqfY', 'd8f9oqfY', '0be3HqfY', 'b3acOqfY', 'aeberqfY', '44a2IqfY', '708e7qfY', 'f4f4MqfY', '?PAGE_BREAK?', '2502x0fY', '070eU0fY', 'a6a7Z0fY', '183cY0fY', '257as0fY', '0da4f0fY', '4809E0fY', '4815F0fY', 'f1a9z0fY', '3672p0fY', '283c80fY', '?PAGE_BREAK?', '29c0BqfY', '9381iqfY', '907ajqfY', '28d5kqfY', '280auqfY', '00b64qfY', '1864JqfY', 'e2835qfY', '7c1eeqfY', '067bTqfY', '46df6qfY', 'b84a9qfY', '614ebqfY', '11bbPqfY', '?PAGE_BREAK?', 'b553q0fY', '36f3y0fY', '222fcqfY', '5cb900fY', '7d7a10fY', '97f9K0fY', 'fc78C0fY', 'c90d30fY', '5b2ag0fY', 'c941A0fY', 'a259L0fY', '6429tqfY', 'a5caD0fY', '08cfm0fY', '22edWqfY', '?PAGE_BREAK?', 'b7fcb0fY', 'd4f0v0fY', 'fb3cQ0fY', '0ba1i0fY', 'a367w0fY', 'ac74V0fY', '3531u0fY', 'fbff20fY', 'e4b8a0fY', '3956N0fY', '0d81d0fY', '029aT0fY', '5dbdl0fY', '?PAGE_BREAK?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?', '?NOT_REAL_OFFER?']  [[10912, 250, 50, 5, 16874, 18, 16874, 5, 35, 250, 5, 82, 128, 5, 267, 46, 2199, 147, 41453, 5, 93, 210, 22, 182, 227, 106, 3845, 6, 31, 0], [408, 99, 1024, 15, 5, 29, 5, 37, 5, 136, 141, 46, 5612, 13, 1763, 7, 3228, 7, 4673, 7, 6008, 7, 6644, 0, 1, 1, 1, 1, 1, 1], [50781, 17910, 5, 967, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1163, 712, 1063, 3313, 2145, 3686, 27, 5, 7, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1362, 16, 3494, 4462, 34761, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1585, 26725, 5, 19, 20, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [932, 11768, 21, 5, 7, 140, 7, 420, 5, 1787, 5, 168, 104, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3772, 3048, 65, 27, 5, 7, 6182, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [882, 248, 7, 578, 5, 79, 21, 5, 93, 210, 22, 182, 227, 57, 425, 6, 31, 200, 202, 7012, 102, 5, 75, 31, 336, 160, 0, 1, 1, 1], [1587, 3925, 21, 5, 18, 152, 18, 465, 5, 688, 336, 5, 7, 727, 7, 800, 7, 1761, 2026, 7, 189, 9, 518, 7, 2168, 7, 272, 1004, 7, 0], [2359, 93, 210, 22, 182, 227, 65, 425, 6, 31, 200, 202, 11439, 102, 5, 112, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [1791, 120, 44401, 102, 5, 15, 5, 17, 75, 31, 336, 5, 151, 5, 7, 9, 3376, 45, 38, 99, 5, 825, 21, 0, 1, 1, 1, 1, 1, 1], [629, 641, 7, 6597, 3664, 7, 3262, 4189, 7, 678, 11, 662, 7, 99, 1522, 232, 942, 7, 5156, 7, 10564, 5, 289, 21, 5, 1932, 42, 0, 1, 1], [1959, 6453, 574, 216, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [7987, 401, 964, 32, 5, 1932, 42, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [12124, 11, 228, 112, 21, 5, 22, 1692, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1172, 7, 12675, 7, 1878, 29642, 7, 1878, 14856, 5, 278, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2621, 13403, 21, 5, 7, 3828, 2621, 7, 11914, 2621, 5, 629, 641, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1038, 491, 1541, 112, 21, 5, 137, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5157, 3302, 5, 5331, 21, 5, 4025, 42, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1172, 1932, 42, 5, 7, 1516, 7, 665, 1265, 7, 229, 665, 2795, 2779, 7, 6325, 7, 6587, 7, 2510, 5635, 7, 5515, 7, 2999, 2614, 7, 491, 5419, 0], [1038, 2819, 964, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2634, 9977, 21, 5, 3302, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [46762, 11, 676, 79, 21, 5, 8696, 8, 220, 13, 123, 11, 110, 5, 5156, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [9487, 15, 5, 4286, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [129, 1269, 416, 13535, 692, 5, 29, 5, 2689, 62, 33, 1480, 160, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [879, 7, 1131, 7, 272, 965, 7, 3179, 7, 4130, 11, 230, 7, 1131, 165, 38, 7, 4900, 165, 38, 7, 122, 27046, 7, 122, 4900, 5, 19397, 21, 0], [1296, 66, 21, 5, 11, 230, 5, 7, 393, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [821, 3687, 21, 5, 579, 5, 137, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1084, 7, 5102, 18, 155, 18, 126, 1194, 5, 18, 9, 836, 5, 8069, 21, 5, 7, 724, 5121, 7, 15791, 9343, 7, 7504, 7, 14954, 4204, 7, 5855, 0], [18785, 118, 21, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3734, 7, 5, 68, 21, 5, 19094, 5, 2904, 33, 151, 4416, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3005, 879, 5, 10794, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [735, 851, 258, 89, 5, 972, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1879, 531, 112, 21, 5, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [463, 7, 5, 3329, 21, 5, 7, 3292, 7, 25769, 7, 25770, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5259, 1180, 68, 32, 5, 7, 862, 7, 328, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [463, 125, 5, 66, 21, 5, 11121, 1190, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [14167, 168, 104, 7, 3537, 628, 7, 457, 7, 4515, 148, 17238, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3445, 7, 155, 7, 565, 5, 2135, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1016, 1044, 35, 29, 5, 7, 290, 7, 457, 7, 2327, 5, 863, 5, 15, 5, 305, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [759, 3054, 5985, 21, 5, 7, 712, 1792, 7, 759, 155, 7, 759, 1362, 7, 2730, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4564, 514, 6, 3161, 16, 3498, 2192, 999, 74, 2103, 18, 449, 18, 984, 18, 7, 18, 155, 18, 6725, 2233, 5, 7, 4163, 21, 5, 18, 18, 18, 0], [720, 1282, 3235, 7, 7534, 6646, 5, 380, 720, 108, 1946, 851, 11, 7256, 65, 1721, 33, 1877, 6, 62, 108, 262, 22, 582, 444, 6, 248, 6, 300, 0], [1111, 285, 5, 75, 31, 336, 5, 10467, 21, 5, 7, 1149, 504, 21, 7, 1719, 6, 646, 7, 5122, 6, 1486, 0, 1, 1, 1, 1, 1, 1, 1], [547, 117, 50, 5, 19, 20, 5, 82, 128, 5, 35, 5, 7, 1041, 7, 677, 724, 7, 3872, 3868, 2576, 7, 648, 7, 648, 37, 7, 1940, 5, 0], [882, 248, 68, 21, 5, 7, 152, 404, 7, 649, 18, 151, 675, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [21862, 990, 19, 20, 16992, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1900, 404, 252, 207, 5, 7, 971, 248, 18, 155, 18, 4707, 5, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [576, 620, 410, 6, 46763, 410, 16, 34762, 36013, 524, 32, 5, 45, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1243, 514, 552, 1078, 5, 1253, 21, 5, 7, 7988, 7, 2233, 7, 620, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [856, 30, 17, 5, 840, 2608, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [37395, 79, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2766, 54, 1050, 5, 384, 216, 21, 5, 6020, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [6463, 6, 2100, 6, 3911, 16, 5446, 232, 331, 3665, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [552, 1078, 3076, 105, 21, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1704, 705, 5, 105, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5353, 20580, 38, 5, 79, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [544, 7, 5380, 18045, 7, 12625, 18045, 7, 1728, 5258, 7, 37396, 2019, 7, 17613, 7, 506, 10565, 7, 50782, 7, 699, 2019, 7, 699, 4398, 5, 528, 108, 0], [3579, 16, 22539, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [31470, 16, 39749, 9397, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3283, 148, 819, 7, 11, 207, 7, 11, 1982, 5, 7569, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1882, 642, 68, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [345, 2168, 89, 5, 211, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1030, 7, 1190, 7, 965, 5, 79, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [449, 1154, 278, 21, 5, 2046, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [16001, 1534, 21, 5, 7, 5380, 7, 6645, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1963, 99, 5, 175, 17, 5, 3006, 13, 2519, 6, 3430, 358, 16, 9428, 13, 1288, 1335, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [189, 11, 1363, 14233, 471, 21, 5, 358, 99, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [247, 9238, 74, 2243, 5, 682, 38, 89, 5, 68, 21, 5, 910, 1674, 31, 151, 649, 269, 148, 910, 160, 3354, 8, 2771, 11, 3735, 11, 3457, 5, 0], [3293, 89, 5, 112, 21, 5, 22, 566, 5, 434, 665, 31471, 3293, 927, 22, 99, 566, 5, 75, 31, 336, 160, 120, 496, 102, 5, 15, 5, 2677, 0], [1557, 4407, 15, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5984, 2268, 6357, 307, 2268, 22, 77, 2268, 13, 13, 385, 570, 912, 4880, 5, 912, 5, 7, 5, 7293, 12, 2901, 483, 62048, 5, 7, 5, 7725, 12, 0], [1042, 11, 1310, 62049, 21, 5, 7, 1009, 151, 4750, 7, 1009, 11, 2470, 7, 32474, 11, 2470, 7, 144, 844, 11, 2470, 0, 1, 1, 1, 1, 1, 1], [9588, 68, 5, 7, 1445, 7, 515, 18330, 7, 378, 417, 7, 1095, 1510, 417, 5, 7406, 21, 5, 31473, 11122, 160, 1002, 9879, 16, 3531, 1808, 5, 1377, 0], [25462, 89, 5, 79, 21, 5, 1009, 1713, 9, 2756, 6, 279, 5, 4045, 5210, 5, 2968, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1030, 247, 189, 278, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1562, 11858, 9, 2968, 68, 21, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [5067, 40622, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1675, 24, 25, 5, 7, 733, 7, 1087, 7, 1850, 68, 32, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2138, 1013, 7, 772, 7, 1021, 74, 796, 5, 11440, 27, 5, 7, 7, 5, 79, 5, 19, 20, 5, 75, 31, 336, 0, 1, 1, 1, 1, 1, 1], [2482, 963, 19, 20, 112, 32, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1532, 19, 20, 5, 7, 1255, 7, 940, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5867, 4372, 5, 7, 578, 164, 7, 6193, 2894, 5, 79, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2763, 7, 284, 314, 5, 18, 626, 18, 363, 18, 415, 5, 168, 104, 5008, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2253, 80, 20, 5, 524, 32, 5, 7, 306, 7, 362, 7, 2723, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3043, 1816, 1117, 392, 19, 20, 5, 67, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5067, 3007, 19, 20, 235, 32, 5, 520, 184, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2874, 799, 19, 20, 5, 1307, 32, 5, 7, 473, 7, 876, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5885, 3314, 15, 5, 6793, 5, 35, 14, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3621, 799, 19, 20, 5, 117, 32, 5, 7, 473, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]]  [2, 2, 1, 1, 2, 1, 1, 1, 3, 3, 2, 0, 3, 3, 1, 2, 1, 1, 2, 1, 3, 3, 1, 1, 1, 1, 0, 1, 2, 1, 2, 3, 2, 2, 1, 2, 2, 2, 1, 1, 0, 1, 1, 1, 2, 2, 3, 3, 2, 1, 1, 1, 0, 1, 2, 3, 1, 1, 3, 2, 1, 1, 3, 2, 1, 1, 1, 0, 2, 2, 1, 1, 2, 1, 3, 2, 2, 2, 2, 3, 1, 1, 1, 0, 2, 2, 3, 1, 1, 1, 3, 1, 1, 3, 2, 1, 2, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]  91          [[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1038, 491, 1541, 112, 21, 5, 137, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3734, 7, 5, 68, 21, 5, 19094, 5, 2904, 33, 151, 4416, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [9487, 15, 5, 4286, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1791, 120, 44401, 102, 5, 15, 5, 17, 75, 31, 336, 5, 151, 5, 7, 9, 3376, 45, 38, 99, 5, 825, 21, 0, 1, 1, 1, 1, 1, 1], [10912, 250, 50, 5, 16874, 18, 16874, 5, 35, 250, 5, 82, 128, 5, 267, 46, 2199, 147, 41453, 5, 93, 210, 22, 182, 227, 106, 3845, 6, 31, 0], [14167, 168, 104, 7, 3537, 628, 7, 457, 7, 4515, 148, 17238, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1585, 26725, 5, 19, 20, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1038, 2819, 964, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [576, 620, 410, 6, 46763, 410, 16, 34762, 36013, 524, 32, 5, 45, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1042, 11, 1310, 62049, 21, 5, 7, 1009, 151, 4750, 7, 1009, 11, 2470, 7, 32474, 11, 2470, 7, 144, 844, 11, 2470, 0, 1, 1, 1, 1, 1, 1], [2138, 1013, 7, 772, 7, 1021, 74, 796, 5, 11440, 27, 5, 7, 7, 5, 79, 5, 19, 20, 5, 75, 31, 336, 0, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [735, 851, 258, 89, 5, 972, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5067, 40622, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [5867, 4372, 5, 7, 578, 164, 7, 6193, 2894, 5, 79, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2253, 80, 20, 5, 524, 32, 5, 7, 306, 7, 362, 7, 2723, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [46762, 11, 676, 79, 21, 5, 8696, 8, 220, 13, 123, 11, 110, 5, 5156, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [547, 117, 50, 5, 19, 20, 5, 82, 128, 5, 35, 5, 7, 1041, 7, 677, 724, 7, 3872, 3868, 2576, 7, 648, 7, 648, 37, 7, 1940, 5, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3293, 89, 5, 112, 21, 5, 22, 566, 5, 434, 665, 31471, 3293, 927, 22, 99, 566, 5, 75, 31, 336, 160, 120, 496, 102, 5, 15, 5, 2677, 0], [552, 1078, 3076, 105, 21, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3621, 799, 19, 20, 5, 117, 32, 5, 7, 473, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [879, 7, 1131, 7, 272, 965, 7, 3179, 7, 4130, 11, 230, 7, 1131, 165, 38, 7, 4900, 165, 38, 7, 122, 27046, 7, 122, 4900, 5, 19397, 21, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3445, 7, 155, 7, 565, 5, 2135, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2359, 93, 210, 22, 182, 227, 65, 425, 6, 31, 200, 202, 11439, 102, 5, 112, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [629, 641, 7, 6597, 3664, 7, 3262, 4189, 7, 678, 11, 662, 7, 99, 1522, 232, 942, 7, 5156, 7, 10564, 5, 289, 21, 5, 1932, 42, 0, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [5885, 3314, 15, 5, 6793, 5, 35, 14, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1959, 6453, 574, 216, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1084, 7, 5102, 18, 155, 18, 126, 1194, 5, 18, 9, 836, 5, 8069, 21, 5, 7, 724, 5121, 7, 15791, 9343, 7, 7504, 7, 14954, 4204, 7, 5855, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [12124, 11, 228, 112, 21, 5, 22, 1692, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1532, 19, 20, 5, 7, 1255, 7, 940, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [408, 99, 1024, 15, 5, 29, 5, 37, 5, 136, 141, 46, 5612, 13, 1763, 7, 3228, 7, 4673, 7, 6008, 7, 6644, 0, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [1111, 285, 5, 75, 31, 336, 5, 10467, 21, 5, 7, 1149, 504, 21, 7, 1719, 6, 646, 7, 5122, 6, 1486, 0, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1163, 712, 1063, 3313, 2145, 3686, 27, 5, 7, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1562, 11858, 9, 2968, 68, 21, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [50781, 17910, 5, 967, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [932, 11768, 21, 5, 7, 140, 7, 420, 5, 1787, 5, 168, 104, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [37395, 79, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1879, 531, 112, 21, 5, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2766, 54, 1050, 5, 384, 216, 21, 5, 6020, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5067, 3007, 19, 20, 235, 32, 5, 520, 184, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5157, 3302, 5, 5331, 21, 5, 4025, 42, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1243, 514, 552, 1078, 5, 1253, 21, 5, 7, 7988, 7, 2233, 7, 620, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3043, 1816, 1117, 392, 19, 20, 5, 67, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [720, 1282, 3235, 7, 7534, 6646, 5, 380, 720, 108, 1946, 851, 11, 7256, 65, 1721, 33, 1877, 6, 62, 108, 262, 22, 582, 444, 6, 248, 6, 300, 0], [3005, 879, 5, 10794, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4564, 514, 6, 3161, 16, 3498, 2192, 999, 74, 2103, 18, 449, 18, 984, 18, 7, 18, 155, 18, 6725, 2233, 5, 7, 4163, 21, 5, 18, 18, 18, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1587, 3925, 21, 5, 18, 152, 18, 465, 5, 688, 336, 5, 7, 727, 7, 800, 7, 1761, 2026, 7, 189, 9, 518, 7, 2168, 7, 272, 1004, 7, 0], [6463, 6, 2100, 6, 3911, 16, 5446, 232, 331, 3665, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [31470, 16, 39749, 9397, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2482, 963, 19, 20, 112, 32, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1172, 1932, 42, 5, 7, 1516, 7, 665, 1265, 7, 229, 665, 2795, 2779, 7, 6325, 7, 6587, 7, 2510, 5635, 7, 5515, 7, 2999, 2614, 7, 491, 5419, 0], [25462, 89, 5, 79, 21, 5, 1009, 1713, 9, 2756, 6, 279, 5, 4045, 5210, 5, 2968, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1362, 16, 3494, 4462, 34761, 21, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [882, 248, 68, 21, 5, 7, 152, 404, 7, 649, 18, 151, 675, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2634, 9977, 21, 5, 3302, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3772, 3048, 65, 27, 5, 7, 6182, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [544, 7, 5380, 18045, 7, 12625, 18045, 7, 1728, 5258, 7, 37396, 2019, 7, 17613, 7, 506, 10565, 7, 50782, 7, 699, 2019, 7, 699, 4398, 5, 528, 108, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [21862, 990, 19, 20, 16992, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1675, 24, 25, 5, 7, 733, 7, 1087, 7, 1850, 68, 32, 5, 19, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [759, 3054, 5985, 21, 5, 7, 712, 1792, 7, 759, 155, 7, 759, 1362, 7, 2730, 5, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [16001, 1534, 21, 5, 7, 5380, 7, 6645, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1900, 404, 252, 207, 5, 7, 971, 248, 18, 155, 18, 4707, 5, 66, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1557, 4407, 15, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [9588, 68, 5, 7, 1445, 7, 515, 18330, 7, 378, 417, 7, 1095, 1510, 417, 5, 7406, 21, 5, 31473, 11122, 160, 1002, 9879, 16, 3531, 1808, 5, 1377, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [189, 11, 1363, 14233, 471, 21, 5, 358, 99, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1963, 99, 5, 175, 17, 5, 3006, 13, 2519, 6, 3430, 358, 16, 9428, 13, 1288, 1335, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [882, 248, 7, 578, 5, 79, 21, 5, 93, 210, 22, 182, 227, 57, 425, 6, 31, 200, 202, 7012, 102, 5, 75, 31, 336, 160, 0, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [129, 1269, 416, 13535, 692, 5, 29, 5, 2689, 62, 33, 1480, 160, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [463, 7, 5, 3329, 21, 5, 7, 3292, 7, 25769, 7, 25770, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2763, 7, 284, 314, 5, 18, 626, 18, 363, 18, 415, 5, 168, 104, 5008, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [7987, 401, 964, 32, 5, 1932, 42, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1882, 642, 68, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1172, 7, 12675, 7, 1878, 29642, 7, 1878, 14856, 5, 278, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [463, 125, 5, 66, 21, 5, 11121, 1190, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [856, 30, 17, 5, 840, 2608, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1296, 66, 21, 5, 11, 230, 5, 7, 393, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [2621, 13403, 21, 5, 7, 3828, 2621, 7, 11914, 2621, 5, 629, 641, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [1704, 705, 5, 105, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [2874, 799, 19, 20, 5, 1307, 32, 5, 7, 473, 7, 876, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [1030, 247, 189, 278, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [5984, 2268, 6357, 307, 2268, 22, 77, 2268, 13, 13, 385, 570, 912, 4880, 5, 912, 5, 7, 5, 7293, 12, 2901, 483, 62048, 5, 7, 5, 7725, 12, 0], [449, 1154, 278, 21, 5, 2046, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [247, 9238, 74, 2243, 5, 682, 38, 89, 5, 68, 21, 5, 910, 1674, 31, 151, 649, 269, 148, 910, 160, 3354, 8, 2771, 11, 3735, 11, 3457, 5, 0], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [821, 3687, 21, 5, 579, 5, 137, 20, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1030, 7, 1190, 7, 965, 5, 79, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3283, 148, 819, 7, 11, 207, 7, 11, 1982, 5, 7569, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [3579, 16, 22539, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1016, 1044, 35, 29, 5, 7, 290, 7, 457, 7, 2327, 5, 863, 5, 15, 5, 305, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [5259, 1180, 68, 32, 5, 7, 862, 7, 328, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [345, 2168, 89, 5, 211, 21, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [18785, 118, 21, 5, 688, 336, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5353, 20580, 38, 5, 79, 32, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]  [14, 71, 78, 75, 116, 16, 79, 121, 148, 101, 49, 174, 13, 53, 62, 155, 65, 159, 167, 6, 94, 114, 18, 120, 32, 12, 166, 150, 44, 165, 183, 63, 198, 8, 98, 23, 84, 151, 192, 163, 72, 15, 47, 189, 129, 99, 97, 73, 34, 117, 125, 135, 38, 19, 95, 164, 83, 92, 102, 37, 170, 199, 122, 188, 112, 186, 157, 138, 195, 184, 179, 132, 145, 144, 181, 36, 141, 178, 20, 142, 115, 175, 77, 130, 24, 128, 21, 113, 70, 27, 152, 29, 96, 93, 173, 60, 42, 86, 194, 30, 39, 68, 57, 131, 5, 127, 22, 76, 59, 197, 149, 11, 52, 74, 111, 168, 26, 182, 3, 106, 46, 104, 140, 169, 119, 162, 35, 118, 45, 51, 193, 9, 156, 103, 90, 160, 58, 81, 67, 196, 143, 133, 134, 85, 82, 69, 43, 1, 107, 137, 66, 177, 91, 124, 108, 180, 61, 54, 7, 41, 50, 87, 33, 28, 89, 64, 154, 158, 17, 0, 187, 40, 126, 190, 185, 191, 147, 172, 80, 139, 171, 100, 31, 56, 153, 2, 109, 4, 176, 161, 136, 123, 48, 55, 10, 88, 146, 105, 25, 110]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_catalogs = pd.read_csv(config['path_in_df_catalog_csv'], sep=';')\n",
    "df_catalogs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11063"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_catalogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload feature csv's split into train and test\n",
    "df_catalogs_train = pd.read_csv(config['path_in_df_catalog_train_csv'], sep=';')\n",
    "# df_catalogs_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_catalogs_test = pd.read_csv(config['path_in_df_catalog_test_csv'], sep=';')\n",
    "# df_catalogs_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8850, 2212)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_catalogs_train), len(df_catalogs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Meta Resources (dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?EOS?', 0),\n",
       " ('?PAD?', 1),\n",
       " ('?UNK?', 2),\n",
       " ('?PAGE_BREAK?', 3),\n",
       " ('?NOT_REAL_OFFER?', 4)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read word2idx dictionary\n",
    "with open(config['path_in_dictionary'], 'rb') as f:\n",
    "    word2idx = pickle.load(f)\n",
    "list(word2idx.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0003leq', {'0003leq_3', '0003leq_6', '0003leq_1', '0003leq_4', '0003leq_7', '0003leq_5', '0003leq_2'}), ('0007YiY', {'0007YiY_4', '0007YiY_11', '0007YiY_5', '0007YiY_8', '0007YiY_7', '0007YiY_13', '0007YiY_6', '0007YiY_1', '0007YiY_10', '0007YiY_3', '0007YiY_9', '0007YiY_16', '0007YiY_12', '0007YiY_15', '0007YiY_2', '0007YiY_14'})]\n"
     ]
    }
   ],
   "source": [
    "# read catalog id to section ids\n",
    "with open(config['path_in_catalog_id_to_section_ids'], 'rb') as f:\n",
    "    catalog_id_to_section_ids = pickle.load(f)\n",
    "print(list(catalog_id_to_section_ids.items())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0003leq_1', ['fed3AqfY', '799dzqfY', 'b8a3DqfY', 'a4c88qfY', '3cf8qqfY', '88a5UqfY', '6d6e0qfY', 'ef59YqfY', 'ab38CqfY', '0cbffqfY', '0a4eEqfY']), ('0003leq_2', ['0ef3QqfY', 'a3abpqfY', 'ce94wqfY', 'e545VqfY', '11aaxqfY', 'e4e12qfY', '431baqfY', '3030ZqfY', 'db3fNqfY', 'd638dqfY', '539csqfY', 'b25flqfY', '18cdFqfY', '50b5vqfY'])]\n"
     ]
    }
   ],
   "source": [
    "# read section maps\n",
    "with open(config['path_in_section_id_to_offer_ids'], 'rb') as f:\n",
    "    section_id_to_offer_ids = pickle.load(f)\n",
    "print(list(section_id_to_offer_ids.items())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0003leq_1', [[11665, 315, 67, 5, 7298, 25, 7298, 5, 37, 315, 5, 130, 209, 5, 149, 56, 1172, 230, 11666, 5, 79, 184, 22, 200, 210, 82, 3012, 6, 31, 0], [488, 118, 1653, 16, 5, 28, 5, 38, 5, 188, 131, 56, 11667, 14, 1173, 8, 3604, 8, 7300, 8, 11668, 8, 11669, 0, 1, 1, 1, 1, 1, 1], [11670, 7301, 5, 1037, 30, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1038, 801, 1522, 3605, 2283, 2023, 29, 5, 8, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1654, 15, 5539, 5540, 11671, 30, 5, 19, 26, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1655, 11672, 5, 19, 26, 75, 30, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1304, 4351, 30, 5, 8, 140, 8, 477, 5, 1806, 5, 432, 99, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3013, 2599, 78, 29, 5, 8, 2284, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1230, 304, 8, 838, 5, 90, 30, 5, 79, 184, 22, 200, 210, 46, 457, 6, 31, 196, 370, 3014, 126, 5, 86, 31, 579, 323, 0, 1, 1, 1], [3015, 4352, 30, 5, 25, 168, 25, 727, 5, 728, 579, 5, 8, 1231, 8, 1656, 8, 2024, 3016, 8, 236, 9, 695, 8, 3606, 8, 409, 1523, 8, 0], [3017, 79, 184, 22, 200, 210, 78, 457, 6, 31, 196, 370, 11673, 126, 5, 125, 30, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "with open(config['path_in_section_id_to_offer_vectors'], 'rb') as f:\n",
    "    section_id_to_offers_as_vectors = pickle.load(f)\n",
    "print(list(section_id_to_offers_as_vectors.items())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0003leq_1', 1), ('0003leq_2', 2), ('0003leq_3', 3), ('0003leq_4', 4), ('0003leq_5', 5)]\n"
     ]
    }
   ],
   "source": [
    "with open(config['path_in_section_id_to_section_num'], 'rb') as f:\n",
    "    section_id_to_section_num = pickle.load(f)\n",
    "print(list(section_id_to_section_num.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0003leq_1', [2, 2, 1, 1, 2, 1, 1, 1, 3, 3, 2]), ('0003leq_2', [3, 3, 1, 2, 1, 1, 2, 1, 3, 3, 1, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "with open(config['path_in_section_id_to_offer_priorities'], 'rb') as f:\n",
    "    section_ids_to_offers_as_priorities = pickle.load(f)\n",
    "print(list(section_ids_to_offers_as_priorities.items())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('fed3AqfY', 2), ('799dzqfY', 2)]\n"
     ]
    }
   ],
   "source": [
    "# read offer maps\n",
    "with open(config['path_in_offer_id_to_priority'], 'rb') as f:\n",
    "    offer_id_to_priority = pickle.load(f)\n",
    "print(list(offer_id_to_priority.items())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('fed3AqfY', [11665, 315, 67, 5, 7298, 25, 7298, 5, 37, 315, 5, 130, 209, 5, 149, 56, 1172, 230, 11666, 5, 79, 184, 22, 200, 210, 82, 3012, 6, 31, 0]), ('799dzqfY', [488, 118, 1653, 16, 5, 28, 5, 38, 5, 188, 131, 56, 11667, 14, 1173, 8, 3604, 8, 7300, 8, 11668, 8, 11669, 0, 1, 1, 1, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "with open(config['path_in_offer_id_to_vector'], 'rb') as f:\n",
    "    offer_id_to_vector = pickle.load(f)\n",
    "print(list(offer_id_to_vector.items())[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Numpy Matrices (X & Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52, 200, 30), (52, 200), array([[   4,    4,    4, ...,    4,    4,    4],\n",
       "        [   4,    4,    4, ...,    4,    4,    4],\n",
       "        [   4,    4,    4, ...,    4,    4,    4],\n",
       "        ...,\n",
       "        [   4,    4,    4, ...,    4,    4,    4],\n",
       "        [1413,   19,   26, ...,    1,    1,    1],\n",
       "        [1660,  530, 1107, ...,    1,    1,    1]], dtype=int32), array([ 14,  71,  78,  75, 116,  16,  79, 121, 148, 101,  49, 174,  13,\n",
       "         53,  62, 155,  65, 159, 167,   6,  94, 114,  18, 120,  32,  12,\n",
       "        166, 150,  44, 165, 183,  63, 198,   8,  98,  23,  84, 151, 192,\n",
       "        163,  72,  15,  47, 189, 129,  99,  97,  73,  34, 117, 125, 135,\n",
       "         38,  19,  95, 164,  83,  92, 102,  37, 170, 199, 122, 188, 112,\n",
       "        186, 157, 138, 195, 184, 179, 132, 145, 144, 181,  36, 141, 178,\n",
       "         20, 142, 115, 175,  77, 130,  24, 128,  21, 113,  70,  27, 152,\n",
       "         29,  96,  93, 173,  60,  42,  86, 194,  30,  39,  68,  57, 131,\n",
       "          5, 127,  22,  76,  59, 197, 149,  11,  52,  74, 111, 168,  26,\n",
       "        182,   3, 106,  46, 104, 140, 169, 119, 162,  35, 118,  45,  51,\n",
       "        193,   9, 156, 103,  90, 160,  58,  81,  67, 196, 143, 133, 134,\n",
       "         85,  82,  69,  43,   1, 107, 137,  66, 177,  91, 124, 108, 180,\n",
       "         61,  54,   7,  41,  50,  87,  33,  28,  89,  64, 154, 158,  17,\n",
       "          0, 187,  40, 126, 190, 185, 191, 147, 172,  80, 139, 171, 100,\n",
       "         31,  56, 153,   2, 109,   4, 176, 161, 136, 123,  48,  55,  10,\n",
       "         88, 146, 105,  25, 110], dtype=int32))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set\n",
    "X_train = np.load(config['path_in_np_X_train'])\n",
    "Y_train = np.load(config['path_in_np_Y_train'])\n",
    "X_train.shape, Y_train.shape, X_train[0], Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12, 200, 30),\n",
       " (12, 200),\n",
       " array([[ 1804,   255,     9, ...,  5512,    12,     0],\n",
       "        [ 7715,  1113,    95, ...,     1,     1,     1],\n",
       "        [    4,     4,     4, ...,     4,     4,     4],\n",
       "        ...,\n",
       "        [  693,  1257, 24201, ...,     1,     1,     1],\n",
       "        [ 1761,  1135, 24343, ...,     1,     1,     1],\n",
       "        [24115, 24116, 24117, ...,     1,     1,     1]], dtype=int32),\n",
       " array([ 15, 115,  90, 187, 167,  14, 163, 109, 178, 139,  85,  51,  45,\n",
       "         16, 155,  54, 175,  86, 161,  78,  91,  47, 122, 162, 121,  74,\n",
       "        137,  21,  37,  73,  53, 191,  32,  97,  69, 185,  10,   0, 143,\n",
       "        180, 120,   5,  77, 182,  94,  75,  60, 157, 101,  83,  33, 184,\n",
       "         11, 106, 197,  88, 144,  79, 131, 104, 193, 152, 117,  38, 105,\n",
       "          7, 113,  57, 145,  48, 147,  43, 160,  71, 132, 196, 159, 138,\n",
       "        127, 118, 135,  99, 110,  22,  44,  64,  62, 148,  36, 116,  34,\n",
       "        119,  27,  23,  58, 174, 124,  56,  68, 181,  82, 142, 166,  84,\n",
       "        188, 169, 156,  98,  41,  93, 150,  80, 102,  92, 100, 107, 168,\n",
       "         31,  12,  65, 146, 153, 133,  55, 128, 192, 190,  63,  81, 199,\n",
       "        151,  35, 103,  13,  25,   9,   1,  19, 183,  49, 114,  70, 125,\n",
       "         67, 108, 158,  18, 141, 130, 194, 111,  76, 123, 112, 165,  66,\n",
       "        134, 154,   3, 172,  40,  26, 198,  50, 129, 195,   6,   4,  89,\n",
       "        186, 179,  20,  30, 173, 177,  28,  95,  39,  17, 140,  72,  46,\n",
       "        170, 164,  87,  42,   8,  24, 149, 176,  96,  29,   2, 126, 189,\n",
       "        136,  52,  59, 171,  61], dtype=int32))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set\n",
    "X_test = np.load(config['path_in_np_X_test'])\n",
    "Y_test = np.load(config['path_in_np_Y_test'])\n",
    "X_test.shape, Y_test.shape, X_test[0], Y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Torch Tensors (X & Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([52, 200, 30]), torch.Size([52, 200]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set\n",
    "X_train_torch = torch.load(config['path_in_torch_X_train'])\n",
    "Y_train_torch = torch.load(config['path_in_torch_Y_train'])\n",
    "X_train_torch.size(), Y_train_torch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 200, 30]), torch.Size([12, 200]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full test set\n",
    "X_test_full_torch = torch.load(config['path_in_torch_X_test'])\n",
    "Y_test_full_torch = torch.load(config['path_in_torch_Y_test'])\n",
    "X_test_full_torch.size(), Y_test_full_torch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y needs to be a long\n",
    "Y_train_torch = Y_train_torch.long()\n",
    "Y_test_full_torch = Y_test_full_torch.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('torch.LongTensor', 'torch.LongTensor')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_torch.type(), Y_test_full_torch.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smaller test set\n",
    "For validation here, due to memory size problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['test_small_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 200, 30]), torch.Size([12, 200]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split\n",
    "X_test_torch = X_test_full_torch[:config['test_small_size']]\n",
    "Y_test_torch = Y_test_full_torch[:config['test_small_size']]\n",
    "X_test_torch.size(), Y_test_torch.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn into Torch Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# into datasets\n",
    "dataset_train = TensorDataset(X_train_torch, Y_train_torch)\n",
    "dataset_test = TensorDataset(X_test_torch, Y_test_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "train_dataloader = DataLoader(dataset_train, batch_size=config['batch_size'], shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(dataset_test, batch_size=config['batch_size'], shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model PtrNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from publication_2_models_real_catalogs import PointerCatalogNetwork, \\\n",
    "    PointerEncoder, PointerAttention, PointerDecoder, PointerOfferEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointerCatalogNetwork(\n",
       "  (word_embedding): Embedding(26169, 64)\n",
       "  (offer_embedding): PointerOfferEmbedder(\n",
       "    (offer_rnn): GRU(64, 64, num_layers=2, batch_first=True, dropout=0.05)\n",
       "  )\n",
       "  (encoder): PointerEncoder(\n",
       "    (lstm): LSTM(64, 32, num_layers=2, batch_first=True, dropout=0.05, bidirectional=True)\n",
       "  )\n",
       "  (decoder): PointerDecoder(\n",
       "    (input_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (att): PointerAttention(\n",
       "      (input_linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (context_linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the model\n",
    "model_ptrnet = PointerCatalogNetwork(\n",
    "    word_embedding_dim=config['ptr_word_emb_dim'],\n",
    "    offer_embedding_dim=config['ptr_offer_emb_dim'],\n",
    "    hidden_dim=config['ptr_hid_dim'],\n",
    "    offer_rnn_layers=config['ptr_offer_rnn_layers'],\n",
    "    catalog_rnn_layers=config['ptr_catalog_rnn_layers'],\n",
    "    dropout_offers=config['ptr_dropout_offers'],\n",
    "    dropout_catalogs=config['ptr_dropout_catalogs'],\n",
    "    bidir_offers=config['ptr_bidir_offers'],  # not handled 2021 04\n",
    "    bidir_catalogs=config['ptr_bidir_catalogs'],\n",
    "    masking=config['ptr_mask'],\n",
    "    vocab_size=len(word2idx),\n",
    ")\n",
    "\n",
    "model_ptrnet.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,824,832 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# how many params\n",
    "count_params(model_ptrnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-elem batch\n",
    "batch_x = X_train_torch[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 200, 200]) torch.Size([2, 200])\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "_ = model_ptrnet(batch_x)\n",
    "print(_[0].size(), _[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "print(_[1].type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "CCE = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer_ptrnet = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model_ptrnet.parameters()),\n",
    "    lr=config['learning_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training | PtrNet"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# test untrained model\n",
    "results_ptrnet, _ = test_model_custom(model_ptrnet, test_dataloader, compare_solved_sort_unique, print_every=999999, x_name=0, y_name=1)\n",
    "print('Result: {:.4f}'.format(results_ptrnet))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show rank correlations only with mask on\n",
    "print('K-Tau: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_ptrnet, get_single_kendall_tau, print_every=999999)))\n",
    "print('S-Rho: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_ptrnet, get_single_spearman_rho, print_every=999999)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 1: 100%|██████████| 26/26 [04:23<00:00, 10.15s/ batches, avg_loss=5.29777]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "last_loss_ptrnet = train_epochs(\n",
    "    model_ptrnet,\n",
    "    optimizer_ptrnet,\n",
    "    CCE,\n",
    "    train_dataloader,\n",
    "    config['num_epochs'],\n",
    "    allow_gpu=True,\n",
    "    x_name=0,\n",
    "    y_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.297767162322998"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_loss_ptrnet.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing | PtrNet\n",
    "Put the model in eval() mode first (prevents dropout and such from predicting sth else from the same permuted x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointerCatalogNetwork(\n",
       "  (word_embedding): Embedding(26169, 64)\n",
       "  (offer_embedding): PointerOfferEmbedder(\n",
       "    (offer_rnn): GRU(64, 64, num_layers=2, batch_first=True, dropout=0.05)\n",
       "  )\n",
       "  (encoder): PointerEncoder(\n",
       "    (lstm): LSTM(64, 32, num_layers=2, batch_first=True, dropout=0.05, bidirectional=True)\n",
       "  )\n",
       "  (decoder): PointerDecoder(\n",
       "    (input_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (att): PointerAttention(\n",
       "      (input_linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (context_linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ptrnet.eval()  # if we had dropout or batchnorm, we must do this"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# actual metrics\n",
    "results_ptrnet, _ = test_model_custom(model_ptrnet, test_dataloader, compare_solved_sort_unique, print_every=999999, x_name=0, y_name=1)\n",
    "print('Result: {:.4f}'.format(results_ptrnet))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show rank correlations only with mask on\n",
    "print('K-Tau: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_ptrnet, get_single_kendall_tau, print_every=999999)))\n",
    "print('S-Rho: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_ptrnet, get_single_spearman_rho, print_every=999999)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sacred Experiment | Model PtrNet\n",
    "We'll want to track the dataset, model params and the result of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - real_catalogs_SIGIR_mini_mask_True - Running command 'run_model_tests'\n",
      "INFO - real_catalogs_SIGIR_mini_mask_True - Started run with ID \"79\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'publication_2_models_real_catalogs.PointerCatalogNetwork'>\n",
      "Result: 0.0058\n",
      "K-Tau: 0.2537, perc_valid: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - real_catalogs_SIGIR_mini_mask_True - Result: 0.00583\n",
      "INFO - real_catalogs_SIGIR_mini_mask_True - Completed after 0:00:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-Rho: 0.3790, perc_valid: 100.0\n"
     ]
    }
   ],
   "source": [
    "# experiment config\n",
    "current_tested_model = model_ptrnet\n",
    "current_optimizer = optimizer_ptrnet\n",
    "current_last_loss = last_loss_ptrnet\n",
    "\n",
    "config_update = {\n",
    "    'model': current_tested_model.__class__.__name__,\n",
    "    'final_training_loss': round(current_last_loss.item(), 10),\n",
    "    'optimizer': current_optimizer.__class__.__name__,\n",
    "    'cfg': config,\n",
    "}\n",
    "\n",
    "# run the experiment, with updated config\n",
    "run_info = ex.run(config_updates=config_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show predictions\n",
    "See what it predicts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specific catalog prediction, with offer text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a catalog\n",
    "chosen_catalog_id = '0003leq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t2502x0fY h: Leeuwenkuil TA' • Chenin Blanc • Shiraz • Lion's Lair, d: TA' • Chenin Blanc • Shiraz • Lion's Lair\n",
      "\t070eU0fY h: Ribena • Original • Light. 850 ml, d: • Original • Light. 850 ml\n",
      "\ta6a7Z0fY h: Diamond hill 3 LITER. • Chardonnay • Shiraz • Shiraz/merlot., d: 3 LITER. • Chardonnay • Shiraz • Shiraz/merlot. BAG-IN-BOX. \n",
      "\t183cY0fY h: Marabou chokoladebars 35-46 gram. • Fransk Nougat • Marabou , d: 35-46 gram. • Fransk Nougat • Marabou Original • Marabou Ore\n",
      "\t257as0fY h: Lays chips, bugles eller doritos Sour Cream & Onion - BBQ - , d: Sour Cream & Onion - BBQ - Salt - • - Original - Nacho Chees\n",
      "\t0da4f0fY h: Primitivo di manduria • Carlo Sani. Denne Primitivo har være, d: • Carlo Sani. Denne Primitivo har været lagret i cirka 6 mån\n",
      "\t4809E0fY h: Haribo POSE. DET ER BILLIGT. 100-135 gram. • Slikposer 135 g, d: POSE. DET ER BILLIGT. 100-135 gram. • Slikposer 135 gram • S\n",
      "\t4815F0fY h: Sodavand 150 cl. Flere varianter. + PANT. 3. • Nikoline • Fa, d: 150 cl. Flere varianter. + PANT. 3. • Nikoline • Faxe Kondi \n",
      "\tf1a9z0fY h: Bki kaffe 500 gram. • Classic Gold • ABC - hele bønner, d: 500 gram. • Classic Gold • ABC - hele bønner\n",
      "\t3672p0fY h: Duyvis nødder Flere varianter 175-225 gram, d: Flere varianter 175-225 gram\n",
      "\t283c80fY h: Nescafé gold STORT GLAS. • Instant kaffe - Original - Crema., d: STORT GLAS. • Instant kaffe - Original - Crema. 200 gram\n",
      "------------------------\n",
      "\tb553q0fY h: Helt kalkunbryst Ca. 800 gram, d: Ca. 800 gram\n",
      "\t36f3y0fY h: Danpo • Frikadeller • Medister. 400 gram, d: • Frikadeller • Medister. 400 gram\n",
      "\t222fcqfY h: Bbq mørbrad 450 gram. JENSENS, d: 450 gram. JENSENS\n",
      "\t5cb900fY h: Skinkestege 700-800 gram. • Orientalsk • Mexico, d: 700-800 gram. • Orientalsk • Mexico\n",
      "\t7d7a10fY h: Nakkefilet DANSK. 1/2 KG. Skæres til nakkekoteletter, steges, d: DANSK. 1/2 KG. Skæres til nakkekoteletter, steges hel eller \n",
      "\t97f9K0fY h: Kylling I ovnklar stegepose 1500 gram. HEL DANSK, d: I ovnklar stegepose 1500 gram. HEL DANSK\n",
      "\tfc78C0fY h: Hakket kalv- & flæsk . 8-12% Ca. 500 gram. SLAGTER NORLYK ER, d: . 8-12% Ca. 500 gram. SLAGTER NORLYK ER HELE ABC LAVPRIS's S\n",
      "\tc90d30fY h: Steaks Ca. 1000 gram. AF UNGKVÆG. Små fine hverdags- steaks , d: Ca. 1000 gram. AF UNGKVÆG. Små fine hverdags- steaks skåret \n",
      "\t5b2ag0fY h: Amanda luksusrogn Pr, d: Pr\n",
      "\tc941A0fY h: Weekend menu tilberedt Komplet MENU af de menu TIL til 22 be, d: tilberedt Komplet MENU af de menu TIL til 22 bedste personer\n",
      "\ta259L0fY h: Sild i spand 800/400-700 gram. • Marinerede hele fileter • M, d: 800/400-700 gram. • Marinerede hele fileter • Marinerede i b\n",
      "\t6429tqfY h: Nordjyder 500. • Frankfurter • Røde knækpølser • Grill pølse, d: 500. • Frankfurter • Røde knækpølser • Grill pølser • Hot do\n",
      "\ta5caD0fY h: Jægerkoteletter Ca. 400 gram. Marinerede koteletter med svam, d: Ca. 400 gram. Marinerede koteletter med svampe, bacon. Tilsæ\n",
      "\t08cfm0fY h: Danpo hakket kylling 450 gram, d: 450 gram\n",
      "\t22edWqfY h: Flensted kartoffelgratin med fløde 500 gram., d: med fløde 500 gram.\n",
      "------------------------\n",
      "\tb7fcb0fY h: Harpic Wc-blåt, d: \n",
      "\td4f0v0fY h: Zendium FRIT VALG. • Tandpasta • Tandbørster • Mundskyl 500 , d: FRIT VALG. • Tandpasta • Tandbørster • Mundskyl 500 ml. Fler\n",
      "\tfb3cQ0fY h: Libero bleer • Comfort • UP&GO. 38-68 stk. • •. 400. Flere v, d: • Comfort • UP&GO. 38-68 stk. • •. 400. Flere varianter. DET\n",
      "\t0ba1i0fY h: Bamseline skyllemiddel Flere varianter 1000 ml., d: Flere varianter 1000 ml.\n",
      "\ta367w0fY h: Libresse Flere varianter. • Trusseindlæg • Bind, d: Flere varianter. • Trusseindlæg • Bind\n",
      "\tac74V0fY h: Hårspray ELNETT. • Extra kraftig • Strong hold. 400 ml, d: ELNETT. • Extra kraftig • Strong hold. 400 ml\n",
      "\t3531u0fY h: Bio-tex • Flydende vask. - Color - White - Black. TA' 920 ml, d: • Flydende vask. - Color - White - Black. TA' 920 ml\n",
      "\tfbff20fY h: Elvital Alle varianter. 200-250 ml. • Shampoo • Balsam • 2in, d: Alle varianter. 200-250 ml. • Shampoo • Balsam • 2in1\n",
      "\te4b8a0fY h: L'oréal triple active creme Flere varianter. 50 ml, d: Flere varianter. 50 ml\n",
      "\t3956N0fY h: Harpic wc-rens Flere varianter 750 ml. KÆMPE PARTI, d: Flere varianter 750 ml. KÆMPE PARTI\n",
      "\t0d81d0fY h: Rexona deodoranter Flere varianter. 50-150 ml. • Spray • Rol, d: Flere varianter. 50-150 ml. • Spray • Roll-on\n",
      "\t029aT0fY h: Abena affaldsposer PR. SAM-PAK. 3 x, d: PR. SAM-PAK. 3 x\n",
      "\t5dbdl0fY h: Axe deodoranter Flere varianter. 150 ml. • Spray, d: Flere varianter. 150 ml. • Spray\n",
      "------------------------\n",
      "\tfed3AqfY h: Påskebryg 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælges fra fre, d: 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælges fra fredag d. 17/\n",
      "\t799dzqfY h: Frisk dansk mælk PR. LITER. Max. 24 timer fra gård til butik, d: PR. LITER. Max. 24 timer fra gård til butik • Skummetmælk • \n",
      "\tb8a3DqfY h: Sukkervafler BELGISKE. 550 gram, d: BELGISKE. 550 gram\n",
      "\ta4c88qfY h: Hatting fransk hotdog  gigant burgerboller 4-6 stk. •, d: 4-6 stk. •\n",
      "\t3cf8qqfY h: Oreo eller prince chokoladekiks 154-240 gram. Flere variante, d: 154-240 gram. Flere varianter\n",
      "\t88a5UqfY h: Knækbrød LEKSANDS. Flere varianter 200 gram, d: LEKSANDS. Flere varianter 200 gram\n",
      "\t6d6e0qfY h: Carletti 73,5 gram. • Lys • Mørk. PÅLÆGSCHOKOLADE. TA', d: 73,5 gram. • Lys • Mørk. PÅLÆGSCHOKOLADE. TA'\n",
      "\tef59YqfY h: Corny müslibars 6 stk. • Nuts, d: 6 stk. • Nuts\n",
      "\tab38CqfY h: BKI KAFFE  • Extra. 400 gram. Ved køb af mere end 10 poser, , d: • Extra. 400 gram. Ved køb af mere end 10 poser, er prisen h\n",
      "\t0cbffqfY h: Pålækker 80-90 gram. - Classic - Tomat. VILDT BILLIGT. • Ham, d: 80-90 gram. - Classic - Tomat. VILDT BILLIGT. • Hamburgerryg\n",
      "\t0a4eEqfY h: Havregryn Ved køb af mere end 6 poser, er prisen herefter 8,, d: Ved køb af mere end 6 poser, er prisen herefter 8,98 kr. 100\n",
      "------------------------\n",
      "\t0ef3QqfY h: Kyllingelår KUN 11,66 KR. PR. KG DET ER BILLIGT. HELE. • Med, d: KUN 11,66 KR. PR. KG DET ER BILLIGT. HELE. • Med rygben 100%\n",
      "\ta3abpqfY h: Steff houlberg • Brændende kærlighed • Forloren hare • Bolle, d: • Brændende kærlighed • Forloren hare • Boller i karry • Dan\n",
      "\tce94wqfY h: Ice cap rejer 125 gram, d: 125 gram\n",
      "\te545VqfY h: Viennetta is 650 ml. ISKOLD PRIS, d: 650 ml. ISKOLD PRIS\n",
      "\t11aaxqfY h: Kyllingeburger I alt 1000 gram. Af kyllingebrystfilet, d: I alt 1000 gram. Af kyllingebrystfilet\n",
      "\te4e12qfY h: Frigodan • Bønnemix • Grønt m/karry • Grønt m/tomat. 450 gra, d: • Bønnemix • Grønt m/karry • Grønt m/tomat. 450 gram\n",
      "\t431baqfY h: Toast 200-290 gram. • Pariser toast • Cowboy toast. STEFF HO, d: 200-290 gram. • Pariser toast • Cowboy toast. STEFF HOULBERG\n",
      "\t3030ZqfY h: Mou luksus suppe 1000 gram. Mange varianter, d: 1000 gram. Mange varianter\n",
      "\tdb3fNqfY h: Andelår JULIUS. 160-200 gram. CHOK PRIS, d: JULIUS. 160-200 gram. CHOK PRIS\n",
      "\td638dqfY h: Frigodan ISKOLD PRIS. • Broccoli • Fine ærter • Meget fine H, d: ISKOLD PRIS. • Broccoli • Fine ærter • Meget fine Haricots v\n",
      "\t539csqfY h: Mou kødboller 650 gram, d: 650 gram\n",
      "\tb25flqfY h: Andebryst 130-150 gram. JULIUS, d: 130-150 gram. JULIUS\n",
      "\t18cdFqfY h: Hønskød i tern 400 gram. Kogt og klar til brug i f.eks. tart, d: 400 gram. Kogt og klar til brug i f.eks. tarteletfyld\n",
      "\t50b5vqfY h: Hvidløgsbaguettes PR. 525 gram, d: PR. 525 gram\n",
      "------------------------\n",
      "\tdb9dGqfY h: God morgen juice Appelsin/blodgrape Appelsin. LITER. FIND DE, d: Appelsin/blodgrape Appelsin. LITER. FIND DEN PÅ KØL !\n",
      "\t4daaRqfY h: 3-stjernet • Kødpølse • Røget medister • Jægerpølse • Frikad, d: • Kødpølse • Røget medister • Jægerpølse • Frikadelle i skiv\n",
      "\tbd0fXqfY h: Riberhus 200 gram. I SKIVER. • Mellemlagret, d: 200 gram. I SKIVER. • Mellemlagret\n",
      "\t9937SqfY h: Salater 150-175 gram. GRAASTEN. Mange varianter, d: 150-175 gram. GRAASTEN. Mange varianter\n",
      "\ta3ddnqfY h: Schulstad • Skovmand - Original - Ekstra grov. - Med fuldkor, d: • Skovmand - Original - Ekstra grov. - Med fuldkorn. 400-100\n",
      "\t59cchqfY h: Flødehavarti 300 gram. VILDT BILLIGT, d: 300 gram. VILDT BILLIGT\n",
      "\td8f9oqfY h: Margarine •. 500 gram. BINE. BILLIGST PÅ HELE INDKØBET, d: •. 500 gram. BINE. BILLIGST PÅ HELE INDKØBET\n",
      "\t0be3HqfY h: Spegepølser 3-STJERNET. 200-230 gram. Flere varianter, d: 3-STJERNET. 200-230 gram. Flere varianter\n",
      "\tb3acOqfY h: Xl lagret ost Ca. 1400 gram, d: Ca. 1400 gram\n",
      "\taeberqfY h: Yoggi yoghurt 1000 gram. . Flere varianter, d: 1000 gram. . Flere varianter\n",
      "\t44a2IqfY h: Tulip •. 300-350 gram. • Baconpostej • Krydderpostej • Fløde, d: •. 300-350 gram. • Baconpostej • Krydderpostej • Flødepostej\n",
      "\t708e7qfY h: Cultura drik 500 ml. • Blåbær • Jordbær, d: 500 ml. • Blåbær • Jordbær\n",
      "\tf4f4MqfY h: Tulip PAKKE. 200 gram. MIDDAGS- FRIKADELLER, d: PAKKE. 200 gram. MIDDAGS- FRIKADELLER\n",
      "------------------------\n",
      "\t29c0BqfY h: stærk chili sauce, sur/sød sauce eller sambal oelek 200-250 , d: 200-250 ml. 100 gram\n",
      "\t9381iqfY h: Tortilla chips SANTA MARIA. 185 gram. • Salted • Cheese • Ch, d: SANTA MARIA. 185 gram. • Salted • Cheese • Chili\n",
      "\t907ajqfY h: Æbler 2 kg. pink lady. vildt billigt, d: 2 kg. pink lady. vildt billigt\n",
      "\t28d5kqfY h: Babymajs 400 gram, d: 400 gram\n",
      "\t280auqfY h: Kartoffelmos 4 breve. á 125 gram. QUEEN, d: 4 breve. á 125 gram. QUEEN\n",
      "\t00b64qfY h: avokado, squash, forårsløg eller radiser m/ top Bundt, d: Bundt\n",
      "\t1864JqfY h: Santa maria nudler 250 gram. VILDT BILLIGT, d: 250 gram. VILDT BILLIGT\n",
      "\te2835qfY h: Asparges FRISKE. 250 gram, d: FRISKE. 250 gram\n",
      "\t7c1eeqfY h: Kokosmælk 17-19%. 400 ml, d: 17-19%. 400 ml\n",
      "\t067bTqfY h: Knorr • Orientalsk risret • Indisk risret • Chicken curry • , d: • Orientalsk risret • Indisk risret • Chicken curry • Mexika\n",
      "\t46df6qfY h: kalanchoe eller potteroser, d: \n",
      "\tb84a9qfY h: bambusskud eller vandkastanjer 227 gram, d: 227 gram\n",
      "\t614ebqfY h: Hellmann's mayonnaise • I glas • I tube. 225-400 gram, d: • I glas • I tube. 225-400 gram\n",
      "\t11bbPqfY h: Blomme tomater 500 gram, d: 500 gram\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n"
     ]
    }
   ],
   "source": [
    "# show correct\n",
    "show_correct_catalog(\n",
    "    catalog_id=chosen_catalog_id,\n",
    "    catalogs_dataframe=df_catalogs,\n",
    "    offers_dataframe=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use premade function to nicely display a single prediction.\n",
    "\n",
    "**Models that do not properly ensure permutation invariance will give different prediction on each run** regardless of being put in .eval() mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0d81d0fY h: Rexona deodoranter Flere varianter. 50-150 ml. • Spray • Rol, d: Flere varianter. 50-150 ml. • Spray • Roll-on\n",
      "\t46df6qfY h: kalanchoe eller potteroser, d: \n",
      "\t3030ZqfY h: Mou luksus suppe 1000 gram. Mange varianter, d: 1000 gram. Mange varianter\n",
      "\tb3acOqfY h: Xl lagret ost Ca. 1400 gram, d: Ca. 1400 gram\n",
      "\t029aT0fY h: Abena affaldsposer PR. SAM-PAK. 3 x, d: PR. SAM-PAK. 3 x\n",
      "\t7d7a10fY h: Nakkefilet DANSK. 1/2 KG. Skæres til nakkekoteletter, steges, d: DANSK. 1/2 KG. Skæres til nakkekoteletter, steges hel eller \n",
      "\t708e7qfY h: Cultura drik 500 ml. • Blåbær • Jordbær, d: 500 ml. • Blåbær • Jordbær\n",
      "\ta3abpqfY h: Steff houlberg • Brændende kærlighed • Forloren hare • Bolle, d: • Brændende kærlighed • Forloren hare • Boller i karry • Dan\n",
      "\ta367w0fY h: Libresse Flere varianter. • Trusseindlæg • Bind, d: Flere varianter. • Trusseindlæg • Bind\n",
      "\t18cdFqfY h: Hønskød i tern 400 gram. Kogt og klar til brug i f.eks. tart, d: 400 gram. Kogt og klar til brug i f.eks. tarteletfyld\n",
      "\t0ba1i0fY h: Bamseline skyllemiddel Flere varianter 1000 ml., d: Flere varianter 1000 ml.\n",
      "\tb7fcb0fY h: Harpic Wc-blåt, d: \n",
      "\tc90d30fY h: Steaks Ca. 1000 gram. AF UNGKVÆG. Små fine hverdags- steaks , d: Ca. 1000 gram. AF UNGKVÆG. Små fine hverdags- steaks skåret \n",
      "\td8f9oqfY h: Margarine •. 500 gram. BINE. BILLIGST PÅ HELE INDKØBET, d: •. 500 gram. BINE. BILLIGST PÅ HELE INDKØBET\n",
      "\t539csqfY h: Mou kødboller 650 gram, d: 650 gram\n",
      "\t00b64qfY h: avokado, squash, forårsløg eller radiser m/ top Bundt, d: Bundt\n",
      "\t0a4eEqfY h: Havregryn Ved køb af mere end 6 poser, er prisen herefter 8,, d: Ved køb af mere end 6 poser, er prisen herefter 8,98 kr. 100\n",
      "\tbd0fXqfY h: Riberhus 200 gram. I SKIVER. • Mellemlagret, d: 200 gram. I SKIVER. • Mellemlagret\n",
      "\tdb3fNqfY h: Andelår JULIUS. 160-200 gram. CHOK PRIS, d: JULIUS. 160-200 gram. CHOK PRIS\n",
      "\t11aaxqfY h: Kyllingeburger I alt 1000 gram. Af kyllingebrystfilet, d: I alt 1000 gram. Af kyllingebrystfilet\n",
      "\t614ebqfY h: Hellmann's mayonnaise • I glas • I tube. 225-400 gram, d: • I glas • I tube. 225-400 gram\n",
      "\t08cfm0fY h: Danpo hakket kylling 450 gram, d: 450 gram\n",
      "\te2835qfY h: Asparges FRISKE. 250 gram, d: FRISKE. 250 gram\n",
      "\tce94wqfY h: Ice cap rejer 125 gram, d: 125 gram\n",
      "\t0ef3QqfY h: Kyllingelår KUN 11,66 KR. PR. KG DET ER BILLIGT. HELE. • Med, d: KUN 11,66 KR. PR. KG DET ER BILLIGT. HELE. • Med rygben 100%\n",
      "\t7c1eeqfY h: Kokosmælk 17-19%. 400 ml, d: 17-19%. 400 ml\n",
      "\ta6a7Z0fY h: Diamond hill 3 LITER. • Chardonnay • Shiraz • Shiraz/merlot., d: 3 LITER. • Chardonnay • Shiraz • Shiraz/merlot. BAG-IN-BOX. \n",
      "\td4f0v0fY h: Zendium FRIT VALG. • Tandpasta • Tandbørster • Mundskyl 500 , d: FRIT VALG. • Tandpasta • Tandbørster • Mundskyl 500 ml. Fler\n",
      "\tb25flqfY h: Andebryst 130-150 gram. JULIUS, d: 130-150 gram. JULIUS\n",
      "\td638dqfY h: Frigodan ISKOLD PRIS. • Broccoli • Fine ærter • Meget fine H, d: ISKOLD PRIS. • Broccoli • Fine ærter • Meget fine Haricots v\n",
      "\tb553q0fY h: Helt kalkunbryst Ca. 800 gram, d: Ca. 800 gram\n",
      "\t97f9K0fY h: Kylling I ovnklar stegepose 1500 gram. HEL DANSK, d: I ovnklar stegepose 1500 gram. HEL DANSK\n",
      "\t22edWqfY h: Flensted kartoffelgratin med fløde 500 gram., d: med fløde 500 gram.\n",
      "\t5cb900fY h: Skinkestege 700-800 gram. • Orientalsk • Mexico, d: 700-800 gram. • Orientalsk • Mexico\n",
      "\te4e12qfY h: Frigodan • Bønnemix • Grønt m/karry • Grønt m/tomat. 450 gra, d: • Bønnemix • Grønt m/karry • Grønt m/tomat. 450 gram\n",
      "\tf1a9z0fY h: Bki kaffe 500 gram. • Classic Gold • ABC - hele bønner, d: 500 gram. • Classic Gold • ABC - hele bønner\n",
      "\t9937SqfY h: Salater 150-175 gram. GRAASTEN. Mange varianter, d: 150-175 gram. GRAASTEN. Mange varianter\n",
      "\ta259L0fY h: Sild i spand 800/400-700 gram. • Marinerede hele fileter • M, d: 800/400-700 gram. • Marinerede hele fileter • Marinerede i b\n",
      "\te545VqfY h: Viennetta is 650 ml. ISKOLD PRIS, d: 650 ml. ISKOLD PRIS\n",
      "\ta5caD0fY h: Jægerkoteletter Ca. 400 gram. Marinerede koteletter med svam, d: Ca. 400 gram. Marinerede koteletter med svampe, bacon. Tilsæ\n",
      "\tb8a3DqfY h: Sukkervafler BELGISKE. 550 gram, d: BELGISKE. 550 gram\n",
      "\t50b5vqfY h: Hvidløgsbaguettes PR. 525 gram, d: PR. 525 gram\n",
      "\tfc78C0fY h: Hakket kalv- & flæsk . 8-12% Ca. 500 gram. SLAGTER NORLYK ER, d: . 8-12% Ca. 500 gram. SLAGTER NORLYK ER HELE ABC LAVPRIS's S\n",
      "\ta4c88qfY h: Hatting fransk hotdog  gigant burgerboller 4-6 stk. •, d: 4-6 stk. •\n",
      "\t0be3HqfY h: Spegepølser 3-STJERNET. 200-230 gram. Flere varianter, d: 3-STJERNET. 200-230 gram. Flere varianter\n",
      "\tef59YqfY h: Corny müslibars 6 stk. • Nuts, d: 6 stk. • Nuts\n",
      "\t36f3y0fY h: Danpo • Frikadeller • Medister. 400 gram, d: • Frikadeller • Medister. 400 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tab38CqfY h: BKI KAFFE  • Extra. 400 gram. Ved køb af mere end 10 poser, , d: • Extra. 400 gram. Ved køb af mere end 10 poser, er prisen h\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tc941A0fY h: Weekend menu tilberedt Komplet MENU af de menu TIL til 22 be, d: tilberedt Komplet MENU af de menu TIL til 22 bedste personer\n",
      "\t2502x0fY h: Leeuwenkuil TA' • Chenin Blanc • Shiraz • Lion's Lair, d: TA' • Chenin Blanc • Shiraz • Lion's Lair\n",
      "\t431baqfY h: Toast 200-290 gram. • Pariser toast • Cowboy toast. STEFF HO, d: 200-290 gram. • Pariser toast • Cowboy toast. STEFF HOULBERG\n",
      "\t907ajqfY h: Æbler 2 kg. pink lady. vildt billigt, d: 2 kg. pink lady. vildt billigt\n",
      "\t283c80fY h: Nescafé gold STORT GLAS. • Instant kaffe - Original - Crema., d: STORT GLAS. • Instant kaffe - Original - Crema. 200 gram\n",
      "\tf4f4MqfY h: Tulip PAKKE. 200 gram. MIDDAGS- FRIKADELLER, d: PAKKE. 200 gram. MIDDAGS- FRIKADELLER\n",
      "\t3cf8qqfY h: Oreo eller prince chokoladekiks 154-240 gram. Flere variante, d: 154-240 gram. Flere varianter\n",
      "\t28d5kqfY h: Babymajs 400 gram, d: 400 gram\n",
      "\t3956N0fY h: Harpic wc-rens Flere varianter 750 ml. KÆMPE PARTI, d: Flere varianter 750 ml. KÆMPE PARTI\n",
      "\taeberqfY h: Yoggi yoghurt 1000 gram. . Flere varianter, d: 1000 gram. . Flere varianter\n",
      "\t6d6e0qfY h: Carletti 73,5 gram. • Lys • Mørk. PÅLÆGSCHOKOLADE. TA', d: 73,5 gram. • Lys • Mørk. PÅLÆGSCHOKOLADE. TA'\n",
      "\tfbff20fY h: Elvital Alle varianter. 200-250 ml. • Shampoo • Balsam • 2in, d: Alle varianter. 200-250 ml. • Shampoo • Balsam • 2in1\n",
      "\te4b8a0fY h: L'oréal triple active creme Flere varianter. 50 ml, d: Flere varianter. 50 ml\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t11bbPqfY h: Blomme tomater 500 gram, d: 500 gram\n",
      "\t0da4f0fY h: Primitivo di manduria • Carlo Sani. Denne Primitivo har være, d: • Carlo Sani. Denne Primitivo har været lagret i cirka 6 mån\n",
      "\t4daaRqfY h: 3-stjernet • Kødpølse • Røget medister • Jægerpølse • Frikad, d: • Kødpølse • Røget medister • Jægerpølse • Frikadelle i skiv\n",
      "\t9381iqfY h: Tortilla chips SANTA MARIA. 185 gram. • Salted • Cheese • Ch, d: SANTA MARIA. 185 gram. • Salted • Cheese • Chili\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t5dbdl0fY h: Axe deodoranter Flere varianter. 150 ml. • Spray, d: Flere varianter. 150 ml. • Spray\n",
      "\tac74V0fY h: Hårspray ELNETT. • Extra kraftig • Strong hold. 400 ml, d: ELNETT. • Extra kraftig • Strong hold. 400 ml\n",
      "\t1864JqfY h: Santa maria nudler 250 gram. VILDT BILLIGT, d: 250 gram. VILDT BILLIGT\n",
      "\t070eU0fY h: Ribena • Original • Light. 850 ml, d: • Original • Light. 850 ml\n",
      "\t799dzqfY h: Frisk dansk mælk PR. LITER. Max. 24 timer fra gård til butik, d: PR. LITER. Max. 24 timer fra gård til butik • Skummetmælk • \n",
      "\t59cchqfY h: Flødehavarti 300 gram. VILDT BILLIGT, d: 300 gram. VILDT BILLIGT\n",
      "\tdb9dGqfY h: God morgen juice Appelsin/blodgrape Appelsin. LITER. FIND DE, d: Appelsin/blodgrape Appelsin. LITER. FIND DEN PÅ KØL !\n",
      "\tb84a9qfY h: bambusskud eller vandkastanjer 227 gram, d: 227 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t3672p0fY h: Duyvis nødder Flere varianter 175-225 gram, d: Flere varianter 175-225 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t29c0BqfY h: stærk chili sauce, sur/sød sauce eller sambal oelek 200-250 , d: 200-250 ml. 100 gram\n",
      "\t183cY0fY h: Marabou chokoladebars 35-46 gram. • Fransk Nougat • Marabou , d: 35-46 gram. • Fransk Nougat • Marabou Original • Marabou Ore\n",
      "\t3531u0fY h: Bio-tex • Flydende vask. - Color - White - Black. TA' 920 ml, d: • Flydende vask. - Color - White - Black. TA' 920 ml\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t4809E0fY h: Haribo POSE. DET ER BILLIGT. 100-135 gram. • Slikposer 135 g, d: POSE. DET ER BILLIGT. 100-135 gram. • Slikposer 135 gram • S\n",
      "\t5b2ag0fY h: Amanda luksusrogn Pr, d: Pr\n",
      "\t ?NOT_REAL_OFFER?\n",
      "------------------------\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t44a2IqfY h: Tulip •. 300-350 gram. • Baconpostej • Krydderpostej • Fløde, d: •. 300-350 gram. • Baconpostej • Krydderpostej • Flødepostej\n",
      "\t ?NOT_REAL_OFFER?\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t0cbffqfY h: Pålækker 80-90 gram. - Classic - Tomat. VILDT BILLIGT. • Ham, d: 80-90 gram. - Classic - Tomat. VILDT BILLIGT. • Hamburgerryg\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tfb3cQ0fY h: Libero bleer • Comfort • UP&GO. 38-68 stk. • •. 400. Flere v, d: • Comfort • UP&GO. 38-68 stk. • •. 400. Flere varianter. DET\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\ta3ddnqfY h: Schulstad • Skovmand - Original - Ekstra grov. - Med fuldkor, d: • Skovmand - Original - Ekstra grov. - Med fuldkorn. 400-100\n",
      "\t067bTqfY h: Knorr • Orientalsk risret • Indisk risret • Chicken curry • , d: • Orientalsk risret • Indisk risret • Chicken curry • Mexika\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t88a5UqfY h: Knækbrød LEKSANDS. Flere varianter 200 gram, d: LEKSANDS. Flere varianter 200 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "------------------------\n",
      "\t280auqfY h: Kartoffelmos 4 breve. á 125 gram. QUEEN, d: 4 breve. á 125 gram. QUEEN\n",
      "\t222fcqfY h: Bbq mørbrad 450 gram. JENSENS, d: 450 gram. JENSENS\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t257as0fY h: Lays chips, bugles eller doritos Sour Cream & Onion - BBQ - , d: Sour Cream & Onion - BBQ - Salt - • - Original - Nacho Chees\n",
      "\tfed3AqfY h: Påskebryg 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælges fra fre, d: 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælges fra fredag d. 17/\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t4815F0fY h: Sodavand 150 cl. Flere varianter. + PANT. 3. • Nikoline • Fa, d: 150 cl. Flere varianter. + PANT. 3. • Nikoline • Faxe Kondi \n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t6429tqfY h: Nordjyder 500. • Frankfurter • Røde knækpølser • Grill pølse, d: 500. • Frankfurter • Røde knækpølser • Grill pølser • Hot do\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n"
     ]
    }
   ],
   "source": [
    "# show predicted\n",
    "# if the model is not permutation invariant, it will predict sth else\n",
    "# for every random permutation of the source catalog\n",
    "model_ptrnet.eval()\n",
    "show_predicted_catalog(\n",
    "    catalog_id='0003leq',\n",
    "    a_model=model_ptrnet,\n",
    "    catalogs_dataframe=df_catalogs,\n",
    "    offers_dataframe=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model DeepSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from publication_2_models_real_catalogs import DeepSets, DeepSetsPointerCatalogNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepSetsPointerCatalogNetwork(\n",
       "  (word_embedding): Embedding(26169, 64)\n",
       "  (offer_embedding): PointerOfferEmbedder(\n",
       "    (offer_rnn): GRU(64, 64, num_layers=2, batch_first=True, dropout=0.05)\n",
       "  )\n",
       "  (set_embedding): DeepSets(\n",
       "    (encode): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (13): ReLU()\n",
       "    )\n",
       "    (out): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (7): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (encoder): PointerEncoder(\n",
       "    (lstm): LSTM(128, 32, num_layers=2, batch_first=True, dropout=0.05, bidirectional=True)\n",
       "  )\n",
       "  (decoder): PointerDecoder(\n",
       "    (input_to_hidden): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (hidden_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (att): PointerAttention(\n",
       "      (input_linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (context_linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the model\n",
    "model_deepsets = DeepSetsPointerCatalogNetwork(\n",
    "    word_embedding_dim=config['ptr_word_emb_dim'],\n",
    "    offer_embedding_dim=config['ptr_offer_emb_dim'],\n",
    "    hidden_dim=config['ptr_hid_dim'],\n",
    "    offer_rnn_layers=config['ptr_offer_rnn_layers'],\n",
    "    catalog_rnn_layers=config['ptr_catalog_rnn_layers'],\n",
    "    dropout_offers=config['ptr_dropout_offers'],\n",
    "    dropout_catalogs=config['ptr_dropout_catalogs'],\n",
    "    bidir_offers=config['ptr_bidir_offers'],  # not handled 2021 04\n",
    "    bidir_catalogs=config['ptr_bidir_catalogs'],\n",
    "    masking=config['ptr_mask'],\n",
    "    vocab_size=len(word2idx),\n",
    ")\n",
    "\n",
    "model_deepsets.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,944,576 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# how many params\n",
    "count_params(model_deepsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-elem batch\n",
    "batch_x = X_train_torch[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 200, 200]) torch.Size([2, 200])\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "_ = model_deepsets(batch_x)\n",
    "print(_[0].size(), _[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "print(_[1].type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "CCE = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer_deepsets = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model_deepsets.parameters()),\n",
    "    lr=config['learning_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training | DeepSets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# test untrained model\n",
    "results_deepsets, _ = test_model_custom(model_deepsets, test_dataloader, compare_solved_sort_unique, print_every=999999, x_name=0, y_name=1)\n",
    "print('Result: {:.4f}'.format(results_deepsets))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show rank correlations only with mask on\n",
    "print('K-Tau: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_deepsets, get_single_kendall_tau, print_every=999999)))\n",
    "print('S-Rho: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_deepsets, get_single_spearman_rho, print_every=999999)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 1: 100%|██████████| 26/26 [04:47<00:00, 11.04s/ batches, avg_loss=5.29849]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "last_loss_deepsets = train_epochs(\n",
    "    model_deepsets,\n",
    "    optimizer_deepsets,\n",
    "    CCE,\n",
    "    train_dataloader,\n",
    "    config['num_epochs'],\n",
    "    allow_gpu=True,\n",
    "    x_name=0,\n",
    "    y_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.298487663269043"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_loss_deepsets.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing | DeepSets\n",
    "Put the model in eval() mode first (prevents dropout and such from predicting sth else from the same permuted x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepSetsPointerCatalogNetwork(\n",
       "  (word_embedding): Embedding(26169, 64)\n",
       "  (offer_embedding): PointerOfferEmbedder(\n",
       "    (offer_rnn): GRU(64, 64, num_layers=2, batch_first=True, dropout=0.05)\n",
       "  )\n",
       "  (set_embedding): DeepSets(\n",
       "    (encode): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (9): ReLU()\n",
       "      (10): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (13): ReLU()\n",
       "    )\n",
       "    (out): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (7): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (encoder): PointerEncoder(\n",
       "    (lstm): LSTM(128, 32, num_layers=2, batch_first=True, dropout=0.05, bidirectional=True)\n",
       "  )\n",
       "  (decoder): PointerDecoder(\n",
       "    (input_to_hidden): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (hidden_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (att): PointerAttention(\n",
       "      (input_linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (context_linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_deepsets.eval()  # if we had dropout or batchnorm, we must do this"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# actual metrics\n",
    "results_deepsets, _ = test_model_custom(model_deepsets, test_dataloader, compare_solved_sort_unique, print_every=999999, x_name=0, y_name=1)\n",
    "print('Result: {:.4f}'.format(results_deepsets))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show rank correlations only with mask on\n",
    "print('K-Tau: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_deepsets, get_single_kendall_tau, print_every=999999)))\n",
    "print('S-Rho: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_deepsets, get_single_spearman_rho, print_every=999999)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sacred Experiment | Model DeepSets\n",
    "We'll want to track the dataset, model params and the result of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - real_catalogs_SIGIR_mini_mask_True - Running command 'run_model_tests'\n",
      "INFO - real_catalogs_SIGIR_mini_mask_True - Started run with ID \"80\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'publication_2_models_real_catalogs.DeepSetsPointerCatalogNetwork'>\n",
      "Result: 0.0071\n",
      "K-Tau: -0.0308, perc_valid: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - real_catalogs_SIGIR_mini_mask_True - Result: 0.00708\n",
      "INFO - real_catalogs_SIGIR_mini_mask_True - Completed after 0:00:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-Rho: -0.0453, perc_valid: 100.0\n"
     ]
    }
   ],
   "source": [
    "# experiment config\n",
    "current_tested_model = model_deepsets\n",
    "current_optimizer = optimizer_deepsets\n",
    "current_last_loss = last_loss_deepsets\n",
    "\n",
    "config_update = {\n",
    "    'model': current_tested_model.__class__.__name__,\n",
    "    'final_training_loss': round(current_last_loss.item(), 10),\n",
    "    'optimizer': current_optimizer.__class__.__name__,\n",
    "    'cfg': config,\n",
    "}\n",
    "\n",
    "# run the experiment, with updated config\n",
    "run_info = ex.run(config_updates=config_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show predictions\n",
    "See what it predicts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specific catalog prediction, with offer text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a catalog\n",
    "chosen_catalog_id = '0003leq'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show correct\n",
    "show_correct_catalog(\n",
    "    catalog_id=chosen_catalog_id,\n",
    "    catalogs_dataframe=df_catalogs,\n",
    "    offers_dataframe=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use premade function to nicely display a single prediction.\n",
    "\n",
    "**Models that do not properly ensure permutation invariance will give different prediction on each run** regardless of being put in .eval() mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tdb9dGqfY h: God morgen juice Appelsin/blodgrape Appelsin. LITER. FIND DE, d: Appelsin/blodgrape Appelsin. LITER. FIND DEN PÅ KØL !\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t0da4f0fY h: Primitivo di manduria • Carlo Sani. Denne Primitivo har være, d: • Carlo Sani. Denne Primitivo har været lagret i cirka 6 mån\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t0d81d0fY h: Rexona deodoranter Flere varianter. 50-150 ml. • Spray • Rol, d: Flere varianter. 50-150 ml. • Spray • Roll-on\n",
      "------------------------\n",
      "------------------------\n",
      "\t9381iqfY h: Tortilla chips SANTA MARIA. 185 gram. • Salted • Cheese • Ch, d: SANTA MARIA. 185 gram. • Salted • Cheese • Chili\n",
      "------------------------\n",
      "\t11aaxqfY h: Kyllingeburger I alt 1000 gram. Af kyllingebrystfilet, d: I alt 1000 gram. Af kyllingebrystfilet\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\te4b8a0fY h: L'oréal triple active creme Flere varianter. 50 ml, d: Flere varianter. 50 ml\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t183cY0fY h: Marabou chokoladebars 35-46 gram. • Fransk Nougat • Marabou , d: 35-46 gram. • Fransk Nougat • Marabou Original • Marabou Ore\n",
      "------------------------\n",
      "\t5cb900fY h: Skinkestege 700-800 gram. • Orientalsk • Mexico, d: 700-800 gram. • Orientalsk • Mexico\n",
      "\t6429tqfY h: Nordjyder 500. • Frankfurter • Røde knækpølser • Grill pølse, d: 500. • Frankfurter • Røde knækpølser • Grill pølser • Hot do\n",
      "\t18cdFqfY h: Hønskød i tern 400 gram. Kogt og klar til brug i f.eks. tart, d: 400 gram. Kogt og klar til brug i f.eks. tarteletfyld\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t6d6e0qfY h: Carletti 73,5 gram. • Lys • Mørk. PÅLÆGSCHOKOLADE. TA', d: 73,5 gram. • Lys • Mørk. PÅLÆGSCHOKOLADE. TA'\n",
      "\ta259L0fY h: Sild i spand 800/400-700 gram. • Marinerede hele fileter • M, d: 800/400-700 gram. • Marinerede hele fileter • Marinerede i b\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "------------------------\n",
      "\tce94wqfY h: Ice cap rejer 125 gram, d: 125 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\ta4c88qfY h: Hatting fransk hotdog  gigant burgerboller 4-6 stk. •, d: 4-6 stk. •\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\td638dqfY h: Frigodan ISKOLD PRIS. • Broccoli • Fine ærter • Meget fine H, d: ISKOLD PRIS. • Broccoli • Fine ærter • Meget fine Haricots v\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tb7fcb0fY h: Harpic Wc-blåt, d: \n",
      "\te2835qfY h: Asparges FRISKE. 250 gram, d: FRISKE. 250 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t3030ZqfY h: Mou luksus suppe 1000 gram. Mange varianter, d: 1000 gram. Mange varianter\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\te4e12qfY h: Frigodan • Bønnemix • Grønt m/karry • Grønt m/tomat. 450 gra, d: • Bønnemix • Grønt m/karry • Grønt m/tomat. 450 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\te545VqfY h: Viennetta is 650 ml. ISKOLD PRIS, d: 650 ml. ISKOLD PRIS\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tfb3cQ0fY h: Libero bleer • Comfort • UP&GO. 38-68 stk. • •. 400. Flere v, d: • Comfort • UP&GO. 38-68 stk. • •. 400. Flere varianter. DET\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t50b5vqfY h: Hvidløgsbaguettes PR. 525 gram, d: PR. 525 gram\n",
      "\ta3ddnqfY h: Schulstad • Skovmand - Original - Ekstra grov. - Med fuldkor, d: • Skovmand - Original - Ekstra grov. - Med fuldkorn. 400-100\n",
      "\t7d7a10fY h: Nakkefilet DANSK. 1/2 KG. Skæres til nakkekoteletter, steges, d: DANSK. 1/2 KG. Skæres til nakkekoteletter, steges hel eller \n",
      "\t070eU0fY h: Ribena • Original • Light. 850 ml, d: • Original • Light. 850 ml\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t28d5kqfY h: Babymajs 400 gram, d: 400 gram\n",
      "\t029aT0fY h: Abena affaldsposer PR. SAM-PAK. 3 x, d: PR. SAM-PAK. 3 x\n",
      "\t5b2ag0fY h: Amanda luksusrogn Pr, d: Pr\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t067bTqfY h: Knorr • Orientalsk risret • Indisk risret • Chicken curry • , d: • Orientalsk risret • Indisk risret • Chicken curry • Mexika\n",
      "\tf1a9z0fY h: Bki kaffe 500 gram. • Classic Gold • ABC - hele bønner, d: 500 gram. • Classic Gold • ABC - hele bønner\n",
      "\tb3acOqfY h: Xl lagret ost Ca. 1400 gram, d: Ca. 1400 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t44a2IqfY h: Tulip •. 300-350 gram. • Baconpostej • Krydderpostej • Fløde, d: •. 300-350 gram. • Baconpostej • Krydderpostej • Flødepostej\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tdb3fNqfY h: Andelår JULIUS. 160-200 gram. CHOK PRIS, d: JULIUS. 160-200 gram. CHOK PRIS\n",
      "\t708e7qfY h: Cultura drik 500 ml. • Blåbær • Jordbær, d: 500 ml. • Blåbær • Jordbær\n",
      "\t3531u0fY h: Bio-tex • Flydende vask. - Color - White - Black. TA' 920 ml, d: • Flydende vask. - Color - White - Black. TA' 920 ml\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t907ajqfY h: Æbler 2 kg. pink lady. vildt billigt, d: 2 kg. pink lady. vildt billigt\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\td4f0v0fY h: Zendium FRIT VALG. • Tandpasta • Tandbørster • Mundskyl 500 , d: FRIT VALG. • Tandpasta • Tandbørster • Mundskyl 500 ml. Fler\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t7c1eeqfY h: Kokosmælk 17-19%. 400 ml, d: 17-19%. 400 ml\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tbd0fXqfY h: Riberhus 200 gram. I SKIVER. • Mellemlagret, d: 200 gram. I SKIVER. • Mellemlagret\n",
      "\tf4f4MqfY h: Tulip PAKKE. 200 gram. MIDDAGS- FRIKADELLER, d: PAKKE. 200 gram. MIDDAGS- FRIKADELLER\n",
      "\t3cf8qqfY h: Oreo eller prince chokoladekiks 154-240 gram. Flere variante, d: 154-240 gram. Flere varianter\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t88a5UqfY h: Knækbrød LEKSANDS. Flere varianter 200 gram, d: LEKSANDS. Flere varianter 200 gram\n",
      "\t283c80fY h: Nescafé gold STORT GLAS. • Instant kaffe - Original - Crema., d: STORT GLAS. • Instant kaffe - Original - Crema. 200 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t0ef3QqfY h: Kyllingelår KUN 11,66 KR. PR. KG DET ER BILLIGT. HELE. • Med, d: KUN 11,66 KR. PR. KG DET ER BILLIGT. HELE. • Med rygben 100%\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tb8a3DqfY h: Sukkervafler BELGISKE. 550 gram, d: BELGISKE. 550 gram\n",
      "\t0be3HqfY h: Spegepølser 3-STJERNET. 200-230 gram. Flere varianter, d: 3-STJERNET. 200-230 gram. Flere varianter\n",
      "\tb25flqfY h: Andebryst 130-150 gram. JULIUS, d: 130-150 gram. JULIUS\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\ta3abpqfY h: Steff houlberg • Brændende kærlighed • Forloren hare • Bolle, d: • Brændende kærlighed • Forloren hare • Boller i karry • Dan\n",
      "\t799dzqfY h: Frisk dansk mælk PR. LITER. Max. 24 timer fra gård til butik, d: PR. LITER. Max. 24 timer fra gård til butik • Skummetmælk • \n",
      "\ta6a7Z0fY h: Diamond hill 3 LITER. • Chardonnay • Shiraz • Shiraz/merlot., d: 3 LITER. • Chardonnay • Shiraz • Shiraz/merlot. BAG-IN-BOX. \n",
      "\t0ba1i0fY h: Bamseline skyllemiddel Flere varianter 1000 ml., d: Flere varianter 1000 ml.\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t3672p0fY h: Duyvis nødder Flere varianter 175-225 gram, d: Flere varianter 175-225 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tef59YqfY h: Corny müslibars 6 stk. • Nuts, d: 6 stk. • Nuts\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\ta5caD0fY h: Jægerkoteletter Ca. 400 gram. Marinerede koteletter med svam, d: Ca. 400 gram. Marinerede koteletter med svampe, bacon. Tilsæ\n",
      "\t0a4eEqfY h: Havregryn Ved køb af mere end 6 poser, er prisen herefter 8,, d: Ved køb af mere end 6 poser, er prisen herefter 8,98 kr. 100\n",
      "\t431baqfY h: Toast 200-290 gram. • Pariser toast • Cowboy toast. STEFF HO, d: 200-290 gram. • Pariser toast • Cowboy toast. STEFF HOULBERG\n",
      "\t5dbdl0fY h: Axe deodoranter Flere varianter. 150 ml. • Spray, d: Flere varianter. 150 ml. • Spray\n",
      "\tc90d30fY h: Steaks Ca. 1000 gram. AF UNGKVÆG. Små fine hverdags- steaks , d: Ca. 1000 gram. AF UNGKVÆG. Små fine hverdags- steaks skåret \n",
      "\t08cfm0fY h: Danpo hakket kylling 450 gram, d: 450 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\taeberqfY h: Yoggi yoghurt 1000 gram. . Flere varianter, d: 1000 gram. . Flere varianter\n",
      "\t0cbffqfY h: Pålækker 80-90 gram. - Classic - Tomat. VILDT BILLIGT. • Ham, d: 80-90 gram. - Classic - Tomat. VILDT BILLIGT. • Hamburgerryg\n",
      "\t97f9K0fY h: Kylling I ovnklar stegepose 1500 gram. HEL DANSK, d: I ovnklar stegepose 1500 gram. HEL DANSK\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tac74V0fY h: Hårspray ELNETT. • Extra kraftig • Strong hold. 400 ml, d: ELNETT. • Extra kraftig • Strong hold. 400 ml\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t2502x0fY h: Leeuwenkuil TA' • Chenin Blanc • Shiraz • Lion's Lair, d: TA' • Chenin Blanc • Shiraz • Lion's Lair\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t4809E0fY h: Haribo POSE. DET ER BILLIGT. 100-135 gram. • Slikposer 135 g, d: POSE. DET ER BILLIGT. 100-135 gram. • Slikposer 135 gram • S\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tfed3AqfY h: Påskebryg 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælges fra fre, d: 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælges fra fredag d. 17/\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t4815F0fY h: Sodavand 150 cl. Flere varianter. + PANT. 3. • Nikoline • Fa, d: 150 cl. Flere varianter. + PANT. 3. • Nikoline • Faxe Kondi \n",
      "\t59cchqfY h: Flødehavarti 300 gram. VILDT BILLIGT, d: 300 gram. VILDT BILLIGT\n",
      "\t11bbPqfY h: Blomme tomater 500 gram, d: 500 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t46df6qfY h: kalanchoe eller potteroser, d: \n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t4daaRqfY h: 3-stjernet • Kødpølse • Røget medister • Jægerpølse • Frikad, d: • Kødpølse • Røget medister • Jægerpølse • Frikadelle i skiv\n",
      "\t22edWqfY h: Flensted kartoffelgratin med fløde 500 gram., d: med fløde 500 gram.\n",
      "\tc941A0fY h: Weekend menu tilberedt Komplet MENU af de menu TIL til 22 be, d: tilberedt Komplet MENU af de menu TIL til 22 bedste personer\n",
      "\ta367w0fY h: Libresse Flere varianter. • Trusseindlæg • Bind, d: Flere varianter. • Trusseindlæg • Bind\n",
      "\t257as0fY h: Lays chips, bugles eller doritos Sour Cream & Onion - BBQ - , d: Sour Cream & Onion - BBQ - Salt - • - Original - Nacho Chees\n",
      "\tab38CqfY h: BKI KAFFE  • Extra. 400 gram. Ved køb af mere end 10 poser, , d: • Extra. 400 gram. Ved køb af mere end 10 poser, er prisen h\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\td8f9oqfY h: Margarine •. 500 gram. BINE. BILLIGST PÅ HELE INDKØBET, d: •. 500 gram. BINE. BILLIGST PÅ HELE INDKØBET\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "------------------------\n",
      "\t1864JqfY h: Santa maria nudler 250 gram. VILDT BILLIGT, d: 250 gram. VILDT BILLIGT\n",
      "\t3956N0fY h: Harpic wc-rens Flere varianter 750 ml. KÆMPE PARTI, d: Flere varianter 750 ml. KÆMPE PARTI\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tb84a9qfY h: bambusskud eller vandkastanjer 227 gram, d: 227 gram\n",
      "\t36f3y0fY h: Danpo • Frikadeller • Medister. 400 gram, d: • Frikadeller • Medister. 400 gram\n",
      "\t00b64qfY h: avokado, squash, forårsløg eller radiser m/ top Bundt, d: Bundt\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t539csqfY h: Mou kødboller 650 gram, d: 650 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t614ebqfY h: Hellmann's mayonnaise • I glas • I tube. 225-400 gram, d: • I glas • I tube. 225-400 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tb553q0fY h: Helt kalkunbryst Ca. 800 gram, d: Ca. 800 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t29c0BqfY h: stærk chili sauce, sur/sød sauce eller sambal oelek 200-250 , d: 200-250 ml. 100 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tfc78C0fY h: Hakket kalv- & flæsk . 8-12% Ca. 500 gram. SLAGTER NORLYK ER, d: . 8-12% Ca. 500 gram. SLAGTER NORLYK ER HELE ABC LAVPRIS's S\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t222fcqfY h: Bbq mørbrad 450 gram. JENSENS, d: 450 gram. JENSENS\n",
      "\tfbff20fY h: Elvital Alle varianter. 200-250 ml. • Shampoo • Balsam • 2in, d: Alle varianter. 200-250 ml. • Shampoo • Balsam • 2in1\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t9937SqfY h: Salater 150-175 gram. GRAASTEN. Mange varianter, d: 150-175 gram. GRAASTEN. Mange varianter\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t280auqfY h: Kartoffelmos 4 breve. á 125 gram. QUEEN, d: 4 breve. á 125 gram. QUEEN\n",
      "\t ?NOT_REAL_OFFER?\n"
     ]
    }
   ],
   "source": [
    "# show predicted\n",
    "# if the model is not permutation invariant, it will predict sth else\n",
    "# for every random permutation of the source catalog\n",
    "show_predicted_catalog(\n",
    "    catalog_id='0003leq',\n",
    "    a_model=model_deepsets,\n",
    "    catalogs_dataframe=df_catalogs,\n",
    "    offers_dataframe=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model SetTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from publication_2_models_real_catalogs import SetTransformer, SetTransformerPointerCatalogNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SetTransformerPointerCatalogNetwork(\n",
       "  (word_embedding): Embedding(26169, 64)\n",
       "  (offer_embedding): PointerOfferEmbedder(\n",
       "    (offer_rnn): GRU(64, 64, num_layers=2, batch_first=True, dropout=0.05)\n",
       "  )\n",
       "  (set_embedding): SetTransformer(\n",
       "    (emb): Sequential(\n",
       "      (0): SAB(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SAB(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (enc): Sequential(\n",
       "      (0): PMA(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SAB(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): SAB(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder): PointerEncoder(\n",
       "    (lstm): LSTM(128, 32, num_layers=2, batch_first=True, dropout=0.05, bidirectional=True)\n",
       "  )\n",
       "  (decoder): PointerDecoder(\n",
       "    (input_to_hidden): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (hidden_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (att): PointerAttention(\n",
       "      (input_linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (context_linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the model\n",
    "model_settrans = SetTransformerPointerCatalogNetwork(\n",
    "    word_embedding_dim=config['ptr_word_emb_dim'],\n",
    "    offer_embedding_dim=config['ptr_offer_emb_dim'],\n",
    "    hidden_dim=config['ptr_hid_dim'],\n",
    "    offer_rnn_layers=config['ptr_offer_rnn_layers'],\n",
    "    catalog_rnn_layers=config['ptr_catalog_rnn_layers'],\n",
    "    dropout_offers=config['ptr_dropout_offers'],\n",
    "    dropout_catalogs=config['ptr_dropout_catalogs'],\n",
    "    bidir_offers=config['ptr_bidir_offers'],  # not handled 2021 04\n",
    "    bidir_catalogs=config['ptr_bidir_catalogs'],\n",
    "    masking=config['ptr_mask'],\n",
    "    vocab_size=len(word2idx),\n",
    ")\n",
    "\n",
    "model_settrans.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,945,024 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# how many params\n",
    "count_params(model_settrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-elem batch\n",
    "batch_x = X_train_torch[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 200, 200]) torch.Size([2, 200])\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "_ = model_settrans(batch_x)\n",
    "print(_[0].size(), _[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "print(_[1].type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "CCE = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer_settrans = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model_settrans.parameters()),\n",
    "    lr=config['learning_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training | Set Transformer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# test untrained model\n",
    "results_settrans, _ = test_model_custom(model_settrans, test_dataloader, compare_solved_sort_unique, print_every=999999, x_name=0, y_name=1)\n",
    "print('Result: {:.4f}'.format(results_settrans))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show rank correlations only with mask on\n",
    "print('K-Tau: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_settrans, get_single_kendall_tau, print_every=999999)))\n",
    "print('S-Rho: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_settrans, get_single_spearman_rho, print_every=999999)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 1: 100%|██████████| 26/26 [05:06<00:00, 11.80s/ batches, avg_loss=5.29775]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "last_loss_settrans = train_epochs(\n",
    "    model_settrans,\n",
    "    optimizer_settrans,\n",
    "    CCE,\n",
    "    train_dataloader,\n",
    "    config['num_epochs'],\n",
    "    allow_gpu=True,\n",
    "    x_name=0,\n",
    "    y_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.297750473022461"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_loss_settrans.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing | Set Transformer\n",
    "Put the model in eval() mode first (prevents dropout and such from predicting sth else from the same permuted x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SetTransformerPointerCatalogNetwork(\n",
       "  (word_embedding): Embedding(26169, 64)\n",
       "  (offer_embedding): PointerOfferEmbedder(\n",
       "    (offer_rnn): GRU(64, 64, num_layers=2, batch_first=True, dropout=0.05)\n",
       "  )\n",
       "  (set_embedding): SetTransformer(\n",
       "    (emb): Sequential(\n",
       "      (0): SAB(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SAB(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (enc): Sequential(\n",
       "      (0): PMA(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SAB(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): SAB(\n",
       "        (mab): MAB(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder): PointerEncoder(\n",
       "    (lstm): LSTM(128, 32, num_layers=2, batch_first=True, dropout=0.05, bidirectional=True)\n",
       "  )\n",
       "  (decoder): PointerDecoder(\n",
       "    (input_to_hidden): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (hidden_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (att): PointerAttention(\n",
       "      (input_linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (context_linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_settrans.eval()  # if we had dropout or batchnorm, we must do this"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# actual metrics\n",
    "results_settrans, _ = test_model_custom(model_settrans, test_dataloader, compare_solved_sort_unique, print_every=999999, x_name=0, y_name=1)\n",
    "print('Result: {:.4f}'.format(results_deepsets))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show rank correlations only with mask on\n",
    "print('K-Tau: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_settrans, get_single_kendall_tau, print_every=999999)))\n",
    "print('S-Rho: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_settrans, get_single_spearman_rho, print_every=999999)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sacred Experiment | Model Set Transformer\n",
    "We'll want to track the dataset, model params and the result of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - real_catalogs_SIGIR_mini_mask_True - Running command 'run_model_tests'\n",
      "INFO - real_catalogs_SIGIR_mini_mask_True - Started run with ID \"81\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'publication_2_models_real_catalogs.SetTransformerPointerCatalogNetwork'>\n",
      "Result: 0.0104\n",
      "K-Tau: 0.2959, perc_valid: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - real_catalogs_SIGIR_mini_mask_True - Result: 0.01042\n",
      "INFO - real_catalogs_SIGIR_mini_mask_True - Completed after 0:00:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-Rho: 0.4432, perc_valid: 100.0\n"
     ]
    }
   ],
   "source": [
    "# experiment config\n",
    "current_tested_model = model_settrans\n",
    "current_optimizer = optimizer_settrans\n",
    "current_last_loss = last_loss_settrans\n",
    "\n",
    "config_update = {\n",
    "    'model': current_tested_model.__class__.__name__,\n",
    "    'final_training_loss': round(current_last_loss.item(), 10),\n",
    "    'optimizer': current_optimizer.__class__.__name__,\n",
    "    'cfg': config,\n",
    "}\n",
    "\n",
    "# run the experiment, with updated config\n",
    "run_info = ex.run(config_updates=config_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show predictions\n",
    "See what it predicts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specific catalog prediction, with offer text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a catalog\n",
    "chosen_catalog_id = '0003leq'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show correct\n",
    "show_correct_catalog(\n",
    "    catalog_id=chosen_catalog_id,\n",
    "    catalogs_dataframe=df_catalogs,\n",
    "    offers_dataframe=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use premade function to nicely display a single prediction.\n",
    "\n",
    "**Models that do not properly ensure permutation invariance will give different prediction on each run** regardless of being put in .eval() mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\td8f9oqfY h: Margarine •. 500 gram. BINE. BILLIGST PÅ HELE INDKØBET, d: •. 500 gram. BINE. BILLIGST PÅ HELE INDKØBET\n",
      "\t257as0fY h: Lays chips, bugles eller doritos Sour Cream & Onion - BBQ - , d: Sour Cream & Onion - BBQ - Salt - • - Original - Nacho Chees\n",
      "\t0be3HqfY h: Spegepølser 3-STJERNET. 200-230 gram. Flere varianter, d: 3-STJERNET. 200-230 gram. Flere varianter\n",
      "\t59cchqfY h: Flødehavarti 300 gram. VILDT BILLIGT, d: 300 gram. VILDT BILLIGT\n",
      "------------------------\n",
      "\t067bTqfY h: Knorr • Orientalsk risret • Indisk risret • Chicken curry • , d: • Orientalsk risret • Indisk risret • Chicken curry • Mexika\n",
      "\taeberqfY h: Yoggi yoghurt 1000 gram. . Flere varianter, d: 1000 gram. . Flere varianter\n",
      "\t3cf8qqfY h: Oreo eller prince chokoladekiks 154-240 gram. Flere variante, d: 154-240 gram. Flere varianter\n",
      "\t00b64qfY h: avokado, squash, forårsløg eller radiser m/ top Bundt, d: Bundt\n",
      "\t22edWqfY h: Flensted kartoffelgratin med fløde 500 gram., d: med fløde 500 gram.\n",
      "\tac74V0fY h: Hårspray ELNETT. • Extra kraftig • Strong hold. 400 ml, d: ELNETT. • Extra kraftig • Strong hold. 400 ml\n",
      "\t2502x0fY h: Leeuwenkuil TA' • Chenin Blanc • Shiraz • Lion's Lair, d: TA' • Chenin Blanc • Shiraz • Lion's Lair\n",
      "\t11aaxqfY h: Kyllingeburger I alt 1000 gram. Af kyllingebrystfilet, d: I alt 1000 gram. Af kyllingebrystfilet\n",
      "\t907ajqfY h: Æbler 2 kg. pink lady. vildt billigt, d: 2 kg. pink lady. vildt billigt\n",
      "\tfb3cQ0fY h: Libero bleer • Comfort • UP&GO. 38-68 stk. • •. 400. Flere v, d: • Comfort • UP&GO. 38-68 stk. • •. 400. Flere varianter. DET\n",
      "\t5dbdl0fY h: Axe deodoranter Flere varianter. 150 ml. • Spray, d: Flere varianter. 150 ml. • Spray\n",
      "\tef59YqfY h: Corny müslibars 6 stk. • Nuts, d: 6 stk. • Nuts\n",
      "\ta5caD0fY h: Jægerkoteletter Ca. 400 gram. Marinerede koteletter med svam, d: Ca. 400 gram. Marinerede koteletter med svampe, bacon. Tilsæ\n",
      "\t614ebqfY h: Hellmann's mayonnaise • I glas • I tube. 225-400 gram, d: • I glas • I tube. 225-400 gram\n",
      "\t3030ZqfY h: Mou luksus suppe 1000 gram. Mange varianter, d: 1000 gram. Mange varianter\n",
      "\t46df6qfY h: kalanchoe eller potteroser, d: \n",
      "\t0a4eEqfY h: Havregryn Ved køb af mere end 6 poser, er prisen herefter 8,, d: Ved køb af mere end 6 poser, er prisen herefter 8,98 kr. 100\n",
      "\t3531u0fY h: Bio-tex • Flydende vask. - Color - White - Black. TA' 920 ml, d: • Flydende vask. - Color - White - Black. TA' 920 ml\n",
      "\t3956N0fY h: Harpic wc-rens Flere varianter 750 ml. KÆMPE PARTI, d: Flere varianter 750 ml. KÆMPE PARTI\n",
      "\t50b5vqfY h: Hvidløgsbaguettes PR. 525 gram, d: PR. 525 gram\n",
      "\t222fcqfY h: Bbq mørbrad 450 gram. JENSENS, d: 450 gram. JENSENS\n",
      "\t0ef3QqfY h: Kyllingelår KUN 11,66 KR. PR. KG DET ER BILLIGT. HELE. • Med, d: KUN 11,66 KR. PR. KG DET ER BILLIGT. HELE. • Med rygben 100%\n",
      "\t070eU0fY h: Ribena • Original • Light. 850 ml, d: • Original • Light. 850 ml\n",
      "\tfc78C0fY h: Hakket kalv- & flæsk . 8-12% Ca. 500 gram. SLAGTER NORLYK ER, d: . 8-12% Ca. 500 gram. SLAGTER NORLYK ER HELE ABC LAVPRIS's S\n",
      "\te2835qfY h: Asparges FRISKE. 250 gram, d: FRISKE. 250 gram\n",
      "\ta4c88qfY h: Hatting fransk hotdog  gigant burgerboller 4-6 stk. •, d: 4-6 stk. •\n",
      "\tce94wqfY h: Ice cap rejer 125 gram, d: 125 gram\n",
      "\t7d7a10fY h: Nakkefilet DANSK. 1/2 KG. Skæres til nakkekoteletter, steges, d: DANSK. 1/2 KG. Skæres til nakkekoteletter, steges hel eller \n",
      "\ta367w0fY h: Libresse Flere varianter. • Trusseindlæg • Bind, d: Flere varianter. • Trusseindlæg • Bind\n",
      "\t44a2IqfY h: Tulip •. 300-350 gram. • Baconpostej • Krydderpostej • Fløde, d: •. 300-350 gram. • Baconpostej • Krydderpostej • Flødepostej\n",
      "\t29c0BqfY h: stærk chili sauce, sur/sød sauce eller sambal oelek 200-250 , d: 200-250 ml. 100 gram\n",
      "\tfed3AqfY h: Påskebryg 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælges fra fre, d: 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælges fra fredag d. 17/\n",
      "\tdb9dGqfY h: God morgen juice Appelsin/blodgrape Appelsin. LITER. FIND DE, d: Appelsin/blodgrape Appelsin. LITER. FIND DEN PÅ KØL !\n",
      "\t029aT0fY h: Abena affaldsposer PR. SAM-PAK. 3 x, d: PR. SAM-PAK. 3 x\n",
      "------------------------\n",
      "------------------------\n",
      "\ta3abpqfY h: Steff houlberg • Brændende kærlighed • Forloren hare • Bolle, d: • Brændende kærlighed • Forloren hare • Boller i karry • Dan\n",
      "\t4809E0fY h: Haribo POSE. DET ER BILLIGT. 100-135 gram. • Slikposer 135 g, d: POSE. DET ER BILLIGT. 100-135 gram. • Slikposer 135 gram • S\n",
      "\t799dzqfY h: Frisk dansk mælk PR. LITER. Max. 24 timer fra gård til butik, d: PR. LITER. Max. 24 timer fra gård til butik • Skummetmælk • \n",
      "\tb553q0fY h: Helt kalkunbryst Ca. 800 gram, d: Ca. 800 gram\n",
      "\t3672p0fY h: Duyvis nødder Flere varianter 175-225 gram, d: Flere varianter 175-225 gram\n",
      "\t9381iqfY h: Tortilla chips SANTA MARIA. 185 gram. • Salted • Cheese • Ch, d: SANTA MARIA. 185 gram. • Salted • Cheese • Chili\n",
      "\tbd0fXqfY h: Riberhus 200 gram. I SKIVER. • Mellemlagret, d: 200 gram. I SKIVER. • Mellemlagret\n",
      "\t283c80fY h: Nescafé gold STORT GLAS. • Instant kaffe - Original - Crema., d: STORT GLAS. • Instant kaffe - Original - Crema. 200 gram\n",
      "\t0d81d0fY h: Rexona deodoranter Flere varianter. 50-150 ml. • Spray • Rol, d: Flere varianter. 50-150 ml. • Spray • Roll-on\n",
      "\t88a5UqfY h: Knækbrød LEKSANDS. Flere varianter 200 gram, d: LEKSANDS. Flere varianter 200 gram\n",
      "\t28d5kqfY h: Babymajs 400 gram, d: 400 gram\n",
      "\ta3ddnqfY h: Schulstad • Skovmand - Original - Ekstra grov. - Med fuldkor, d: • Skovmand - Original - Ekstra grov. - Med fuldkorn. 400-100\n",
      "\tb7fcb0fY h: Harpic Wc-blåt, d: \n",
      "\tb8a3DqfY h: Sukkervafler BELGISKE. 550 gram, d: BELGISKE. 550 gram\n",
      "\td4f0v0fY h: Zendium FRIT VALG. • Tandpasta • Tandbørster • Mundskyl 500 , d: FRIT VALG. • Tandpasta • Tandbørster • Mundskyl 500 ml. Fler\n",
      "\t6429tqfY h: Nordjyder 500. • Frankfurter • Røde knækpølser • Grill pølse, d: 500. • Frankfurter • Røde knækpølser • Grill pølser • Hot do\n",
      "\tb84a9qfY h: bambusskud eller vandkastanjer 227 gram, d: 227 gram\n",
      "\t0ba1i0fY h: Bamseline skyllemiddel Flere varianter 1000 ml., d: Flere varianter 1000 ml.\n",
      "\t5cb900fY h: Skinkestege 700-800 gram. • Orientalsk • Mexico, d: 700-800 gram. • Orientalsk • Mexico\n",
      "\t431baqfY h: Toast 200-290 gram. • Pariser toast • Cowboy toast. STEFF HO, d: 200-290 gram. • Pariser toast • Cowboy toast. STEFF HOULBERG\n",
      "\tdb3fNqfY h: Andelår JULIUS. 160-200 gram. CHOK PRIS, d: JULIUS. 160-200 gram. CHOK PRIS\n",
      "\t ?NOT_REAL_OFFER?\n",
      "------------------------\n",
      "\t183cY0fY h: Marabou chokoladebars 35-46 gram. • Fransk Nougat • Marabou , d: 35-46 gram. • Fransk Nougat • Marabou Original • Marabou Ore\n",
      "\t97f9K0fY h: Kylling I ovnklar stegepose 1500 gram. HEL DANSK, d: I ovnklar stegepose 1500 gram. HEL DANSK\n",
      "\t18cdFqfY h: Hønskød i tern 400 gram. Kogt og klar til brug i f.eks. tart, d: 400 gram. Kogt og klar til brug i f.eks. tarteletfyld\n",
      "\tab38CqfY h: BKI KAFFE  • Extra. 400 gram. Ved køb af mere end 10 poser, , d: • Extra. 400 gram. Ved køb af mere end 10 poser, er prisen h\n",
      "\t0da4f0fY h: Primitivo di manduria • Carlo Sani. Denne Primitivo har være, d: • Carlo Sani. Denne Primitivo har været lagret i cirka 6 mån\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\te4b8a0fY h: L'oréal triple active creme Flere varianter. 50 ml, d: Flere varianter. 50 ml\n",
      "\t539csqfY h: Mou kødboller 650 gram, d: 650 gram\n",
      "\t5b2ag0fY h: Amanda luksusrogn Pr, d: Pr\n",
      "\t4815F0fY h: Sodavand 150 cl. Flere varianter. + PANT. 3. • Nikoline • Fa, d: 150 cl. Flere varianter. + PANT. 3. • Nikoline • Faxe Kondi \n",
      "\t ?NOT_REAL_OFFER?\n",
      "------------------------\n",
      "\t36f3y0fY h: Danpo • Frikadeller • Medister. 400 gram, d: • Frikadeller • Medister. 400 gram\n",
      "\tb25flqfY h: Andebryst 130-150 gram. JULIUS, d: 130-150 gram. JULIUS\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t708e7qfY h: Cultura drik 500 ml. • Blåbær • Jordbær, d: 500 ml. • Blåbær • Jordbær\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t9937SqfY h: Salater 150-175 gram. GRAASTEN. Mange varianter, d: 150-175 gram. GRAASTEN. Mange varianter\n",
      "------------------------\n",
      "\tfbff20fY h: Elvital Alle varianter. 200-250 ml. • Shampoo • Balsam • 2in, d: Alle varianter. 200-250 ml. • Shampoo • Balsam • 2in1\n",
      "\ta6a7Z0fY h: Diamond hill 3 LITER. • Chardonnay • Shiraz • Shiraz/merlot., d: 3 LITER. • Chardonnay • Shiraz • Shiraz/merlot. BAG-IN-BOX. \n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t11bbPqfY h: Blomme tomater 500 gram, d: 500 gram\n",
      "\te545VqfY h: Viennetta is 650 ml. ISKOLD PRIS, d: 650 ml. ISKOLD PRIS\n",
      "------------------------\n",
      "\t7c1eeqfY h: Kokosmælk 17-19%. 400 ml, d: 17-19%. 400 ml\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\te4e12qfY h: Frigodan • Bønnemix • Grønt m/karry • Grønt m/tomat. 450 gra, d: • Bønnemix • Grønt m/karry • Grønt m/tomat. 450 gram\n",
      "\t6d6e0qfY h: Carletti 73,5 gram. • Lys • Mørk. PÅLÆGSCHOKOLADE. TA', d: 73,5 gram. • Lys • Mørk. PÅLÆGSCHOKOLADE. TA'\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tb3acOqfY h: Xl lagret ost Ca. 1400 gram, d: Ca. 1400 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t08cfm0fY h: Danpo hakket kylling 450 gram, d: 450 gram\n",
      "\tf1a9z0fY h: Bki kaffe 500 gram. • Classic Gold • ABC - hele bønner, d: 500 gram. • Classic Gold • ABC - hele bønner\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\td638dqfY h: Frigodan ISKOLD PRIS. • Broccoli • Fine ærter • Meget fine H, d: ISKOLD PRIS. • Broccoli • Fine ærter • Meget fine Haricots v\n",
      "\t280auqfY h: Kartoffelmos 4 breve. á 125 gram. QUEEN, d: 4 breve. á 125 gram. QUEEN\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tf4f4MqfY h: Tulip PAKKE. 200 gram. MIDDAGS- FRIKADELLER, d: PAKKE. 200 gram. MIDDAGS- FRIKADELLER\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\ta259L0fY h: Sild i spand 800/400-700 gram. • Marinerede hele fileter • M, d: 800/400-700 gram. • Marinerede hele fileter • Marinerede i b\n",
      "\tc90d30fY h: Steaks Ca. 1000 gram. AF UNGKVÆG. Små fine hverdags- steaks , d: Ca. 1000 gram. AF UNGKVÆG. Små fine hverdags- steaks skåret \n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t1864JqfY h: Santa maria nudler 250 gram. VILDT BILLIGT, d: 250 gram. VILDT BILLIGT\n",
      "\t0cbffqfY h: Pålækker 80-90 gram. - Classic - Tomat. VILDT BILLIGT. • Ham, d: 80-90 gram. - Classic - Tomat. VILDT BILLIGT. • Hamburgerryg\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t4daaRqfY h: 3-stjernet • Kødpølse • Røget medister • Jægerpølse • Frikad, d: • Kødpølse • Røget medister • Jægerpølse • Frikadelle i skiv\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tc941A0fY h: Weekend menu tilberedt Komplet MENU af de menu TIL til 22 be, d: tilberedt Komplet MENU af de menu TIL til 22 bedste personer\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n"
     ]
    }
   ],
   "source": [
    "# show predicted\n",
    "# if the model is not permutation invariant, it will predict sth else\n",
    "# for every random permutation of the source catalog\n",
    "show_predicted_catalog(\n",
    "    catalog_id='0003leq',\n",
    "    a_model=model_settrans,\n",
    "    catalogs_dataframe=df_catalogs,\n",
    "    offers_dataframe=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from publication_2_models_real_catalogs import CustomAttentionSetLayer, CustomAttentionSetEmbedder, CustomAttentionPointerCatalogNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomAttentionPointerCatalogNetwork(\n",
       "  (word_embedding): Embedding(26169, 64)\n",
       "  (offer_embedding): PointerOfferEmbedder(\n",
       "    (offer_rnn): GRU(64, 64, num_layers=2, batch_first=True, dropout=0.05)\n",
       "  )\n",
       "  (set_embedding): CustomAttentionSetEmbedder(\n",
       "    (l1): CustomAttentionSetLayer(\n",
       "      (e): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (s): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (a): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (l2): CustomAttentionSetLayer(\n",
       "      (e): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (s): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (a): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (l3): CustomAttentionSetLayer(\n",
       "      (e): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (s): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (a): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (l4): CustomAttentionSetLayer(\n",
       "      (e): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (s): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (a): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): PointerEncoder(\n",
       "    (lstm): LSTM(128, 32, num_layers=2, batch_first=True, dropout=0.05, bidirectional=True)\n",
       "  )\n",
       "  (decoder): PointerDecoder(\n",
       "    (input_to_hidden): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (hidden_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (att): PointerAttention(\n",
       "      (input_linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (context_linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the model\n",
    "model_custom = CustomAttentionPointerCatalogNetwork(\n",
    "    word_embedding_dim=config['ptr_word_emb_dim'],\n",
    "    offer_embedding_dim=config['ptr_offer_emb_dim'],\n",
    "    hidden_dim=config['ptr_hid_dim'],\n",
    "    offer_rnn_layers=config['ptr_offer_rnn_layers'],\n",
    "    catalog_rnn_layers=config['ptr_catalog_rnn_layers'],\n",
    "    dropout_offers=config['ptr_dropout_offers'],\n",
    "    dropout_catalogs=config['ptr_dropout_catalogs'],\n",
    "    bidir_offers=config['ptr_bidir_offers'],  # not handled 2021 04\n",
    "    bidir_catalogs=config['ptr_bidir_catalogs'],\n",
    "    masking=config['ptr_mask'],\n",
    "    vocab_size=len(word2idx),\n",
    ")\n",
    "\n",
    "model_custom.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,941,060 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# how many params\n",
    "count_params(model_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-elem batch\n",
    "batch_x = X_train_torch[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 200, 200]) torch.Size([2, 200])\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "_ = model_custom(batch_x)\n",
    "print(_[0].size(), _[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "print(_[1].type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "CCE = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer_custom = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model_custom.parameters()),\n",
    "    lr=config['learning_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training | Custom"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# test untrained model\n",
    "results, _ = test_model_custom(model_custom, test_dataloader, compare_solved_sort_unique, print_every=999999, x_name=0, y_name=1)\n",
    "print('Result: {:.4f}'.format(results))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show rank correlations only with mask on\n",
    "print('K-Tau: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_custom, get_single_kendall_tau, print_every=999999)))\n",
    "print('S-Rho: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_custom, get_single_spearman_rho, print_every=999999)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 1: 100%|██████████| 26/26 [00:39<00:00,  1.52s/ batches, avg_loss=5.29851]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "last_loss_custom = train_epochs(\n",
    "    model_custom,\n",
    "    optimizer_custom,\n",
    "    CCE,\n",
    "    train_dataloader,\n",
    "    config['num_epochs'],\n",
    "    allow_gpu=True,\n",
    "    x_name=0,\n",
    "    y_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.298511028289795"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_loss_custom.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing | Custom\n",
    "Put the model in eval() mode first (prevents dropout and such from predicting sth else from the same permuted x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomAttentionPointerCatalogNetwork(\n",
       "  (word_embedding): Embedding(26169, 64)\n",
       "  (offer_embedding): PointerOfferEmbedder(\n",
       "    (offer_rnn): GRU(64, 64, num_layers=2, batch_first=True, dropout=0.05)\n",
       "  )\n",
       "  (set_embedding): CustomAttentionSetEmbedder(\n",
       "    (l1): CustomAttentionSetLayer(\n",
       "      (e): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (s): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (a): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (l2): CustomAttentionSetLayer(\n",
       "      (e): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (s): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (a): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (l3): CustomAttentionSetLayer(\n",
       "      (e): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (s): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (a): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (l4): CustomAttentionSetLayer(\n",
       "      (e): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (s): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (a): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): PointerEncoder(\n",
       "    (lstm): LSTM(128, 32, num_layers=2, batch_first=True, dropout=0.05, bidirectional=True)\n",
       "  )\n",
       "  (decoder): PointerDecoder(\n",
       "    (input_to_hidden): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (hidden_to_hidden): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (hidden_out): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (att): PointerAttention(\n",
       "      (input_linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (context_linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_custom.eval()  # if we had dropout or batchnorm, we must do this"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# actual metrics\n",
    "results, _ = test_model_custom(model_custom, test_dataloader, compare_solved_sort_unique, print_every=999999, x_name=0, y_name=1)\n",
    "print('Result: {:.4f}'.format(results))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show rank correlations only with mask on\n",
    "print('K-Tau: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_custom, get_single_kendall_tau, print_every=999999)))\n",
    "print('S-Rho: {:.4f}, % valid: {}'.format(*get_batch_rank_correlation_and_perc_valid(test_dataloader, model_custom, get_single_spearman_rho, print_every=999999)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sacred Experiment | Model Custom\n",
    "We'll want to track the dataset, model params and the result of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - real_catalogs_SIGIR_mini_mask_True - Running command 'run_model_tests'\n",
      "INFO - real_catalogs_SIGIR_mini_mask_True - Started run with ID \"82\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'publication_2_models_real_catalogs.CustomAttentionPointerCatalogNetwork'>\n",
      "Result: 0.0054\n",
      "K-Tau: -0.0067, perc_valid: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - real_catalogs_SIGIR_mini_mask_True - Result: 0.00542\n",
      "INFO - real_catalogs_SIGIR_mini_mask_True - Completed after 0:00:09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-Rho: -0.0124, perc_valid: 100.0\n"
     ]
    }
   ],
   "source": [
    "# experiment config\n",
    "current_tested_model = model_custom\n",
    "current_optimizer = optimizer_custom\n",
    "current_last_loss = last_loss_custom\n",
    "\n",
    "config_update = {\n",
    "    'model': current_tested_model.__class__.__name__,\n",
    "    'final_training_loss': round(current_last_loss.item(), 10),\n",
    "    'optimizer': current_optimizer.__class__.__name__,\n",
    "    'cfg': config,\n",
    "}\n",
    "\n",
    "# run the experiment, with updated config\n",
    "run_info = ex.run(config_updates=config_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show predictions\n",
    "See what it predicts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specific catalog prediction, with offer text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a catalog\n",
    "chosen_catalog_id = '0003leq'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# show correct\n",
    "show_correct_catalog(\n",
    "    catalog_id=chosen_catalog_id,\n",
    "    catalogs_dataframe=df_catalogs,\n",
    "    offers_dataframe=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use premade function to nicely display a single prediction.\n",
    "\n",
    "**Models that do not properly ensure permutation invariance will give different prediction on each run** regardless of being put in .eval() mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t3030ZqfY h: Mou luksus suppe 1000 gram. Mange varianter, d: 1000 gram. Mange varianter\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\ta4c88qfY h: Hatting fransk hotdog  gigant burgerboller 4-6 stk. •, d: 4-6 stk. •\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t280auqfY h: Kartoffelmos 4 breve. á 125 gram. QUEEN, d: 4 breve. á 125 gram. QUEEN\n",
      "\t067bTqfY h: Knorr • Orientalsk risret • Indisk risret • Chicken curry • , d: • Orientalsk risret • Indisk risret • Chicken curry • Mexika\n",
      "\tfed3AqfY h: Påskebryg 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælges fra fre, d: 33 cl. KYLLE - KYLLE. 3 33. + PANT. Sælges fra fredag d. 17/\n",
      "\tb8a3DqfY h: Sukkervafler BELGISKE. 550 gram, d: BELGISKE. 550 gram\n",
      "\t18cdFqfY h: Hønskød i tern 400 gram. Kogt og klar til brug i f.eks. tart, d: 400 gram. Kogt og klar til brug i f.eks. tarteletfyld\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t46df6qfY h: kalanchoe eller potteroser, d: \n",
      "\t1864JqfY h: Santa maria nudler 250 gram. VILDT BILLIGT, d: 250 gram. VILDT BILLIGT\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tb553q0fY h: Helt kalkunbryst Ca. 800 gram, d: Ca. 800 gram\n",
      "------------------------\n",
      "\ta6a7Z0fY h: Diamond hill 3 LITER. • Chardonnay • Shiraz • Shiraz/merlot., d: 3 LITER. • Chardonnay • Shiraz • Shiraz/merlot. BAG-IN-BOX. \n",
      "\ta259L0fY h: Sild i spand 800/400-700 gram. • Marinerede hele fileter • M, d: 800/400-700 gram. • Marinerede hele fileter • Marinerede i b\n",
      "\t2502x0fY h: Leeuwenkuil TA' • Chenin Blanc • Shiraz • Lion's Lair, d: TA' • Chenin Blanc • Shiraz • Lion's Lair\n",
      "\t183cY0fY h: Marabou chokoladebars 35-46 gram. • Fransk Nougat • Marabou , d: 35-46 gram. • Fransk Nougat • Marabou Original • Marabou Ore\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t5dbdl0fY h: Axe deodoranter Flere varianter. 150 ml. • Spray, d: Flere varianter. 150 ml. • Spray\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\te2835qfY h: Asparges FRISKE. 250 gram, d: FRISKE. 250 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t00b64qfY h: avokado, squash, forårsløg eller radiser m/ top Bundt, d: Bundt\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tb7fcb0fY h: Harpic Wc-blåt, d: \n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tce94wqfY h: Ice cap rejer 125 gram, d: 125 gram\n",
      "\t3672p0fY h: Duyvis nødder Flere varianter 175-225 gram, d: Flere varianter 175-225 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t44a2IqfY h: Tulip •. 300-350 gram. • Baconpostej • Krydderpostej • Fløde, d: •. 300-350 gram. • Baconpostej • Krydderpostej • Flødepostej\n",
      "\t0a4eEqfY h: Havregryn Ved køb af mere end 6 poser, er prisen herefter 8,, d: Ved køb af mere end 6 poser, er prisen herefter 8,98 kr. 100\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tef59YqfY h: Corny müslibars 6 stk. • Nuts, d: 6 stk. • Nuts\n",
      "\t36f3y0fY h: Danpo • Frikadeller • Medister. 400 gram, d: • Frikadeller • Medister. 400 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tfc78C0fY h: Hakket kalv- & flæsk . 8-12% Ca. 500 gram. SLAGTER NORLYK ER, d: . 8-12% Ca. 500 gram. SLAGTER NORLYK ER HELE ABC LAVPRIS's S\n",
      "\t9937SqfY h: Salater 150-175 gram. GRAASTEN. Mange varianter, d: 150-175 gram. GRAASTEN. Mange varianter\n",
      "\t88a5UqfY h: Knækbrød LEKSANDS. Flere varianter 200 gram, d: LEKSANDS. Flere varianter 200 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\ta367w0fY h: Libresse Flere varianter. • Trusseindlæg • Bind, d: Flere varianter. • Trusseindlæg • Bind\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t29c0BqfY h: stærk chili sauce, sur/sød sauce eller sambal oelek 200-250 , d: 200-250 ml. 100 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tb3acOqfY h: Xl lagret ost Ca. 1400 gram, d: Ca. 1400 gram\n",
      "\tf4f4MqfY h: Tulip PAKKE. 200 gram. MIDDAGS- FRIKADELLER, d: PAKKE. 200 gram. MIDDAGS- FRIKADELLER\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t708e7qfY h: Cultura drik 500 ml. • Blåbær • Jordbær, d: 500 ml. • Blåbær • Jordbær\n",
      "------------------------\n",
      "\ta5caD0fY h: Jægerkoteletter Ca. 400 gram. Marinerede koteletter med svam, d: Ca. 400 gram. Marinerede koteletter med svampe, bacon. Tilsæ\n",
      "\te4e12qfY h: Frigodan • Bønnemix • Grønt m/karry • Grønt m/tomat. 450 gra, d: • Bønnemix • Grønt m/karry • Grønt m/tomat. 450 gram\n",
      "\t0da4f0fY h: Primitivo di manduria • Carlo Sani. Denne Primitivo har være, d: • Carlo Sani. Denne Primitivo har været lagret i cirka 6 mån\n",
      "\tbd0fXqfY h: Riberhus 200 gram. I SKIVER. • Mellemlagret, d: 200 gram. I SKIVER. • Mellemlagret\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t0ef3QqfY h: Kyllingelår KUN 11,66 KR. PR. KG DET ER BILLIGT. HELE. • Med, d: KUN 11,66 KR. PR. KG DET ER BILLIGT. HELE. • Med rygben 100%\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tb25flqfY h: Andebryst 130-150 gram. JULIUS, d: 130-150 gram. JULIUS\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t11aaxqfY h: Kyllingeburger I alt 1000 gram. Af kyllingebrystfilet, d: I alt 1000 gram. Af kyllingebrystfilet\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t799dzqfY h: Frisk dansk mælk PR. LITER. Max. 24 timer fra gård til butik, d: PR. LITER. Max. 24 timer fra gård til butik • Skummetmælk • \n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t5b2ag0fY h: Amanda luksusrogn Pr, d: Pr\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t0d81d0fY h: Rexona deodoranter Flere varianter. 50-150 ml. • Spray • Rol, d: Flere varianter. 50-150 ml. • Spray • Roll-on\n",
      "\t50b5vqfY h: Hvidløgsbaguettes PR. 525 gram, d: PR. 525 gram\n",
      "\t7d7a10fY h: Nakkefilet DANSK. 1/2 KG. Skæres til nakkekoteletter, steges, d: DANSK. 1/2 KG. Skæres til nakkekoteletter, steges hel eller \n",
      "\t ?NOT_REAL_OFFER?\n",
      "\taeberqfY h: Yoggi yoghurt 1000 gram. . Flere varianter, d: 1000 gram. . Flere varianter\n",
      "\t070eU0fY h: Ribena • Original • Light. 850 ml, d: • Original • Light. 850 ml\n",
      "\t9381iqfY h: Tortilla chips SANTA MARIA. 185 gram. • Salted • Cheese • Ch, d: SANTA MARIA. 185 gram. • Salted • Cheese • Chili\n",
      "\td8f9oqfY h: Margarine •. 500 gram. BINE. BILLIGST PÅ HELE INDKØBET, d: •. 500 gram. BINE. BILLIGST PÅ HELE INDKØBET\n",
      "\t28d5kqfY h: Babymajs 400 gram, d: 400 gram\n",
      "\ta3abpqfY h: Steff houlberg • Brændende kærlighed • Forloren hare • Bolle, d: • Brændende kærlighed • Forloren hare • Boller i karry • Dan\n",
      "\tfbff20fY h: Elvital Alle varianter. 200-250 ml. • Shampoo • Balsam • 2in, d: Alle varianter. 200-250 ml. • Shampoo • Balsam • 2in1\n",
      "\t539csqfY h: Mou kødboller 650 gram, d: 650 gram\n",
      "------------------------\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t7c1eeqfY h: Kokosmælk 17-19%. 400 ml, d: 17-19%. 400 ml\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t3531u0fY h: Bio-tex • Flydende vask. - Color - White - Black. TA' 920 ml, d: • Flydende vask. - Color - White - Black. TA' 920 ml\n",
      "\tfb3cQ0fY h: Libero bleer • Comfort • UP&GO. 38-68 stk. • •. 400. Flere v, d: • Comfort • UP&GO. 38-68 stk. • •. 400. Flere varianter. DET\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t6429tqfY h: Nordjyder 500. • Frankfurter • Røde knækpølser • Grill pølse, d: 500. • Frankfurter • Røde knækpølser • Grill pølser • Hot do\n",
      "\tc941A0fY h: Weekend menu tilberedt Komplet MENU af de menu TIL til 22 be, d: tilberedt Komplet MENU af de menu TIL til 22 bedste personer\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t4809E0fY h: Haribo POSE. DET ER BILLIGT. 100-135 gram. • Slikposer 135 g, d: POSE. DET ER BILLIGT. 100-135 gram. • Slikposer 135 gram • S\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\td4f0v0fY h: Zendium FRIT VALG. • Tandpasta • Tandbørster • Mundskyl 500 , d: FRIT VALG. • Tandpasta • Tandbørster • Mundskyl 500 ml. Fler\n",
      "\t59cchqfY h: Flødehavarti 300 gram. VILDT BILLIGT, d: 300 gram. VILDT BILLIGT\n",
      "\t5cb900fY h: Skinkestege 700-800 gram. • Orientalsk • Mexico, d: 700-800 gram. • Orientalsk • Mexico\n",
      "\t431baqfY h: Toast 200-290 gram. • Pariser toast • Cowboy toast. STEFF HO, d: 200-290 gram. • Pariser toast • Cowboy toast. STEFF HOULBERG\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t222fcqfY h: Bbq mørbrad 450 gram. JENSENS, d: 450 gram. JENSENS\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tab38CqfY h: BKI KAFFE  • Extra. 400 gram. Ved køb af mere end 10 poser, , d: • Extra. 400 gram. Ved køb af mere end 10 poser, er prisen h\n",
      "\t97f9K0fY h: Kylling I ovnklar stegepose 1500 gram. HEL DANSK, d: I ovnklar stegepose 1500 gram. HEL DANSK\n",
      "\t907ajqfY h: Æbler 2 kg. pink lady. vildt billigt, d: 2 kg. pink lady. vildt billigt\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\ta3ddnqfY h: Schulstad • Skovmand - Original - Ekstra grov. - Med fuldkor, d: • Skovmand - Original - Ekstra grov. - Med fuldkorn. 400-100\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t283c80fY h: Nescafé gold STORT GLAS. • Instant kaffe - Original - Crema., d: STORT GLAS. • Instant kaffe - Original - Crema. 200 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t08cfm0fY h: Danpo hakket kylling 450 gram, d: 450 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t3cf8qqfY h: Oreo eller prince chokoladekiks 154-240 gram. Flere variante, d: 154-240 gram. Flere varianter\n",
      "\tdb3fNqfY h: Andelår JULIUS. 160-200 gram. CHOK PRIS, d: JULIUS. 160-200 gram. CHOK PRIS\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t0be3HqfY h: Spegepølser 3-STJERNET. 200-230 gram. Flere varianter, d: 3-STJERNET. 200-230 gram. Flere varianter\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t029aT0fY h: Abena affaldsposer PR. SAM-PAK. 3 x, d: PR. SAM-PAK. 3 x\n",
      "\tac74V0fY h: Hårspray ELNETT. • Extra kraftig • Strong hold. 400 ml, d: ELNETT. • Extra kraftig • Strong hold. 400 ml\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t4815F0fY h: Sodavand 150 cl. Flere varianter. + PANT. 3. • Nikoline • Fa, d: 150 cl. Flere varianter. + PANT. 3. • Nikoline • Faxe Kondi \n",
      "\t257as0fY h: Lays chips, bugles eller doritos Sour Cream & Onion - BBQ - , d: Sour Cream & Onion - BBQ - Salt - • - Original - Nacho Chees\n",
      "\tdb9dGqfY h: God morgen juice Appelsin/blodgrape Appelsin. LITER. FIND DE, d: Appelsin/blodgrape Appelsin. LITER. FIND DEN PÅ KØL !\n",
      "\t11bbPqfY h: Blomme tomater 500 gram, d: 500 gram\n",
      "\td638dqfY h: Frigodan ISKOLD PRIS. • Broccoli • Fine ærter • Meget fine H, d: ISKOLD PRIS. • Broccoli • Fine ærter • Meget fine Haricots v\n",
      "\t0cbffqfY h: Pålækker 80-90 gram. - Classic - Tomat. VILDT BILLIGT. • Ham, d: 80-90 gram. - Classic - Tomat. VILDT BILLIGT. • Hamburgerryg\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t22edWqfY h: Flensted kartoffelgratin med fløde 500 gram., d: med fløde 500 gram.\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t3956N0fY h: Harpic wc-rens Flere varianter 750 ml. KÆMPE PARTI, d: Flere varianter 750 ml. KÆMPE PARTI\n",
      "\tf1a9z0fY h: Bki kaffe 500 gram. • Classic Gold • ABC - hele bønner, d: 500 gram. • Classic Gold • ABC - hele bønner\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t0ba1i0fY h: Bamseline skyllemiddel Flere varianter 1000 ml., d: Flere varianter 1000 ml.\n",
      "\te4b8a0fY h: L'oréal triple active creme Flere varianter. 50 ml, d: Flere varianter. 50 ml\n",
      "\t614ebqfY h: Hellmann's mayonnaise • I glas • I tube. 225-400 gram, d: • I glas • I tube. 225-400 gram\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\t6d6e0qfY h: Carletti 73,5 gram. • Lys • Mørk. PÅLÆGSCHOKOLADE. TA', d: 73,5 gram. • Lys • Mørk. PÅLÆGSCHOKOLADE. TA'\n",
      "\tb84a9qfY h: bambusskud eller vandkastanjer 227 gram, d: 227 gram\n",
      "\te545VqfY h: Viennetta is 650 ml. ISKOLD PRIS, d: 650 ml. ISKOLD PRIS\n",
      "\t4daaRqfY h: 3-stjernet • Kødpølse • Røget medister • Jægerpølse • Frikad, d: • Kødpølse • Røget medister • Jægerpølse • Frikadelle i skiv\n",
      "\t ?NOT_REAL_OFFER?\n",
      "\tc90d30fY h: Steaks Ca. 1000 gram. AF UNGKVÆG. Små fine hverdags- steaks , d: Ca. 1000 gram. AF UNGKVÆG. Små fine hverdags- steaks skåret \n"
     ]
    }
   ],
   "source": [
    "# show predicted\n",
    "# if the model is not permutation invariant, it will predict sth else\n",
    "# for every random permutation of the source catalog\n",
    "show_predicted_catalog(\n",
    "    catalog_id='0003leq',\n",
    "    a_model=model_custom,\n",
    "    catalogs_dataframe=df_catalogs,\n",
    "    offers_dataframe=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- (x) load data in\n",
    "- (x) train a ptr net model\n",
    "- (x) add sacred tracking\n",
    "- (x) check predicted catalogs by seeing which offers (heading/description) were placed together (i.e. print predicted catalog)\n",
    "    - (x) take a catalog from known (by id) 0003leq\n",
    "    - (x) shuffle its offers as vectors into sth else (but keep new index to offer id mapping\n",
    "    - (x) shuffle its offer ids in the same exact way\n",
    "    - (x) get the offer id predicted order from prediction\n",
    "    - (x) show text/description of each offer, marking page breaks (if present)\n",
    "- (x) adjust and train other models (1 epoch here)\n",
    "    - (x) add deepsets\n",
    "    - (x) add set-transformer (working version in pycharm)\n",
    "    - (x) consider if we want to add RPW (since we're seemingly dropping custom?) Or add custom? With deeper layers?\n",
    "- (x) move real and mini sigir data to GPU instance\n",
    "- (x) run longer training there\n",
    "\n",
    "# NEXT\n",
    "- **we need to handle predicting page breaks without giving the model info on how many there should be** (varying number of clusters)\n",
    "    - this could be achieved by predicting a second sequence, with 0s where no page break (after it) and 1 where there should be.\n",
    "- we might want to get offer embeddings via the binary co-occurrence task.\n",
    "- use a Transformer (maybe pytorch class?) as word-level offer encoder\n",
    "- could also figure out the exact source of the memory error with full test set rho/tau calculations, to get less of a CV and more of a true test result on those (including normal result, but that one didn't suffer from OOM with a full 2K test set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archives\n",
    "Below I'm keeping some useful stuff relevant to real catalog data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-proof of torch with these nested batches\n",
    "This is kind of tricky, catalogs are arrays of offers, which are themselves made up of sequences of word tokens (as indices of a dictionary). To not shoot myself in the foot for later, here's a proof of concept of a model able to massage this data into classic (batch, num_offers, offer_embedding_size) shape."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# data\n",
    "batch_size = 2\n",
    "words_per_offer = 10\n",
    "offers_per_catalog = 5\n",
    "word2idx_size = 12\n",
    "\n",
    "# model\n",
    "word_embedding_size = 32\n",
    "offer_hidden_size = 24\n",
    "offer_recurrent_layers = 2\n",
    "offer_batch_first = True\n",
    "\n",
    "x = torch.randint(low=0,\n",
    "                  high=word2idx_size,\n",
    "                  size=(batch_size, offers_per_catalog, words_per_offer,))\n",
    "print('Size at start: ', x.size(), x)\n",
    "\n",
    "# here we try to do a forward() pass:\n",
    "word_embedding_layer = nn.Embedding(num_embeddings=word2idx_size,\n",
    "                                    embedding_dim=word_embedding_size)\n",
    "offer_embedding_layer = nn.GRU(input_size=word_embedding_size,\n",
    "                               hidden_size=offer_hidden_size,\n",
    "                               num_layers=offer_recurrent_layers,\n",
    "                               batch_first=offer_batch_first)\n",
    "\n",
    "# embed words\n",
    "x = word_embedding_layer(x)\n",
    "print('Size after word embedding: ', x.size())\n",
    "\n",
    "# go through each offer, and get a fixed length vector for it\n",
    "# catalogs_with_embedded_offers = torch.empty([0, offers_per_catalog, words_per_offer])\n",
    "batch_hidden = []\n",
    "for catalog in x:\n",
    "    offers_hidden = []\n",
    "    for offer in catalog:\n",
    "\n",
    "        # 1-offer batch\n",
    "        offer = offer.unsqueeze(0)\n",
    "\n",
    "        # RNN\n",
    "        _, hidden_states_from_layers = offer_embedding_layer(offer)\n",
    "\n",
    "        # new offer representation is the hidden state of the last layer\n",
    "        offer_hidden = hidden_states_from_layers[-1]\n",
    "\n",
    "        print('Offer hidden: ', offer_hidden.size())\n",
    "\n",
    "        # append it to the placeholder\n",
    "        offers_hidden.append(offer_hidden)\n",
    "\n",
    "    # stack and squeeze\n",
    "    catalog_hidden = torch.stack(offers_hidden, dim=0)\n",
    "    catalog_hidden = catalog_hidden.squeeze(1)\n",
    "    print('Catalog hidden: ', catalog_hidden.size())\n",
    "\n",
    "    # add to batch\n",
    "    batch_hidden.append(catalog_hidden)\n",
    "\n",
    "# back to a normal batch\n",
    "batch_hidden = torch.stack(batch_hidden, dim=0)\n",
    "print('Batch stack: ', batch_hidden.size())\n",
    "\n",
    "\n",
    "# assumptions:\n",
    "#  1. we can get catalogs with same n-offers, as dataloaders (tensors) we can embedd offers with an RNN into fixed size\n",
    "#  2. we can embedd offers with an RNN into fixed size\n",
    "#  3. we can deal with embedded words (b, o, w, e) shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
